{"1676209673.3742688": {"單位": "", "標題": "螞蟻", "作者": "", "發布日": 0, "摘要": "", "全文": "螞蟻屬完全變態昆蟲，要經過卵、幼蟲、蛹等階段才發展為成蟲，大部分的物種在幼蟲階段沒有移動能力，由工蟻餵養，工蟻覓食時會把液態食物吃下，回巢後再吐出餵給幼蟲，成蟲之間也以這種方式交換食物，此行為稱作「交哺 」（trophallaxis)，幼蟲發育時需要舒適的溫度，因此工蟻經常將它們搬來搬去，維持合適的生長環境。大部分螞蟻可粗分為三個階級：工蟻、雄蟻和蟻后，雌幼蟲發育成工蟻或是蟻后則取決於幼蟲期獲得的養分[來源請求]。工蟻沒有翅膀，只有雄蟻和處女雌蟻有翅膀，雌蟻交配後會把翅膀拔掉，雄蟻在交配後一段時間便會死亡。"}, "1676210646.4363058": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306984126397040076_1676210426716為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210648.7068481": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306984126397040076_1676210426716為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210674.4444792": {"單位": "", "標題": "伍動螞蟻-", "作者": "", "發布日": 0, "摘要": "", "全文": "螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側(KahootQ&A、google問卷編1.\t前測問卷發放-小學生的螞蟻知識知多少?\t(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題講及臭巨山蟻來更了解螞蟻的日常習性，並藉此螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻知識知多少》的螞蟻知識推廣的更懂螞蟻，所以我在專題講座後請參語的同學在我煩惱要做什麼當我的獨立研究時，忽然看到了螞蟻相關報告，讓我彷彿撥雲見日，我決定要以螞蟻當作我的獨立研究主題。在文獻探討中，我將其分為八個章節，在網路上搜尋有關螞蟻的知識。並在閒暇的時間進行有關螞蟻的小實驗，目的就是要讓我的報告更完整，且更有價值。經過了一段艱辛的路程後，我完成了我的獨立研究。希望能讓大家更了解螞蟻，且更尊重牠們。螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們的(二)讓大家了解螞蟻之餘，能更尊重牠們。為蟻窩中具有生殖能力的雌性螞蟻，整個蟻群都為蟻后的後代。有時不需要雄蟻介入也能進行孤雌生殖，不過在這種情況下所產出來的卵為未受精的卵，只會孵化出雄蟻。大多數的蟻后和雄蟻都會進行婚飛，也就是在特定時間讓蟻后與型蟻同時飛出巢外，並且進行交配，而不同螞蟻進行婚飛的時間也不盡相同。依照種類的不同，有些種一個蟻窩中只會有一隻蟻后，也有些種類的螞蟻在一個蟻窩中同時會有上百隻具有生殖能力的蟻后。蟻后可生存長達30年，紀錄中由德國昆蟲學家HermannAppel所飼養的黑褐毛山蟻蟻后活了28¾年。雖然蟻后被稱為「蟻后」，但不能將人類社會當中上下階級和統治的觀念給帶入螞蟻社會中。事實上，蟻后在蟻巢中只是個產卵機器，在部分情況下甚至會被推翻。由此可證蟻后不一定在蟻巢中絕對的權勢。雄蟻的主要工作是與蟻后交配。由未受精的卵細胞發育而來，性染色體為X(人類男性的性染色體為XY)，大部分有翅，交配完不久後便會死去。工蟻的主要工作為負責搜尋食物、照顧蟻卵、幼蟲等大部分的工作，體型比兵蟻小。是由受精的卵細胞發育而來，染色體雙套（2n），大部分在一出生就就受到蟻后分泌的費洛蒙影響，所以不會產卵，在蟻后死亡後可能會產下未受精卵。未受精卵有營養卵或是雄蟻卵兩種，營養卵是食物，雄蟻卵則會孵化成雄蟻；而某些物種的工蟻卵巢能夠發育，交配後能夠產下能發育的受精卵。部分物種的工蟻產卵管特化為螫針，可以用來制服獵物或是防衛蟻窩。在螞蟻巢中，較年輕的工蟻會負責照顧蟻后；而幾乎所有的螞蟻都具有年齡多形性（Agepolytheism）的分工機制，除了兩個物種以外，分別是Amblyoponepallipes和大眼擬鬥牛犬蟻（Nothomyrmeciamacrops）。1.和工蟻一起保衛蟻巢。如熱帶火蟻、收穫蟻屬。2.在工蟻出外覓食的時候，幫忙擔任清除雜物的「推土機」並非每一種螞蟻都有兵蟻，沒有兵蟻的物種包括針蟻亞科、琉璃蟻亞科、擬家蟻亞科等。兵蟻是由受精的卵細胞發育而來，染色體雙套，為沒有生殖能力的雌蟲。某些物種的兵蟻頭部及大顎高度骨化且發達。一般來說頭部異速生長的大型個體稱作兵蟻，而頭部沒有異速生長的大型個體則稱作大工蟻，但這兩個詞彙之間還是有難以區分的灰色地帶。具有兵蟻的物種如大頭家蟻屬，具在蟻巢中，除生殖階級外，所有個體無翅。觸角為膝狀，某些物種觸角末端膨大，稱作「垂節」，牠們的觸角，牠們也用觸角判斷彼此身分。大部分物種胸部和腹部之間隘縮，形成腰節，實則屬於胸部的延伸，或稱腹柄節，具有三個腹節。胸節與前伸腹節合稱「中軀」），腹垂節稱作「後軀」。螞蟻的體型範圍平均大約為0.75~52mm，目前已知體型最大的螞蟻為已滅絕的古巨蟻亞科，蟻后體長可達6cm，翅膀長度可達15cm。螞蟻可以透過費洛蒙溝通，一隻螞蟻如果發現了食物，它就會在回家的路上留下一路的氣味，其他的螞蟻就會沿著這條氣味路線去找食物，並不斷地留下氣味加強氣味。如果這裡的食物被採集完了，沒有螞蟻再來，氣味就會逐漸消散。如果一隻螞蟻被碾碎，就會散發出強烈的警戒費洛蒙(註一)引起其他螞蟻進入緊戒狀態；如果一隻螞蟻散發出死亡費洛蒙，不管那隻螞蟻是活的還是螞蟻和其他昆蟲一樣透過觸角辨識氣味，觸角的末幾節膨大，呈膝狀彎曲，非常靈活。由於觸角是一對，因此既能辨别氣味的強度，也能辨識氣味來源的方向距離。但是也造就了蟻客(專門寄生於螞蟻巢內的生物，部分蟻客對螞蟻沒有害處，不過有一部分的蟻客對螞蟻有明顯危害)成蟲互相交哺並通過其氣味了解對方的健康狀況，對方發現的食物等資訊。同時也能區別對方屬於從事哪個分工的階級。如負責餵養蟻后及幼蟲的螞蟻，或是負責搜集食物的螞蟻后會不斷地分泌費洛蒙，這種費洛蒙能抑制工蟻的卵巢發育並讓工蟻知道蟻后還在巢內，一旦以這種氣味消失，有些物種會出現新的蟻后，有些物種的工蟻則會開始產卵，填補蟻后的功能。某些螞蟻用大顎啃咬以攻擊或自衛，山蟻亞科的物種能從腹部末端分泌蟻酸（甲酸），刺激被叮咬的傷口紅腫疼痛；部分物種腹部末端具有螫針。螞蟻亦是全世界力氣最大的昆蟲之一，牠的負重能力相當驚人，能拖動比牠體重還重1400倍的物品，也能背負自身體重註一:警戒費洛蒙分成己醛、己醇、正十一酮和丁基辛酮。己醛會最先出現，提醒工蟻提高警覺；己醇是與酒精(乙醇)類似的物質，會促使工蟻尋找問題來源；正十一酮會吸引工蟻接近問題來源，並在碰到外來物時張口就咬；丁基辛酮最後才會出現，會讓工蟻展開攻擊與咬噬的行動。蠻蟻亞科Agroecomyrmecinae鈍針蟻亞科Amblyoponinae（包含新蟻亞科Apomyrminae）†布朗長蟻亞科†Brownimeciinae異針蟻亞科Heteroponerinae鬥牛犬蟻亞科Myrmeciinae（包含：擬鬥牛犬蟻亞擬家蟻亞科Pseudomyrmecinae†蜂蟻亞科†Sphecomyrminae†幽冥蟻亞科†Haidomyrmecini†阿爾曼蟻亞科†Armaniinae，有些文獻將牠列入蟻科，有些則獨立一科，但無論如何，該亞科都在蟻總科（Formicoidea）之下目前已確定有21亞科283屬，11700種。茲舉幾種以說明:(一)行軍蟻:牠們會一直移居，並且吞食路上遇到的獵物。在移居過程中，1.又名弓背蟻屬或木匠蟻屬，是蟻科山蟻亞科的一個屬。2.牠們不喜歡築巢在乾燥的地方，而巢穴可能建於房屋的橫樑、地板或巢穴中。牠們是雜食性的螞蟻，以食物碎屑或其他昆蟲為食，也會食3.巨山蟻屬的成員眾多，台灣目前本屬有十七種，巨山蟻屬以牠們獨特的習性聞名。牠們會在木材裡挖洞，並以這些通道為生活重心，因為牠們這種特殊的生活習性，所以規模較大的巨山蟻群落會造成房屋結構性毀損，但通常不像白蟻破壞過的那麼嚴重。4.一個成熟的巨山蟻群落一般會有一隻蟻后，許多待孵化的卵，超過兩千隻以上的工蟻，和一個只有工蟻的附屬群落。5.目前發現的蟻后體型最大者為1.91公分。而屋裡的巨山蟻可能是來自主群落或附屬群落，例如：巨山蟻可能來自戶外已枯萎的大樹，陸6.本屬的膨咕巨山蟻跟蜜瓶蟻一樣有貯蜜蟻階級(蜜瓶蟻中的貯蜜蟻又稱蜜缽階級工蟻)它們會收集糖蜜並儲存它們。而在鬧飢荒時，這些貯蜜蟻就派上用場了:牠們會把這些花蜜回哺給同伴食用。7.被巨山蟻在裡面築巢的木材會有木屑遺落在附近，而被白蟻破壞過的木材則會有含泥類物質，當發現附近有上述的木屑(通常會包含已死亡的螞蟻和部分被巨山蟻吃掉的昆蟲殘骸)，就代表附近可能有巨山蟻的巢穴。巨山蟻喜歡築巢在較潮濕的木頭中。(三)針蟻:這種螞蟻包含世界最大的螞蟻:巨人恐針蟻。牠們是少數沒有蟻后的螞蟻，交配過的工蟻會取代蟻后，可以透過解剖牠(四)蜜瓶蟻:牠們的部分大型工蟻會吸飽蜜，在鬧飢荒的時候回吐花蜜，因此被稱為蜜缽階級工蟻。牠們也是澳洲居民的美食，澳洲居民會從牠們的屁股吸取花蜜，但是被人類吸食的蜜瓶蟻也會因為人類破壞式的取(五)火蟻:火蟻屬中有惡名昭彰的入侵紅火蟻，但是火蟻屬中，在台灣已發現1.獵食紅火蟻：生活在森林邊緣，都市綠地、海邊、草地、農地等。在石頭下或土中常常可以發現牠們的蟻巢。牠們是多后制體系的螞蟻，成熟蟻巢由數隻具生殖能力的蟻后和數百隻工蟻組成。牠們分布在台灣中低海拔地區，牠們的食性是雜食偏素食性，主要食物是花蜜、蜜腺分泌和小型昆蟲屍體。牠們除了。會讓工蟻組成小組出外覓食，還會用蟻賊的方式，偷取附近蟻巢的資源。目前未發現有2.知本火蟻：牠們是一種分布在廣西、湖南、湖北天堂寨和台灣。牠們跟原生於南美洲、中美洲、墨西哥和部分美國南部地區的切葉蟻有親戚關係。牠們原生於美洲的熱帶與亞熱帶地區，後來隨著交通工具入侵印度、非洲、太平洋島嶼等地區。牠們攻擊性較強，會出現主動攻擊人畜與莊稼，甚至會咬破電線，破壞供電系統。牠們的毒腺中含有大量生物鹼，叮咬人時會造成劇烈疼痛。會危害當地的農林業生產、人體健康、公共安全及生態環境。3.入侵紅火蟻：牠們的英文簡稱為RIFA，是Redimportedfireant的縮寫，原分布在巴拉那河流域，由於生活在河邊，所以發展出「蟻筏」，也就是讓工蟻互相咬住對方，變成一個蟻筏，並且把蟻后、卵、幼蟲及蛹放在上面，載牠們渡河。由於牠們體表防水，所以不會淹死。紅火蟻在二十世紀初入侵美國南部，造成美國十二個州超過一億公畝(一百億平方公尺)被入侵紅火蟻佔領，每年損失約數十億美元以上。且目前未發現能夠有效防治入侵紅火蟻的生物。火蟻屬成員的毒液大多含有大量生物鹼，叮咬人時會產生如火燒般的劇痛，這也是牠們被取名為「火蟻」的原因。紅火蟻的成熟群落約有二十萬隻至五十萬隻，所以入侵者往往會被大量的火蟻叮咬。被火蟻叮咬後，大部分的人除了會感到劇痛，還會產生水泡，若把它抓破，則會造成二次性的感染。少部分的人甚至會產生嚴重的過螞蟻是靠氣味溝通的。所以蟻客就是掌握了螞蟻的費洛蒙，才能滲透進蟻巢。有些蟻客寄生在蟻巢內純粹是為了尋求庇護，如寄生家蟻；有些蟻客則是為了取得食物，如:黑隱翅蟲的幼蟲會寄生在蟻巢內，並吞食正牌的螞蟻幼蟲。牠們沒有消滅整個蟻巢，是因為牠們也會自相殘殺。甚至有一種蜘蛛會偽有些植物也跟螞蟻有共生關係。如:有一種植物會分泌蜜露，供螞蟻食用，和讓螞蟻築巢在裡面。而螞蟻則會趕走要吃牠們的動物，並且清除雜草。而這有助於植物生長。形成互利共生的關係。螞蟻可以簡單分為頭胸腹三部分，但是更細微的部分呢?以下是我從網路抓(KahootQ&A、google問卷編1.前測問卷發放-小學生的螞蟻知識知多少?(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題2.螞蟻習性觀察:我透過飼養高雄巨山蟻、希氏巨山蟻，以及臭巨山蟻來更了解螞蟻的日常習性，並藉此驗證我所查到的文獻內容是否正3.校內演講:螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻4.後測問卷發放-我了解舉辦一場專題講座是否能夠讓同學更懂螞蟻，所以我在專題講座後請參語的同學幫我填寫回饋問卷，也給我一些一、前測問卷分析-小學生的螞蟻知識知多少?我為了想要了解小學生對螞蟻的認識，因此特地發了這份問卷，並請高年級的電腦老師鍾佑聆老師於電腦課的時候花幾分鐘的時間請大家填寫。下表顯示我於二零二零年十二月二十一日所發出，並於二零二零年十二月三十日回收的問卷共527筆的結果如下，請詳細閱讀。由此表可知，在527人中，有480個人回答了正確答案(正確答案:六隻腳)，21人回答螞蟻有四隻腳，26人回答螞蟻有八隻腳。難度:低由此表可知，在527人中，有491個人回答了正確答案(正確答案:蟻后)，6個人回答兵蟻，9個人回答雄蟻，17個人回答工蟻。難度:低由此表可知，在527人中，有十三人回答蟻后、四百八十一人回答工蟻、四十人回答雄蟻及一百八十二人回答兵蟻(正確答案:工蟻和兵蟻)。難度:低由此表可知，在527人中，有475個人回答了正確答案(正確答案:兵蟻)，7人回答蟻后，36人回答工蟻，8人回答雄蟻。難度:低由此表可知，在527人中，有489個人回答了正確答案(正確答案:雄蟻)，5人回答兵蟻，14人回答蟻后，19人回答工蟻。難度:低由此表可知，在525人中，有192個人回答了正確答案(正確答案:亞全山蟻)，125人回答狂蟻(小黑蟻)，53人回答亞絲山蟻，154人回答都不是。難度:高由此表可知，在523人中，有168個人回答了正確答案(正確答案:亞絲山蟻)，170人回答狂蟻(小黑蟻)，99人回答都不是，85人回答亞全山蟻。難度:高由此表可知，在523人中，有317個人回答了正確答案(正確答案:蜜瓶蟻)，78人回答狂蟻(小黑蟻)，43人回答亞絲山蟻，84人回答都不是，難度:中由此表可知，在523人中，有211個人回答了正確答案(正確答案:火家蟻)，130人回答黃瘋蟻，35人回答蜜瓶蟻，83人回答都不是，63人回答白霜前琉璃由此表可知，在523人中，有110人回答了正確答案(正確答案:蜈蚣)，67人回答青蛙，154人回答都不是，120人回答蜘蛛，72人回答蠍子。難度:高由此表可知，在523人中，有181個人回答了正確答案(正確答案:不是)，342由此表可知，在518人中，有179人回答了正確答案(正確答案:黃瘋蟻)，196人回答白霜前琉璃蟻，62人回答蜜瓶蟻，83人回答狂蟻。難度:高由此表可知，在518人中，有324人回答了正確答案(正確答案:鋸針蟻)，61人回答黃瘋蟻，100人回答狂蟻，33人回答蜜瓶蟻。難度:中1.螞蟻遇到石膏粉與滑石粉時，會因為摩擦力降低而無法爬上斜坡。2.不同種或同種不同窩的螞蟻在相遇時有可能會打起來，也可能會互相忽略，但是在其中一方確定自己有百分之百的勝算時，便會征服另一個群落。(三)專題講座後的搶答活動:後測kahoot問答:螞蟻冷知識知多少?在我進行完螞蟻專題講座後，我用kahoot進行機智問答。以下是我的題1.螞蟻有幾隻腳(選項:四隻腳、六隻腳、八隻腳、十隻腳)2.一般來說，什麼螞蟻會產卵(選項:雄蟻、蟻后、工蟻、兵蟻)3.請問何種螞蟻是由非受精卵孵化而成?(選項:工蟻、蟻后、雄蟻、兵4.以下何者是「蟻客」?(選項:獨角仙、鍬形蟲、黑隱翅蟲(幼蟲)、蟑5.下列何者會捕食螞蟻(選項:草齡幼蟲、蝴蝶、蜜蜂、以上皆非)6.下列敘述何者正確?(選項:螞蟻為群落服務並不為任何好處、所有的螞蟻都具有兵蟻階級、螞蟻群都是雜食性的昆蟲、螞蟻是一種真社會7.螞蟻的一生為何?(選項:卵-幼蟲-蛹-成蟲、卵-若蟲-成蟲、卵-若蟲8.古代有一種「蚳醢」，為帝王食補。請問蚳醢為下列何者?(選項:螞9.螞蟻和下列何者有親戚關係?(選項:蟑螂、白蟻、螳螂、胡蜂)10.白蟻和下列何者有親戚關係?選項:蟑螂、獨角仙、天蛾、胡蜂)11.請問螞蟻透過甚麼溝通?(選項:費洛蒙、聲音、震動、以上皆是)12.請問下列何種螞蟻會使用蟻酸攻擊?(選項:蠻蟻亞科、家蟻亞科、此為我於民國一一○年三月三十號螞蟻講座後發出的滿意度調查問卷:由此表可知，有四個人對於我在台上的表現給三分、二個人給我四分、五個人由此表可知，有四個人對於我在台上的表現給三分、三個人給我四分、四個人由此表可知，有十一個人在這次專題演講後，對於螞蟻知識有更深的了解、零由此表可知，有七個人在這次專題演講後，不會想要進一步了解螞蟻的相關知識或主動閱讀相關書籍、四個人會想要進一步了解螞蟻的相關知識或主動閱讀此為我對同學們發出的專題講座滿意度調查問卷:簡報得稍微有點多，我還沒看完就換下一頁。可以講得再慢一點搶答部分應先設定好平板、電腦，以免讓大家等太久由此表可知，有六個人認為不用改進、兩個人認為可以先把平板和電腦設定好、一個人認為我講太快了、一個人認為簡報上面的字有點多、一個人認為簡根據我發出的表格，有五題難度為低，三題難度為中，五題難度為高，平均難度為中。卻有很多題目連一半的答對率都不到，我覺得是因為我的問卷題目太刁鑽而且太難。下次可以考慮把題目的難度降低且不要出那麼刁鑽，會更我將研究結果統一整理成一個表格，來表達我的結果與討論，還有結論與此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側問答的結果、結論和建議製作的表格:一、維基百科https://reurl.cc/6yV2xO二、超罕見的詭異螞蟻！澳洲原住民最愛的甜食「蜜罐蟻」，號稱行走食物櫃https://reurl.cc/R1Dao6三、臺灣生命大百科:獵食火家蟻https://reurl.cc/7oLnKN四、知本火蟻https://reurl.cc/r84Ga4五、認識火蟻https://reurl.cc/e87lGb六、巨山蟻屬https://reurl.cc/Q3xlpZ七、下課花路米第749集-小小螞蟻大世界(上)https://reurl.cc/VXVoW6八、下課花路米第750集-小小螞蟻大世界(下)https://reurl.cc/OqWom9九、下課花路米第1181集-台灣還有紅火蟻?https://reurl.cc/odG3K3十、流言追追追第51集-螞蟻剋星https://reurl.cc/9X8A5j流言追追追第4集https://reurl.cc/KjZg3e螞蟻的構造https://reurl.cc/pmndVZ螞蟻亞科列表https://reurl.cc/5ox9qv"}, "1676210716.6615682": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306984126397040076_1676210426716為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210724.327447": {"單位": "", "標題": "伍動螞蟻-", "作者": "", "發布日": 0, "摘要": "", "全文": "螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側(KahootQ&A、google問卷編1.\t前測問卷發放-小學生的螞蟻知識知多少?\t(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題講及臭巨山蟻來更了解螞蟻的日常習性，並藉此螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻知識知多少》的螞蟻知識推廣的更懂螞蟻，所以我在專題講座後請參語的同學在我煩惱要做什麼當我的獨立研究時，忽然看到了螞蟻相關報告，讓我彷彿撥雲見日，我決定要以螞蟻當作我的獨立研究主題。在文獻探討中，我將其分為八個章節，在網路上搜尋有關螞蟻的知識。並在閒暇的時間進行有關螞蟻的小實驗，目的就是要讓我的報告更完整，且更有價值。經過了一段艱辛的路程後，我完成了我的獨立研究。希望能讓大家更了解螞蟻，且更尊重牠們。螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們的(二)讓大家了解螞蟻之餘，能更尊重牠們。為蟻窩中具有生殖能力的雌性螞蟻，整個蟻群都為蟻后的後代。有時不需要雄蟻介入也能進行孤雌生殖，不過在這種情況下所產出來的卵為未受精的卵，只會孵化出雄蟻。大多數的蟻后和雄蟻都會進行婚飛，也就是在特定時間讓蟻后與型蟻同時飛出巢外，並且進行交配，而不同螞蟻進行婚飛的時間也不盡相同。依照種類的不同，有些種一個蟻窩中只會有一隻蟻后，也有些種類的螞蟻在一個蟻窩中同時會有上百隻具有生殖能力的蟻后。蟻后可生存長達30年，紀錄中由德國昆蟲學家HermannAppel所飼養的黑褐毛山蟻蟻后活了28¾年。雖然蟻后被稱為「蟻后」，但不能將人類社會當中上下階級和統治的觀念給帶入螞蟻社會中。事實上，蟻后在蟻巢中只是個產卵機器，在部分情況下甚至會被推翻。由此可證蟻后不一定在蟻巢中絕對的權勢。雄蟻的主要工作是與蟻后交配。由未受精的卵細胞發育而來，性染色體為X(人類男性的性染色體為XY)，大部分有翅，交配完不久後便會死去。工蟻的主要工作為負責搜尋食物、照顧蟻卵、幼蟲等大部分的工作，體型比兵蟻小。是由受精的卵細胞發育而來，染色體雙套（2n），大部分在一出生就就受到蟻后分泌的費洛蒙影響，所以不會產卵，在蟻后死亡後可能會產下未受精卵。未受精卵有營養卵或是雄蟻卵兩種，營養卵是食物，雄蟻卵則會孵化成雄蟻；而某些物種的工蟻卵巢能夠發育，交配後能夠產下能發育的受精卵。部分物種的工蟻產卵管特化為螫針，可以用來制服獵物或是防衛蟻窩。在螞蟻巢中，較年輕的工蟻會負責照顧蟻后；而幾乎所有的螞蟻都具有年齡多形性（Agepolytheism）的分工機制，除了兩個物種以外，分別是Amblyoponepallipes和大眼擬鬥牛犬蟻（Nothomyrmeciamacrops）。1.和工蟻一起保衛蟻巢。如熱帶火蟻、收穫蟻屬。2.在工蟻出外覓食的時候，幫忙擔任清除雜物的「推土機」並非每一種螞蟻都有兵蟻，沒有兵蟻的物種包括針蟻亞科、琉璃蟻亞科、擬家蟻亞科等。兵蟻是由受精的卵細胞發育而來，染色體雙套，為沒有生殖能力的雌蟲。某些物種的兵蟻頭部及大顎高度骨化且發達。一般來說頭部異速生長的大型個體稱作兵蟻，而頭部沒有異速生長的大型個體則稱作大工蟻，但這兩個詞彙之間還是有難以區分的灰色地帶。具有兵蟻的物種如大頭家蟻屬，具在蟻巢中，除生殖階級外，所有個體無翅。觸角為膝狀，某些物種觸角末端膨大，稱作「垂節」，牠們的觸角，牠們也用觸角判斷彼此身分。大部分物種胸部和腹部之間隘縮，形成腰節，實則屬於胸部的延伸，或稱腹柄節，具有三個腹節。胸節與前伸腹節合稱「中軀」），腹垂節稱作「後軀」。螞蟻的體型範圍平均大約為0.75~52mm，目前已知體型最大的螞蟻為已滅絕的古巨蟻亞科，蟻后體長可達6cm，翅膀長度可達15cm。螞蟻可以透過費洛蒙溝通，一隻螞蟻如果發現了食物，它就會在回家的路上留下一路的氣味，其他的螞蟻就會沿著這條氣味路線去找食物，並不斷地留下氣味加強氣味。如果這裡的食物被採集完了，沒有螞蟻再來，氣味就會逐漸消散。如果一隻螞蟻被碾碎，就會散發出強烈的警戒費洛蒙(註一)引起其他螞蟻進入緊戒狀態；如果一隻螞蟻散發出死亡費洛蒙，不管那隻螞蟻是活的還是螞蟻和其他昆蟲一樣透過觸角辨識氣味，觸角的末幾節膨大，呈膝狀彎曲，非常靈活。由於觸角是一對，因此既能辨别氣味的強度，也能辨識氣味來源的方向距離。但是也造就了蟻客(專門寄生於螞蟻巢內的生物，部分蟻客對螞蟻沒有害處，不過有一部分的蟻客對螞蟻有明顯危害)成蟲互相交哺並通過其氣味了解對方的健康狀況，對方發現的食物等資訊。同時也能區別對方屬於從事哪個分工的階級。如負責餵養蟻后及幼蟲的螞蟻，或是負責搜集食物的螞蟻后會不斷地分泌費洛蒙，這種費洛蒙能抑制工蟻的卵巢發育並讓工蟻知道蟻后還在巢內，一旦以這種氣味消失，有些物種會出現新的蟻后，有些物種的工蟻則會開始產卵，填補蟻后的功能。某些螞蟻用大顎啃咬以攻擊或自衛，山蟻亞科的物種能從腹部末端分泌蟻酸（甲酸），刺激被叮咬的傷口紅腫疼痛；部分物種腹部末端具有螫針。螞蟻亦是全世界力氣最大的昆蟲之一，牠的負重能力相當驚人，能拖動比牠體重還重1400倍的物品，也能背負自身體重註一:警戒費洛蒙分成己醛、己醇、正十一酮和丁基辛酮。己醛會最先出現，提醒工蟻提高警覺；己醇是與酒精(乙醇)類似的物質，會促使工蟻尋找問題來源；正十一酮會吸引工蟻接近問題來源，並在碰到外來物時張口就咬；丁基辛酮最後才會出現，會讓工蟻展開攻擊與咬噬的行動。蠻蟻亞科Agroecomyrmecinae鈍針蟻亞科Amblyoponinae（包含新蟻亞科Apomyrminae）†布朗長蟻亞科†Brownimeciinae異針蟻亞科Heteroponerinae鬥牛犬蟻亞科Myrmeciinae（包含：擬鬥牛犬蟻亞擬家蟻亞科Pseudomyrmecinae†蜂蟻亞科†Sphecomyrminae†幽冥蟻亞科†Haidomyrmecini†阿爾曼蟻亞科†Armaniinae，有些文獻將牠列入蟻科，有些則獨立一科，但無論如何，該亞科都在蟻總科（Formicoidea）之下目前已確定有21亞科283屬，11700種。茲舉幾種以說明:(一)行軍蟻:牠們會一直移居，並且吞食路上遇到的獵物。在移居過程中，1.又名弓背蟻屬或木匠蟻屬，是蟻科山蟻亞科的一個屬。2.牠們不喜歡築巢在乾燥的地方，而巢穴可能建於房屋的橫樑、地板或巢穴中。牠們是雜食性的螞蟻，以食物碎屑或其他昆蟲為食，也會食3.巨山蟻屬的成員眾多，台灣目前本屬有十七種，巨山蟻屬以牠們獨特的習性聞名。牠們會在木材裡挖洞，並以這些通道為生活重心，因為牠們這種特殊的生活習性，所以規模較大的巨山蟻群落會造成房屋結構性毀損，但通常不像白蟻破壞過的那麼嚴重。4.一個成熟的巨山蟻群落一般會有一隻蟻后，許多待孵化的卵，超過兩千隻以上的工蟻，和一個只有工蟻的附屬群落。5.目前發現的蟻后體型最大者為1.91公分。而屋裡的巨山蟻可能是來自主群落或附屬群落，例如：巨山蟻可能來自戶外已枯萎的大樹，陸6.本屬的膨咕巨山蟻跟蜜瓶蟻一樣有貯蜜蟻階級(蜜瓶蟻中的貯蜜蟻又稱蜜缽階級工蟻)它們會收集糖蜜並儲存它們。而在鬧飢荒時，這些貯蜜蟻就派上用場了:牠們會把這些花蜜回哺給同伴食用。7.被巨山蟻在裡面築巢的木材會有木屑遺落在附近，而被白蟻破壞過的木材則會有含泥類物質，當發現附近有上述的木屑(通常會包含已死亡的螞蟻和部分被巨山蟻吃掉的昆蟲殘骸)，就代表附近可能有巨山蟻的巢穴。巨山蟻喜歡築巢在較潮濕的木頭中。(三)針蟻:這種螞蟻包含世界最大的螞蟻:巨人恐針蟻。牠們是少數沒有蟻后的螞蟻，交配過的工蟻會取代蟻后，可以透過解剖牠(四)蜜瓶蟻:牠們的部分大型工蟻會吸飽蜜，在鬧飢荒的時候回吐花蜜，因此被稱為蜜缽階級工蟻。牠們也是澳洲居民的美食，澳洲居民會從牠們的屁股吸取花蜜，但是被人類吸食的蜜瓶蟻也會因為人類破壞式的取(五)火蟻:火蟻屬中有惡名昭彰的入侵紅火蟻，但是火蟻屬中，在台灣已發現1.獵食紅火蟻：生活在森林邊緣，都市綠地、海邊、草地、農地等。在石頭下或土中常常可以發現牠們的蟻巢。牠們是多后制體系的螞蟻，成熟蟻巢由數隻具生殖能力的蟻后和數百隻工蟻組成。牠們分布在台灣中低海拔地區，牠們的食性是雜食偏素食性，主要食物是花蜜、蜜腺分泌和小型昆蟲屍體。牠們除了。會讓工蟻組成小組出外覓食，還會用蟻賊的方式，偷取附近蟻巢的資源。目前未發現有2.知本火蟻：牠們是一種分布在廣西、湖南、湖北天堂寨和台灣。牠們跟原生於南美洲、中美洲、墨西哥和部分美國南部地區的切葉蟻有親戚關係。牠們原生於美洲的熱帶與亞熱帶地區，後來隨著交通工具入侵印度、非洲、太平洋島嶼等地區。牠們攻擊性較強，會出現主動攻擊人畜與莊稼，甚至會咬破電線，破壞供電系統。牠們的毒腺中含有大量生物鹼，叮咬人時會造成劇烈疼痛。會危害當地的農林業生產、人體健康、公共安全及生態環境。3.入侵紅火蟻：牠們的英文簡稱為RIFA，是Redimportedfireant的縮寫，原分布在巴拉那河流域，由於生活在河邊，所以發展出「蟻筏」，也就是讓工蟻互相咬住對方，變成一個蟻筏，並且把蟻后、卵、幼蟲及蛹放在上面，載牠們渡河。由於牠們體表防水，所以不會淹死。紅火蟻在二十世紀初入侵美國南部，造成美國十二個州超過一億公畝(一百億平方公尺)被入侵紅火蟻佔領，每年損失約數十億美元以上。且目前未發現能夠有效防治入侵紅火蟻的生物。火蟻屬成員的毒液大多含有大量生物鹼，叮咬人時會產生如火燒般的劇痛，這也是牠們被取名為「火蟻」的原因。紅火蟻的成熟群落約有二十萬隻至五十萬隻，所以入侵者往往會被大量的火蟻叮咬。被火蟻叮咬後，大部分的人除了會感到劇痛，還會產生水泡，若把它抓破，則會造成二次性的感染。少部分的人甚至會產生嚴重的過螞蟻是靠氣味溝通的。所以蟻客就是掌握了螞蟻的費洛蒙，才能滲透進蟻巢。有些蟻客寄生在蟻巢內純粹是為了尋求庇護，如寄生家蟻；有些蟻客則是為了取得食物，如:黑隱翅蟲的幼蟲會寄生在蟻巢內，並吞食正牌的螞蟻幼蟲。牠們沒有消滅整個蟻巢，是因為牠們也會自相殘殺。甚至有一種蜘蛛會偽有些植物也跟螞蟻有共生關係。如:有一種植物會分泌蜜露，供螞蟻食用，和讓螞蟻築巢在裡面。而螞蟻則會趕走要吃牠們的動物，並且清除雜草。而這有助於植物生長。形成互利共生的關係。螞蟻可以簡單分為頭胸腹三部分，但是更細微的部分呢?以下是我從網路抓(KahootQ&A、google問卷編1.前測問卷發放-小學生的螞蟻知識知多少?(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題2.螞蟻習性觀察:我透過飼養高雄巨山蟻、希氏巨山蟻，以及臭巨山蟻來更了解螞蟻的日常習性，並藉此驗證我所查到的文獻內容是否正3.校內演講:螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻4.後測問卷發放-我了解舉辦一場專題講座是否能夠讓同學更懂螞蟻，所以我在專題講座後請參語的同學幫我填寫回饋問卷，也給我一些一、前測問卷分析-小學生的螞蟻知識知多少?我為了想要了解小學生對螞蟻的認識，因此特地發了這份問卷，並請高年級的電腦老師鍾佑聆老師於電腦課的時候花幾分鐘的時間請大家填寫。下表顯示我於二零二零年十二月二十一日所發出，並於二零二零年十二月三十日回收的問卷共527筆的結果如下，請詳細閱讀。由此表可知，在527人中，有480個人回答了正確答案(正確答案:六隻腳)，21人回答螞蟻有四隻腳，26人回答螞蟻有八隻腳。難度:低由此表可知，在527人中，有491個人回答了正確答案(正確答案:蟻后)，6個人回答兵蟻，9個人回答雄蟻，17個人回答工蟻。難度:低由此表可知，在527人中，有十三人回答蟻后、四百八十一人回答工蟻、四十人回答雄蟻及一百八十二人回答兵蟻(正確答案:工蟻和兵蟻)。難度:低由此表可知，在527人中，有475個人回答了正確答案(正確答案:兵蟻)，7人回答蟻后，36人回答工蟻，8人回答雄蟻。難度:低由此表可知，在527人中，有489個人回答了正確答案(正確答案:雄蟻)，5人回答兵蟻，14人回答蟻后，19人回答工蟻。難度:低由此表可知，在525人中，有192個人回答了正確答案(正確答案:亞全山蟻)，125人回答狂蟻(小黑蟻)，53人回答亞絲山蟻，154人回答都不是。難度:高由此表可知，在523人中，有168個人回答了正確答案(正確答案:亞絲山蟻)，170人回答狂蟻(小黑蟻)，99人回答都不是，85人回答亞全山蟻。難度:高由此表可知，在523人中，有317個人回答了正確答案(正確答案:蜜瓶蟻)，78人回答狂蟻(小黑蟻)，43人回答亞絲山蟻，84人回答都不是，難度:中由此表可知，在523人中，有211個人回答了正確答案(正確答案:火家蟻)，130人回答黃瘋蟻，35人回答蜜瓶蟻，83人回答都不是，63人回答白霜前琉璃由此表可知，在523人中，有110人回答了正確答案(正確答案:蜈蚣)，67人回答青蛙，154人回答都不是，120人回答蜘蛛，72人回答蠍子。難度:高由此表可知，在523人中，有181個人回答了正確答案(正確答案:不是)，342由此表可知，在518人中，有179人回答了正確答案(正確答案:黃瘋蟻)，196人回答白霜前琉璃蟻，62人回答蜜瓶蟻，83人回答狂蟻。難度:高由此表可知，在518人中，有324人回答了正確答案(正確答案:鋸針蟻)，61人回答黃瘋蟻，100人回答狂蟻，33人回答蜜瓶蟻。難度:中1.螞蟻遇到石膏粉與滑石粉時，會因為摩擦力降低而無法爬上斜坡。2.不同種或同種不同窩的螞蟻在相遇時有可能會打起來，也可能會互相忽略，但是在其中一方確定自己有百分之百的勝算時，便會征服另一個群落。(三)專題講座後的搶答活動:後測kahoot問答:螞蟻冷知識知多少?在我進行完螞蟻專題講座後，我用kahoot進行機智問答。以下是我的題1.螞蟻有幾隻腳(選項:四隻腳、六隻腳、八隻腳、十隻腳)2.一般來說，什麼螞蟻會產卵(選項:雄蟻、蟻后、工蟻、兵蟻)3.請問何種螞蟻是由非受精卵孵化而成?(選項:工蟻、蟻后、雄蟻、兵4.以下何者是「蟻客」?(選項:獨角仙、鍬形蟲、黑隱翅蟲(幼蟲)、蟑5.下列何者會捕食螞蟻(選項:草齡幼蟲、蝴蝶、蜜蜂、以上皆非)6.下列敘述何者正確?(選項:螞蟻為群落服務並不為任何好處、所有的螞蟻都具有兵蟻階級、螞蟻群都是雜食性的昆蟲、螞蟻是一種真社會7.螞蟻的一生為何?(選項:卵-幼蟲-蛹-成蟲、卵-若蟲-成蟲、卵-若蟲8.古代有一種「蚳醢」，為帝王食補。請問蚳醢為下列何者?(選項:螞9.螞蟻和下列何者有親戚關係?(選項:蟑螂、白蟻、螳螂、胡蜂)10.白蟻和下列何者有親戚關係?選項:蟑螂、獨角仙、天蛾、胡蜂)11.請問螞蟻透過甚麼溝通?(選項:費洛蒙、聲音、震動、以上皆是)12.請問下列何種螞蟻會使用蟻酸攻擊?(選項:蠻蟻亞科、家蟻亞科、此為我於民國一一○年三月三十號螞蟻講座後發出的滿意度調查問卷:由此表可知，有四個人對於我在台上的表現給三分、二個人給我四分、五個人由此表可知，有四個人對於我在台上的表現給三分、三個人給我四分、四個人由此表可知，有十一個人在這次專題演講後，對於螞蟻知識有更深的了解、零由此表可知，有七個人在這次專題演講後，不會想要進一步了解螞蟻的相關知識或主動閱讀相關書籍、四個人會想要進一步了解螞蟻的相關知識或主動閱讀此為我對同學們發出的專題講座滿意度調查問卷:簡報得稍微有點多，我還沒看完就換下一頁。可以講得再慢一點搶答部分應先設定好平板、電腦，以免讓大家等太久由此表可知，有六個人認為不用改進、兩個人認為可以先把平板和電腦設定好、一個人認為我講太快了、一個人認為簡報上面的字有點多、一個人認為簡根據我發出的表格，有五題難度為低，三題難度為中，五題難度為高，平均難度為中。卻有很多題目連一半的答對率都不到，我覺得是因為我的問卷題目太刁鑽而且太難。下次可以考慮把題目的難度降低且不要出那麼刁鑽，會更我將研究結果統一整理成一個表格，來表達我的結果與討論，還有結論與此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側問答的結果、結論和建議製作的表格:一、維基百科https://reurl.cc/6yV2xO二、超罕見的詭異螞蟻！澳洲原住民最愛的甜食「蜜罐蟻」，號稱行走食物櫃https://reurl.cc/R1Dao6三、臺灣生命大百科:獵食火家蟻https://reurl.cc/7oLnKN四、知本火蟻https://reurl.cc/r84Ga4五、認識火蟻https://reurl.cc/e87lGb六、巨山蟻屬https://reurl.cc/Q3xlpZ七、下課花路米第749集-小小螞蟻大世界(上)https://reurl.cc/VXVoW6八、下課花路米第750集-小小螞蟻大世界(下)https://reurl.cc/OqWom9九、下課花路米第1181集-台灣還有紅火蟻?https://reurl.cc/odG3K3十、流言追追追第51集-螞蟻剋星https://reurl.cc/9X8A5j流言追追追第4集https://reurl.cc/KjZg3e螞蟻的構造https://reurl.cc/pmndVZ螞蟻亞科列表https://reurl.cc/5ox9qv"}, "1676210732.0940633": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306984126397040076_1676210426716為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210774.983037": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306984126397040076_1676210426716為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210785.403142": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36308127470250942248_1676210083761為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676210977.3826022": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery363013002200944701103_1676210963929為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676211205.6049662": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36307282536263739197_1676211194201為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676211373.044206": {"單位": "", "標題": "(ㄧ)、研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36306122693278001712_1676211361329為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制：由於我們的基礎架構為基於文章檢索(DocumentRetrieving)來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當Distractor預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣本研究計畫將以三年為期，共八項研究議題進行，各研究產出如上文所示，並整合各技術成為一選擇題自動生成系統，預期的展示情境為：我們可於系統直接輸入一知識範圍，系統將利用我們所開發之技術先進行自動關鍵語萃取，而後進行各種類型的選擇題出題並考量題組關聯性。我們也將彙整各研究議題中所發展之技術為一個成為公開原始碼專案，以為後續相關研究之用。並將計畫執行過程所累積的資料，公開希望能吸引更多研究者之投入。對於學術研究、國家發展及其他應用方面預期之貢獻自然語言生成已是未來深度學習領域之熱門研究重點。透過本研究計畫之投入我們將可進行先驅之探索，建立學生團隊與自然語言處理與生成之能力，並持續過去之閱讀測驗自動出題研究成果，以知識類型選擇題自動出題為主要系統開發目標為例，希冀能為國內外探索不同的自然語言生成應用服務。此外若可順利完成也可以成為一成功範例利用人工智慧輔助教師進行測驗的客製化與個人化學習。對比於題庫類型的方式，透過我們技術我們將可動態產生各式各樣不同之考題為每個人量身定做難度適中之考題。就此一觀點出發，我們預期本計畫除學術研究價值外，同時也兼具商業價值，也應可成為EdTech(教育科技)領域之一環。再者，疫情改變了學習與教學的模式。同步與非同步之線上教學已成為教學模式常態之一。線上教學帶來了好處，但也帶來了顧慮。其中，學習的專注度應是諸多顧慮中主要令人擔憂的一環。隔著螢幕學生學習是否專注？目前的教學內容學生是否已跟上進度？等等問題是線上教學學習專注度所在意的問題。對此，我們認為適時與即時地檢測學生學習成效，來提醒學生與教師目前之學習成效，應能適度緩解線上學習專注度之顧慮。因此，我們也常見於MOOCs課程於一個授課單元結束後適時地給予測驗(多數以選擇題測驗)，來確認學生學習成效。然而，人工設計試題耗費心力，一成不變全班同學皆相同試題也可能透過即時訊息(instantmessage)之分享而取得答案，造成檢測之無效。對此，我們認為隨著深度學習技術之快速演進，結合自然語言(NaturalLanguageGeneration)生成技術來進行自動出題技術已成為可能；透過自然語言生成技術自動化出題，產生多樣化的試題，來進行個人化的檢測，將有除了可以增進研讀論文、撰寫程式、架設系統以及撰寫論文的基本能力之外，參與本計畫之研究人員，將可以學習到深度學習與自然語言生成技術之基本觀念、實際應用以及相關的核心技術，在這些基礎之下，透過積極的研究與討論，將可以提升參與計畫人員思考問題與解決困難的重要能力。我們預期可獲得具體技能如下:(1)設計與建立一個深度學習模型之能力，(2)整合不同先進技術之能力，(3)自然語言生成技術之瞭解，(4)資訊檢索相關知識與軟體套件之暸解，(5)佈建深度學習模型於WebScale之能力。"}, "1676211401.714697": {"單位": "", "標題": "1324234", "作者": "", "發布日": 0, "摘要": "", "全文": "rhbsrhwsrh:ndgsnsegnan"}, "1676211422.082183": {"單位": "", "標題": "1121121", "作者": "", "發布日": 0, "摘要": "", "全文": "'rgbwrgwgwgw:rsgvsvr"}, "1676211498.0740092": {"單位": "", "標題": "研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。我們預期的展示情境為：給定一知識範圍(如農業文集)，我們可於系統直接輸入一組主題關鍵詞，而後自動生成關於該主題相關之選擇題題組(含字詞等級、句子等級、挑選是非類型之選擇題)。然而，如同前言背景中所言，現有技術離目標仍有許多待強化之處，對此我們擬定三大出題目標：字詞等級干擾選項、句子等級干擾選項與反事實干擾選項進行研究。針對此三大目標，我們擬定(1)基於知識圖譜之強化與(2)基於生成語言模型與對比學習之強化三個核心技術進行探討。研究技術項目與項目間之關係與進行規劃如Figure7所示。於第一年度中，我們規劃「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」、「基於語言模型與知識圖譜之Text2Text干擾選項生成」與「基於Masked-LM之反事實干擾選項生成研究」進行研究。「考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化」著眼於優化目前https://mcq-demo.nlpnchu.org之WordLevel之選擇題生成系統。希冀自動過濾相似或語意不正確題幹，並且考量干擾選項彼此間之關聯進行最終干擾選項集合之綜合挑選。「基於生成語言模型之Text2Text干擾選項生成模型」則考量Text2Text模式利用生成模型直接生成干擾選項序列，藉此嘗試生成句子等級之干擾選項。並進一步地探索結合知識圖譜與語言模型之干擾選項生成，希冀透過知識圖譜之整合來生成更有誘導性且合理之字詞等級干擾選項。此外，於「基於Masked-LM之反事實干擾選項生成研究」項目中，我們預計著手挑戰反事實干擾選項生成，我們嘗試利用透過NER擷取給定事實陳述句中之關鍵字並Masked-LM該關鍵字來填入機率較低之字詞，以為反事實語句生成之作法。我們預期第一年度工作完成後，將可優化現有單詞等級干擾選項之選擇題自動生成系統，並於第二年度中，我們則規劃「基於知識圖譜強化之反事實干擾選項生成」、「基於對比式學習之干擾選項生成模型強化」與「利用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選」。於此年度中，進一步嘗試利用知識圖譜萃取三元組知識後進行反事實語句之生成，基本想法為透過萃取三元組後再進一步輸入語言模型，並希望語言模型適當地進行反事實語句的改寫。此一部分預計使用第一年度之「基於Masked-LM之反事實干擾選項生成研究」之基礎以為訓練資料。對於字詞等級的干擾選項，我們則探索利用Open-DomainQuestionAnswering模型所錯誤回報之答案當作干擾選項。我們希望透過此不同之想法來取得更多樣的干擾選項。再者，如前言所述，生成模型生成序列時常出現生成結果重複的狀況，對此我們嘗試利用對比式來改善生成模型這方面的缺點，以優化干擾選項之生成。第二年度工作項目完成後，我們可初步提供反事實干擾選項之選擇題生成、優化後之句子等級干擾選項生成與基於ODQA方式取得之字詞等級干擾選項生成。於第三年度中，我們則規劃「基於NodeCentrality考量主題涵蓋性之選擇題題組生成」與「生成難度可控之干擾選項生成研究」。如同前言所述，一個理想的選擇題出題系統應該考慮題組生成，整體題目之主題涵蓋性，對此我們也將嘗試基於知識圖譜涵蓋的方式考慮節點centrality重要度方式來進行題組之生成。同時我們也將嘗試題目難易度之控制生成研究。我們的想法是當自動生成成為可能後未來的出題應該是個人化模式；針對個人的學習狀況進行測驗，因此我們規劃「個人化與生成難度可控之干擾選項生成研究」進行探討。第三年度，我們也預計投入人力進行系統的實作開發與整合。以下茲針對擬訂之研究議題其問題挑戰與1.基於語言模型與知識圖譜之Text2Text干擾選項生成模型近年來，語言模型除了使用CandicateGeneratingandRanking架構的MaskedLM之外，使用Encoder-Decoder架構的Text2Text模型於生成任務上也有很好的成果，因此我們的想法是把干擾選項生成Model視為一個Text2Text任務，嘗試讓模型直接生成干擾選項。且使用Text2Text模型生成Distractor有別於用MaskedLM生成Distractor，我們希望模型能生成的Distractor有以下特性(1)非單詞之Distractor:目前在Distractor生成上多為單詞生成，要生成一段敘述/句子的干擾選項還沒有很好的做法。(2)特定domain之MCQ:目前的MCQ多為英文測驗，若想針對特定領域出選擇題，使用MaskedLM生成的Distractor會因語料庫限制而為達到上述的兩種目標需求，我們設Q為輸入之問句，A為輸入問句之答案，並將Q與A字串接字串當作輸入，訓練模型輸出一連串問句Q的干擾選項字串D=(d1,d2,d3)。模型架構如圖2所示，我們將「哪一種技術最適用於嚴重特殊傳染性肺炎之病原快速篩檢?」與「聚合￿連鎖反應」接在一起輸入至Text2Text模型，而模型生成了「重組DNA技術」、「電腦斷層掃描」與「組織培養」三個干擾選項，三個選項皆為醫療檢測方式且都不是單詞，符合如前言所述，我們也預計探索使用知識圖譜來強化生成干擾選項的能力。如Figure8的圖例，我們可以使用語言模型結合醫療知識圖譜，利用給定的文本從知識圖譜中萃取有包含這些topicentities以及相鄰的nodeentities的子圖，再分別將文本與子圖輸入至語言模型和GraphNeuralNetwork(GNN)，讓模型學習找出關鍵的資訊與強化network中重要entitynodes跟edges的權重，藉由GNN的額外資訊與語言模型能力生成更好的選項。Figure8為我們規劃做法的概觀。主要分兩階段進行：(1)關鍵字子圖與GNNEmbedding萃取與(2)GNNEmbedding與LanugageEmbedding間之FusionEncoder生成。具體而言，第一個階段是將從知識圖譜裡萃取相關的知識圖譜子圖。我們一開始先使用NERModel抓取題幹中的entities，再透過這些entities透過知識圖譜去尋找entitynodes以及所有跟entitynodes相鄰3-hop內的bridgenodes，將檢索出來的結果當成知識圖譜子圖，並在後續第二階段提供以Figure9的圖例，我們先將問題透過NERModel斷詞得到”白血病”、”發病”、”器官”與”發病原因”當作entities，再透過這些entities當作關鍵字透過Retriever從知識圖譜萃取Figure8:結合知識圖譜與語言模型生成之構想架構圖與這些詞相關的node和edge，如利用”白血病”與”器官”能找到”肝臟”、”骨髓”、”肺部”等等entities，我們能利用這些entities來當作後續的生成選項。第二個階段則將文本與第一階段得到的知識圖譜子圖分別輸入至語言模型與GNN進行訓練，訓練目標為將Input的[MASK]Token還原來產生干擾選項，先將語言模型的Input額外新增[MASK]Token，經過N層LMLayer做self-attention後，透過FusionEncoder再結合知識圖譜的資訊與原本的文本去生成選項，透過以上的手法，來強化干擾選項之生成。2.考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化如同研究目的所述，本研究項目著眼於優化現有Retrieve-and-Generate生成架構。我們•文章檢索器過濾:在Retrieving-and-Generating方法中Retriever會檢索回傳含有主題字詞的文章，但有部分文章並不適合當作問句生成模型的輸入，那些文章含有太多的雜訊，我們想嘗試在這步驟先過濾一些文章。我們的想法是利用詞向量中的相似詞再次檢索Retriever回傳的文章，把過於不相關的文章濾掉，減少問句生成模型輸出過於複•生成題幹品質自動過濾：問句生成模型輸出的問句，會再交由使用者挑選，但為了更好的效果，我們想嘗試利用語言模型做初步的篩選，減少人工挑選時間。我們想嘗試利用ODQA模型來過濾問句，將問句生成模型輸出的問句輸入至問答模型後，根據問答模型的回答結果與信心分數來決定該問句是否合適當作MCQ。如Figure10所例，我們將生成之問句再次投入ODQA模型，透過答案選項之信心度來為問句生成過濾之基Figure10:Unanswerablequestionsolution•考量干擾選項間關聯之干擾選項挑選:如前言所述，一個可以提升選擇題生成品質￿考量干擾選項彼此之間之難易度。而在Retrieving-and-Generating方法中，生成干擾選項的方式為取出詞向量模型中與主題字詞相似之詞，使用相似度前三名當作干擾選項，因此有選項過於相近而造成問題太難的可能。為做改善，我們取出所有相似詞的向量與主題字詞向量計算相對距離，設定各個選項與答案的相似度範圍(距離範圍)，再從中隨機挑選相似詞，讓干擾選項彼此之間難易度有所區分以提升試題之鑑別度。•基於語言模型之干擾選項候選生成:雖然詞向量模型生成distractor過程迅速，但如果有主題字詞沒有被詞向量模型看過或有主題字詞一字多意，就無法生成適當的干擾選項。這個問題我們想嘗試使用MaskedLM來解決，我們將Retriever回傳的文章中含有主題字詞的段落記錄下來，移除主題字詞後輸入MaskedLM，再從MaskedLM輸出的候選字中選出distractor，使用這個方式生成的干擾選項不會被上述的缺點受限，也更Figure11:OptimizedRetrievingandGeneratingFramework3.基於Masked-LM之反事實干擾選項生成研究本研究項目為基於Masked-LM技巧來生成反事實干擾選項。我們需要先查找與事實相符之敘述，再修改成反事實干擾選項。我們預計之作法為：首先讓使用者先輸入考題關鍵字，再使用retriever查找相關文章，其目的為從相關文章中選取與事實相符之敘述。接著，將retriever檢索到的文章回傳給使用者，由使用者選取與事實相符之敘述。並按照以下之步驟進行Masked-LM反事實干擾選項生成。為了抽換專有名詞，我們先使用命名實體與事實相符之敘述中的所有專有名詞，以下圖為例”腎小管藉壓力差方式再吸收葡萄糖回微血管”，透過命名實體模型會萃取出專透過命名實體模型，我們會萃取出多個與事實相符之敘述中的專有名詞，我們需要選擇一個專有名詞行抽換。我們認為該專有名詞在相關文章中的重要程度越高，越高機率是考題中的重點。為了確保抽換專有名詞的品質，我們使用BM25來查看各個專有Figure12:AutoEncoder模型與AutoRegressive模型做MaskLM3.使用Maskedlanguagemodel模型進行改寫Maskedlanguagemodel，簡稱為MaskLM，該任務的會將輸入中的部分內容遮擋起來，模型會根據其他未被遮擋的內容，預測出被遮擋的內容或與其擁有相似語義的內容，現有的MaskLM模型分為兩種，分別為AutoEncoder框架的MaskLM模型與AutoRe-gressive框架的MaskLM模型，經典模型如BERT與BART。針對MaskLM任務，兩種模型進行預測的方式也有所不同，AutoEncoder框架的模型會預測出字，而AutoRe-gressive框架的模型會預測出字、詞或是句子，詳細範例如Figure12。根據抽換專有名詞的需求，我們將使用Autoregressive模型做MaskLM任務來抽換重要的專有名詞。然而模型預測出的內容眾多，有可能是原先遮擋的內容、遮擋內容的同義詞或是與遮擋內容擁有相似語義的內容。理想的情況下，模型預測的內容最高機率為原先遮擋的內容，若我們選擇原先遮擋的內容或是遮擋內容的同義詞進行抽換，會造成與事實相符之敘述未改變，便無法生成反事實干擾選項。為了避免此狀況發生，我們使用NLI任務中的換句話說(MRPC)任務來檢測其是否為干擾選項。換句話說任務主要在判斷兩句話的語意是否相同，為了避免MaskLM模型選用同義詞進行抽換，即模型生成的干擾選項仍是正確的，我們將與事實相符之敘述與生成之干擾選項作為模型的輸入，若模型認為兩句話具有相同語義，我們會讓MaskLM模型預4.基於知識圖譜強化之反事實干擾選項生成於本研究項目中，我們嘗試利用知識圖譜提供語言模型額外資訊達成反事實干擾選項生成。我們的構想如Figure4所示，包含以下步驟。首先我們會讓使用者先輸入考題內文，再將內文使用斷詞或NER模型萃取entity，利用這些entity於知識圖譜中查找相關子圖，子圖必須包含內文中所有的entitynodes以及所有跟entitynodes相鄰節點，以此為知識生成之基礎。接著我們將檢索到的子圖內的nodes與edges萃取成三元組，每筆三元組的結構是以node,edge,node組成。如同圖中所示，每一筆三元組描述一基本事實陳述，如導體可以3.將與事實相符之敘述修改為反事實干擾選項為了將與事實相符之敘述更改為反事實干擾選項，我們將前一步驟所萃取的三元組與考題內文當作作語言模型的輸入來生成反事實干擾選項。我們預計透過生成語言模型與輸入給定的問句和三元組來生成與問句情境相符合的反事實干擾選項，以FigurejQuery36305983518858060475_1676211393343為例，生成語言模型在給定關於與導體相關的題目敘述以及從知識圖譜萃取與導體相關的三元組後，模型藉由這些三元組推斷其中的關係，比如”導體可以導電->石墨是導體->筆芯是由石墨製成”，從上述的三元組推斷出”筆芯可以導電”的事實，也可以改寫成”筆芯不能導電”的反事實干擾選項。5.使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究如前言所述，我們預計使用ODQA模型所回答之錯誤結果來當作干擾選項(如Figure5)。以我們先前曾開發https://agri.nlpnchu.org/之農業問答系統為例，我們發現以上想法所面臨的挑於ODQA的架構下，可能會遇到ODQA正確回答所下達之問題，其回傳結果皆為可行之答案，也因此無法被使用來當干擾選項，對此，我們探索兩種作法來進行調整。–1.使用BM25，且刪除尋找出來文章的正確答案在使用BM25的情境下，因為是使用關鍵字比對，所以會找出許多跟正確答案相關的文章，我們將找到文章的正確答案刪除，這樣這個文章會變成絕對回答不出正確答案的文章，可是因為Reader對文字有一定的理解能力，並且具有關鍵字的文章中也很可能會有，他會從剩下可能的答案中，尋找一個最相近的選項，這樣就可以較容易生出干擾選項。如Figure13所示，我們將答案”2,4-D”從文章中直接刪除後，再交給Reader進行閱讀，藉此確保正確答案不會被回傳。Figure13:基於ODQA架構之Retriever弱化方法–2.使用DensePassageRetrieverDensePassageRetriever[16]，DensePassageRetriever可以將資料庫的文章轉為向量的方式表示，在搜尋的時候也將Query轉為向量，並且比對兩個向量的相似度，這樣就可以找出相似的文章，可是我們想說，可以利用DPR找尋文章相似度的這一點，理論上相似的文章跟Query算出來的相似度會是最高的，我們可以將相似度高的文章拿出來，並且查看有沒有答案出現在上面，如果沒有答案，我們就將他丟給Reader，因為我們覺得如我相似度高，就代表Retriever認為裡面有答案，可是裡面並沒有含有我們的正解，所以這篇文章就含Retriever認為是答案，但是實際上不是答案的文字，所以這時候我們將這篇文章傳給Reader，就會有比較高在我們使用baseline的情境中，有時候也會出現不相關的答案，例如在??中，問模型關於殺草劑的問題，會出現的人力除草，人力除草跟題目所問的殺草劑名稱是不相關的，所以我們需要用一個方法把他過濾掉。在這種情況下，我們如果加入正確答案當作Query一起輸入Retriever，就會增加模型找到正確passage的機率，對我們想找跟正確答案不相關但是相似度較高的Passage會產生反效果，所以我們採用的是從Reader輸出之後把他過濾掉的方法。當Reader從Retriever拿到Passage之後，我們會將正確答案去除，之後再將剩餘的答案丟入一個LanguageModel作判斷，如果他跟答案的距離過於遙遠，就放入NegativeList，如果是相關的就放入PositiveList，之後要挑相關答案的時候可以從PositiveList裡面挑選。6.基於對比式學習之干擾選項生成模型強化ContrastiveLearning的設計上需要考量如何去設定PositiveSample以及NegativeSample。在我們的目標中，因為不希望模型會重複的生成出相同意思的句子，所以我們預計使用同義的句子當作NegativeSample，而資料集中的干擾選項可以被當作PositiveSample。然而，由於我們的資料集中並沒有NagativeSample的選項，也就是同義於模型生成的選項。對此，我們的想法為透過迭代生成來產生我們需要的NegativeSample。具體而言，如Figure14所舉例，在DistractorGenerator的第一次生成中，我們會輸入Question以及Answer使模型生成出干擾選項。而在第二次迭代中，我們除了會輸入QuestionAnswerPair外，還會再加上在上一次迭代中生成的干擾選項，以提示模型先前已生成的Distractor的資訊。對於第二次迭代的輸出來說，第一次迭代輸出的Distractor，即為它的NegativeSample，因為DistractorGenerator必須要生成出與上一次迭代生成的Distractor意義相異的句子，所以它們之間的SentenceEmbedding不能太過接近。Figure14:IterationGenerater示意，在第一次的迭代中生成的Distractor會作為第二次迭代的輸入，以提示模型不要生成出類似的DistractorFigure15:對比式學習於干擾選項生成之預想架構我們所規劃之整體框架，如Figure15所示。我們使用多次迭代的方式來生成Distractor，對於第一次迭代來說，我們會從其他in-batch的data中取得Sentence當作NegativeSample。而在第二次以後的迭代來說，除了其他in-batch的Sentence以外，我們還會將此次迭代前所生成的Distractor加入我們的NegativeSample中。透過NegativeSample和模型輸出的Distractor的dotproduct可以計算出ContrastiveLoss，此外我們也會加入Distractor和Label計算的CrossEntropyLoss，來計算出我們的TotalLoss15。ContrastiveLoss定義如下:x為生成的distractor，p為資料集中的Distractor(Label)，N為NegativeSampleSet，N={n1,n2,...nj}，其中包括先前迭代生成的Distractor以及其他in-batch的選項。7.基於NodeCentrality考量主題涵蓋性之選擇題題組生成如同前言所述，本研究議題之目標為考量主題涵蓋性之選擇題題組生成。因此，我們預計根據使用者所指定的主題，按Figure16架構規劃來進行題組生成。1.透過知識圖譜子圖萃取來涵蓋所指定主題之內容：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。我們的基本想法為在知識圖譜上我們定位出與使用者輸入之主題關鍵字相關之結點後，我們可以試者套入PageRank或者其他圖形上計算NodeCentrality重要節點挑選，並以重要節點為題幹生成之主軸。2.透過上一步取得之重要答案片段後，進行問題之生成。並生成較多的問題數量以為CandidateQuestionPool，而後將問題將題組生成問題設定一成為一選擇最佳化議題(Optimization)：根據主題生成大量的單一題目，而後定義UtilityScore來計算個別題目組合後之優劣，來挑選最佳化的題組以為輸出。於本研究項目中，我們預計探索以下兩種生成難度控制方式。•調整Masked-LM比例之反事實選項難度控制：現有的Masked-LM模型會將重要的專有名詞進行遮擋，模型會透過未遮擋的內容對該專有名詞進行預測。理想的情況下，當我們僅對該專有名詞進行遮擋時，模型可成功地預測出遮擋的專有名詞或語義相近的專有名詞，這不僅是因為MaskLM模型夠強大，也是因為未遮擋的內容提供模型足夠多的資訊讓模型預測，若未遮擋的內容提供的資訊不夠多，則模型預測出的內容有可能會與遮擋的內容語義相差很多。我們根據Masked-LM模型的此特性對題目的難易度進行控制，若我們將多個專有名詞進行遮擋，再讓模型預測時，模型會因為提供的資訊不足，而預測出語義較不相近的專有名詞，即較不可能的答案。以下表為例，我們可以觀察到當[Mask]越多時，我們要判斷該事實是否正確就越形容易。[Mask]借壓力差吸收[Mask]回微血管[Mask]借壓力差吸收[Mask]回[Mask]•調整ODQA檢索文章之難度控制："}, "1676211510.5607574": {"單位": "", "標題": "研究計畫之背景與目的", "作者": "", "發布日": 0, "摘要": "", "全文": "自然語言生成(NaturalLanguageGeneration)將是未來深度學習領域之熱門研究議題。2022年年末ChatGPT語言模型所帶來的示範性與展示效果預期將吸引更多研究目光。而個人於中興大學之研究團隊近年於自然語言生成之耕耘已建立初步研究成果。在過去朝著自然語言生成方向前進，我們探索自動生成試題之研究方向前進。於前期研究計畫「基於深度學習語言模型之閱讀測驗自動化生成研究109-2221-E-005-058-MY3」中，我們著眼於基於深度學習模型進行閱讀測驗(ReadingComprehensionTesting)題型之自動出題。在計畫執行過程中，我們•Ying-HongChan,Yao-ChungFan:KeywordProvisionQuestionGenerationforFacilitatingEducationalReadingComprehensionPreparation.INLG(InternationalNaturalLanguageGen-erationConference)2022.•Ho-LamChung,Ying-HongChan,Yao-ChungFan:ABERT-basedDistractorGenerationSchemewithMulti-taskingandNegativeAnswerTrainingStrategies.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2020.•Shang-HsuanChiang,Ssu-ChengWang,Yao-ChungFan:CDGP:AutomaticClozeDistractorGenerationbasedonPre-trainedLanguageModel.EMNLP(EmpiricalMethodsinNaturalLanguageProcessing)Findings2022.•Hsien-YungPeng,Ho-LamChung,Ying-HongChan,Yao-ChungFan:MisleadingInferenceGenerationviaProximalPolicyOptimization.PAKDD(AdvancesinKnowledgeDiscoveryandDataMining-26thPacific-AsiaConference)2022此外我們也將前期計畫之自動出題研究成果進行實作，可於以下兩個網址進行實測。•問句生成QuestionGeneration：給定文章、指定片段，透過自然語言生成模型進行問句生成。目前系統可於https://classic.queratorai.com/進行實測。•克漏字干擾選項生成DistractorGeneration：此一部分針對給定之文章進行克漏字誘導選項生成。目前系統可於：https://cdgp-demo.nlpnchu.org/進行實測。基於過去之研究成果累積，本計劃延續自然語言生成技術於自動出題之研究成果，擬定知識類型選擇題(MultipleChoiceQuestion,MCQ)自動生成為目標。以四技二專統一測驗考試為例(如Table2所示)，知識類型選擇題將包含題幹與四個選項(其中包含正確答案與干擾選項)，主要針對某一知識範圍進行測驗。我們認為知識範圍選擇題之自動生成可分為兩部分：(1)問題題幹(Stem)生成與(2)干擾選項(Distractor)生成。題幹生成主要目標為選擇題問題本身之生成，而干擾選項則著眼於誘導選項之生成。知識類型選擇題為學習測驗最常見的測驗模式之一。對比於閱讀測驗生成，知識類型選擇題的自動生成，將可減輕教師準備個人化教學測驗之負擔，也為學生提供更有效率之學習檢測方式。以現有我們成果為基礎，一個基本之自動選擇題出題系統作法為(如圖1)所示：我們可利用資訊檢索技術(如BM25Retriever)，從給定之文集資料庫(目前使用2021中文維基百科所有中文文章)中檢索主題字詞相關文章後，結合前期計畫所開發之問句生成模型(QuestionGeneration)[4]生成題幹，而後再利用詞向量模型(例如word2vec模型)找出相近字詞以為干擾選項。我們將這樣的構想先行實作一系統(稱之為Retrieve-and-GeneratePipeline)，目前此系統可於https://mcq-demo.nlpnchu.org/使用。使用者可藉由輸入主題相關字詞，選擇題生成系統將自動生成輸入字詞相關之選擇題結果。舉例而言，我們以「骨髓、白血病、淋巴」為主題字詞輸入至系統。我們挑選較佳之成果顯示於Table1。自動生成選擇題AutomaticGeneratedMCQQ1:哪一種癌症種類的統稱中可以看出它會造成不正常白血球的大量增生?(a)白血病、(b)乳腺癌、(c)腎病、(d)帕金森氏症Q1:白血病的發病原因通常是發生在哪一個器官上?(a)肝臟、(b)淋巴、(c)甲狀腺、(d)骨髓Q:白血病是最常見的兒童癌症，其中80%的病例是慢性的哪一種性病變?(a)淋巴結、(b)微血管、(c)淋巴、(d)黏膜Table1:目前選擇題自動生成結果範例。目前系統可於https://mcq-demo.nlpnchu.org/。目前我們挑選較佳之生成結果顯示於此Table中。建議審查委員自行輸入關鍵字詞組，來觀察我們Figure1:Retrieve-and-Generate基本架構。本例中我們以”骨髓、白血病、淋巴”為關鍵詞進行文章檢索，而再使用”骨髓”為答案，分別生成問句與干擾選項。從展示之結果中，我們發現自動選擇題出題之可能性。但仔細觀察會發現現有系統離實際應用仍有空間須待努力。也因此觸發本期研究計畫之提出。具體而言，我們認為選擇題自•句子等級之干擾選項生成(Sentence-LevelDistractorGeneration)首先，關於干擾選項的部分，若仰賴詞向量模型來產生干擾選項，我們所能取得的干擾選項便僅限於單詞(Word-Level)等級。從統測試題中，我們發現許多題目之干擾選項屬於句子等級(Sentence-Level)。以Table2中Q3與Q4選擇題為例，我們可以看到選項皆為句子等級之描述，此為目前基於詞向量來產生干擾選項的做法所不能。•反事實干擾選項生成(Counter-FactualSentenceGeneration)我們觀察到選擇題題型中，有著下列何者為錯誤或正確類型之考題。其干擾選項是一個較長的描述句。以Table2為例，Q5與Q6為分別詢問下列選項何者正確/錯誤。此題型，為變像之是非題。除了句子等級生成外，核心技術牽涉的是反事實(Counter-Factual)句子之生成。如何生成此類型之句子以為干擾選項也將是研究重點所在。•選擇題生成品質提升(MCQQuestionQualityImprovement)此外，我們也看到retreive-and-generatepipeline的做法，所產生的題幹本身有時是一個過於空泛之問題(例如，下列何種疾病為兒童常見之癌症？)或者並非語意正確之語句(例如，中樞性的什麼症狀是缺乏抗利尿激素的?)。如何有效判斷生成不良之語句，減低人工進一步過濾/挑選題目之負擔也是需進行研究之議題。此外，基於詞向量之干擾選項作法也有待商榷;隨機從相近詞向量挑選distractor，是否能確保distractor之誘導品類型I:單詞等級的干擾選項Word-LevelDistractorsQ1：淋巴器官是人體防禦系統中重要的一環，可提供淋巴細胞發育或活化所需要的條件與狀態。下列何者是淋巴球進行防禦與活化的器官？(a)骨髓(b)胸腺(c)肝臟(d)脾臟Q2：健康人體感覺神經傳入大腦的訊息大部分經過轉接，(a)視丘(b)下視丘(c)中腦(d)橋腦類型II:句子等級的干擾選項Sentence-LevelDistractors(a)無就巢性(b)體型大(c)著肉多(d)耐粗食Q4：下列何者為「聯合國國際糧農組織」(FAO)成立最重要的目標及首要任務？(a)消除及戰勝飢餓(b)聯絡及交流農業資訊(c)自然環境的永續及保護(d)實現國際間的公平貿易類型III:句子等級且與事實相違背的干擾選項Counter-FactualDistractorsQ5：有關人類上皮細胞的細胞週期之敘述，下列何者正確？(c)後期，分離的染色分體往細胞中央移動(d)末期，細胞膜內凹且細胞質開始一分為二Q6：有關一健康成人泌尿系統功能的敘述，下列何者錯誤？(a)腎臟每日約產生濾液180公升及尿液1.5公升(b)腎小管藉壓力差方式再吸收葡萄糖回微血管(c)腎臟藉排尿量多寡來維持體內水分的恆定(d)若出現尿毒症狀時，可使用血液透析方式進行治療Table2:四技二專統一測驗選擇題類型概觀。Q1與Q2擷取自110學年度護理基礎生物考科，Q3與Q4110學年度農業群農業概論考科，Q5與Q6取自110學年度農業群基礎生物考科質？也許所挑選的distractor並不具誘導性，使得受測者很輕易地可挑選出正確答案，或者挑選到答案的同義詞，造成一題有多個正確答案。根據先前計畫執行訪談教師所知，於測驗時為考量受測全體鑑別度，教師出題時會考量干擾選項彼此之間之難易度；通常三個干擾選項中，會有一個離正確答案較遠之干擾選項(誘導性較低)，一個次之，一個最為困難最具有誘導性。藉此來有適當的鑑別度。目前我們直接使用詞向量之作法並未考量此設計。•主題題組生成(MCQQuestionGroupGeneration)目前我們的系統僅為單一關鍵字詞之出題。我們認為一個良好的自動出題應該是以題組為單位進行出題；使用者指定一主題知識，系統根據此一主題知識範圍進行5-10題之選擇題自動生成，題目之間也應該彼此考量。目前Retreive-and-Generatepipeline的做法，我們使用使用者給定的關鍵字為答案，進行題目之生成。然而比較好的做法應為將使用者給定的關鍵字集合為知識範圍之指定，系統根據該範圍自動挑選重要概念關鍵字進行答案挑選，而後再進行選擇題題組之生成。針對上述之研究挑戰，於本研究規劃中我們擬定下列八項研究議題進行探討。•研究項目ㄧ：基於語言模型與知識圖譜之Text2Text干擾選項生成模型(DistractorGenerationbasedonText2TextLanguageModelandKnowledgeGraph)Figure2:Text2Text干擾選項生成架構Figure3:基於Masked-LM之反事實干擾選項現有之Distractor生成研究多是基於CandicateGenerating-and-Ranking架構，先透過知識庫(如Wordnet)或者透過MaskedLM的方式取得候選字後，再適當進行候選詞特徵排序以為最終干擾選項。對此我們有不同之想法，我們預計嘗試把干擾選項生成設定為一個Text2Text任務；如圖2所例，預期的輸入為題幹Q與答案A之串接字串，透過ModelEncoder與Decoder轉化輸出為一連串之干擾選項字串“重組DNA技術[SEP]電腦斷層掃描[SEP]組織培養”。我們透過語言生成模型直接將輸入對比轉換為輸出。此外，透過此一Text2Text方式，生成句子等級的干擾選項也將為可能。再者，近年來語言模型研究趨勢除了將模型參數量與訓練資料持續增加外，引入知識圖譜來強化生成模型於常識理解與推理能力也成為研究社群的關注所在[5][13]。也因此，探索整合知識圖譜於選擇題自動生成也因此成為我們規劃之研究項目。希冀藉由整合知識圖譜來提升干擾選項之誘導性與題幹生成之正確性。•研究項目二：基於Masked-LM之反事實干擾選項生成研究(Counter-FactualSentenceGenerationbasedonMasked-LM)如同前言所述，“下列何者正確/錯誤”題目為常見之類型選擇題題型。對此，我們預計嘗試以下之作法。首先，我們假定可取得正確敘述之語句S。我們先針對語句S中的字詞進行命名實體辨識(NamedEntityRecognition,NER)，其後再利用語言模型針對所取得之命名實體進行WholeWordMasking(WWM)，填入機率較低之填空結果，藉此生成反事實描述之語句。如Figure4所例，我們將所給定之事實描述，藉由NER方式挑選”葡萄糖”一次進行Masked，再藉由語言模型推測該Masked字詞，並挑選機率相對較低之預測填入。藉此創造出反事實之陳述句。然而，如何確保不挑選到同義詞？要進行多少個字詞之Masked？如何自動從主題文章中挑選事實陳述句以進行改寫？等等•研究項目三：基於知識圖譜強化之反事實干擾選項生成(Counter-FactualSentenceGen-erationbasedonKnowledge-GraphAugmentedLanguageModel)針對反事實干擾選項生成之議題，除了研究項目二之Masked-LM作法外，我們另一個構想為利用知識圖譜來強化Counter-Factual語句之生成。如Figure4所示，我們基本想法為先萃取與題幹相關聯之知識圖譜子圖(LocalSubgraph)並取得知識三元組，以此輸入至語言模型中，訓練語言模型反向改寫三元組語句，以此為反事實干擾選項。然而，此模式之訓練資料該如何取得？如何從知識圖譜上萃取子圖，並生成合適三元組？如何引入GraphNeuralNetwork來萃取結構？為此研究項目需進行探討之工作內容。•研究項目四：基於對比式學習之干擾選項生成模型強化(DistractorGenerationModelbasedonContrastiveLearning)我們過去的研究經驗[8]與相關研究[35]皆指出當使用Generative語言模型來生成句子Figure4:基於知識圖譜強化之反事實干擾選項生成構想層級之輸出時，模型經常會產生語意之相同，但字面的結果。如Table3所示，選項A跟C雖然字面敘述上不同，但實際上都是描述同樣的意思。生成重複選項將導致選擇副交感神經興奮會導致使心跳加速，血壓上升Table3:模型生成的誤導選項重複出現的範例對此，我們預計探索對比式學習(ContrastiveLearning)[7][35]來提升生成品質。對比式學習於自然語言之應用中主要想法為透過選取PositiveSample以及NegativSample使得模型去學習到生成句子跟同義句子的相同以及跟異類句子的不同之處，這樣我們可以使用重複選項當作我們的NegativeSample，然後資料集中的干擾選項當作PostiveSample，期望模型可以學習避免生成出重複的誤導選項。因此，我們預計探索對比式•研究項目五：使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究(Us-ingIncorrectAnswersfromODQAasDistractors)而除了利用生成模型產生Distractors外，我們發現利用Open-DomainQuestionAnswer-ing(ODQA)模型所產生的錯誤結果是一個值得探討的干擾選項的取得方式。具體而言，現有的ODQA模型主要包含一個Retriever與一個Reader，Retriever負責檢索相關的文章，而Reader利用檢索出來的文章利用閱讀理解模型(ReadingComprehensionModel)來找尋答案片段。由於ODQA並非完美，因此也會有錯誤結果之回報。但我們發現錯誤結果與正確答案並非天差地遠，閱讀理解模型所回報之結果通常也與答案接以圖5為例，當我們下達Q：「下列何者為目前世界上應用最廣的殺草劑，其具備有生長素之特性，常用於闊葉雜草防治，亦為選擇性殺草劑的一種？」，ODQA系統將取得圖5中右半部之答案：「萌前除草劑、2,4-D、非選擇性除草劑、10殺丹粒劑」。其中，2,4-D為正確答案，餘者為錯誤答案。然而我們覺得這些錯誤答案，可以當作Q之干擾選項來使用。有別於基於生成模型研究項目，利用ODQA模型之錯誤答案來當作干擾選項應可提供不同思路進行干擾選項生成。這樣的想法乍看可行，但仍有若干技術點需進行探討。諸如，如何控制ODQA模型之錯誤？我們需要在Reader部分弱化Reader的能力，或者弱化Retriever能力，來製造ODQA的錯誤？如何從錯誤回報結果挑選干擾選項？這些皆是尚待深入研究之議題。也因此觸發本研究項目之規劃。Figure5:利用ODQA模型之錯誤答案來當作Distractors•研究項目六：基於NodeCentrality考量主題涵蓋性之選擇題題組生成(MCQGroupGenerationconsideringTopicCoveragebasedGraphNodeCentrality)上述所規劃的選擇題生成做法，主要針對單題進行生成。若要產生多題/題組考題，就是重複相同流程，獨立產生個別考題後，整合為一題組。然而，題組生成做法應當考慮題與題之間之關聯性與互補性。因此，我們認為比較好的做法應當為根據使用者所指定的主題，透過(1)知識圖譜子圖萃取來涵蓋所指定主題之內容與(2)透過主題重要概念萃取：藉由知識圖譜上NodeCentrality方式來萃取關鍵字，以為題幹之生成。此外，如何根據主題互補性，來挑選個別生成之題組，用以組成選擇題題組也是需進行•研究項目七：考量題幹可用性與干擾選項間關聯之Retrieve-and-Generate架構優化(Op-timizingRetrieve-and-GenerateFrameworkconsideringStemUtilityandDistractorCorrela-tion)本研究項目著眼於優化現有Retrieve-and-Generate架構設定。Retrieve-and-Generate架構雖然簡單，但我們可以發現其於單字等級的干擾選項生成已有一定的可用性。我們預計可優化之處為：(1)我們發現引用現有系統於題幹生成時，會有題幹生成結果不佳的狀況。對此，我們發現其中的一個原因為Retriever所檢索之文章品質不佳(文章過短或者與主題不相關)，導致不良之題幹生成。因此如何改善檢索機制來挑選較佳的文章用以進行生成，便是值得探討的課題。再者，題幹生成不佳也有部分原因是來自於問句生成模型本身之生成錯誤，如何有效過濾生成不佳的題幹也因此是一個可需進行研究之項目。(2)如同前言所述，干擾選項之挑選應該考量彼此間之關聯，而非獨立挑選。如何納入此觀點來進行干擾選項之生成也因此成為預計關注之議題。又再者，我們基於word2vec方式之字詞等級干擾選項挑選是否可以引入語言模型之詞向量來求取•研究項目八：生成難度可控之選擇題生成研究Difficulty-ControlledMCQGeneration發展自動化生成考題之可能願景為：針對個人化學習自對應生成難度適中之測驗，以增加學習與檢測之效率。因此，如何針對現有技術探討生成結果難度控制也因此成為一可探索之研究議題。由於我們的基礎架構為基於文章檢索來取得包含使用者所給定的關鍵字之文章，並使用該文章與關鍵字為問題生成模型之輸入，來生成選擇題問句。我們若挑選較為冷門之文章進行生成，則預期可以生成較為困難之題幹。而就干擾選項而言，若我們基於研究項目五「使用Open-DomainQuestionAnswering錯誤結果之干擾選項挑選研究」，利用ODQA來取得干擾選項之作法。我們可藉由調整輸入給閱讀理解模型之文章來產生難度較高的錯誤。具體而言，給定一有包含正確答案A之文章C，我們先將答案片段A於文章D中刪除，而後將其輸入至閱讀理解模型，藉此產生錯誤之閱讀理解結果，以這樣的錯誤結果當干擾選項預期將有較高之誘導能力。相類似的想法也可以套用為挑選Retriever認為相關度比較不高的文章以為閱讀理解模型之輸入。此外，就生成題目之廣度與深度而言，我們可藉由控制取得之文章來調配題組之廣度與深度。例如，若我們以單篇或少數篇文章進行生成，我們所生成的主題題組針對測驗內容而言，應該可產生知識性較為深入之試題。而若針對較多篇文章，則應可產生範圍較廣之測驗試題。上述之研究議題，乍看可行但仍有許多細節需進行探索，如上述研究背景目的所述，本研究計畫擬探索基於現有Retrieve-and-GeneratePipeline之選擇題自動生成架構進行強化。我們以三年為期，規劃在此目標下擬定八項關鍵技術進行研究探討。如Figure6所示，八個工作項目又可區分為三項主軸：「選擇題生成品質提升」、「反事實選項生成」與「群組生成與難度控制」。其中，於「選擇題生成品質提升」研究主軸中，我們探索利用語言模型與知識圖譜架構來生成，將選擇題選項生成問題設定成為一Text2Text任務，輸入為問題題幹與正確答案所串接之TextSequence，而輸出為所生成之distractor串接之TextSequence。此外，我們也嘗試引入對比式學習來改善Text2Text生成模式之品質。我們也預期規劃探索利用ODQA方式來取得干擾選項。而於「反事實選項生成」研究主軸中，我們探索反事實陳述句之生成。我們預計嘗試基於MaskedLM取代重要名詞之反事實語句生成作法與基於知識圖譜知識三元組萃取改寫之作法。於第三個研究主軸中，我們則嘗試針對題組生成與難度可控制之干擾選項生成進行研究。MultipleChoice,Multi-此資料集特色在於為Multi-hop形式，答案需從複數文檔中推理而成；資料來自維基百科以及PubMed，PubMed為生物醫學論文的搜尋引擎，在兩個來源各自提供51,318(Wiki)和2,508(PubMed)筆問題。資料來自國高中英文考試，提供超過10萬筆問題以及2.8萬篇文本，題型上為英文閱讀測驗，會需要閱讀故事或對話紀錄，而針對該文本會有複數題目，每個題目此資料集的挑戰在於，內容來自於7個不同領域(新聞、小學自然科學、旅遊、小說故事等等)，為文本與題目提供多樣性，總計約1萬筆問題與800篇文本。MultipleChoice,Open-為Open-domain形式，並不提供文本，只有問題與答案；包含12,247筆問題、一個正確答案和四個干擾選項；題目類型為知識與常識題，來自於ConceptNet與同時包含兩種形式資料，填空題與Open-domain；填空題形式命名為QUASAR-S，其中資料來源自StackOverflow，提供約37K筆問題。Open-domain形式命名為QUASAR-T，提供約43K筆問題。來自StanfordUniversity的閱讀理解資料集，包含了超過100K筆問題和536篇對應的維基百科文本；延續了SQuAD1.1的題目外，[31]另外加入約50K筆無答案的題目，進一步測試機器能否在無對應答案時回答否，而MedQA是基於美國醫師執照考試(USMLE)所產生的資料集，其中問題皆為較為困難的專業醫學相關的知識，且包含了英文、簡體中文、繁體中文分別有約12K、34K、14K個問題集，這種專業的知識能使機器針對單一領域產生更具參考價值的distractor，目前此任務排名上最佳為ValentinLiévin團隊做出的Codex5-shot訓練機器學習模型進行閱讀理解(MachineReadingComprehensionTask)為最常見的深度學習自然語言任務。諸如，SQuAD[32]、RACE[21]、DROP[10]與HotPotQA[41]等資料集，皆是測驗/訓練機器學習模型於答案找尋、邏輯推理與摘要之能力。其中，許多機器閱讀理解任務採用多選題方式進行測驗。選擇題的自動答題與選擇題的自動生成為一體兩面之應用。因此具有選擇題樣態的資料集為我們選擇題自動生成研究之根本資料集，我們將目前所探知之相選擇題與干擾選項生成之相關研究可按應用類型可區隔為英文學習測驗與知識學習測驗。干擾選項生成研究於英文學習測驗應用，主要以自動生成閱讀理解與克漏字類型的考題為目標。閱讀理解之干擾選項生成與本研究計畫之知識類型選擇題之自動出題目標不同。因此本研究回顧中，我們不做此分類每一研究細部說明。我們將此類型之相關研究按不同象限做分類：(1)干擾選項層級之差異(生成字詞等級與句子等級之差異)象限，(2)題目類型(閱讀理解與克漏字測驗)，(3)生成方式(CandidateRanking與Generative)。我們按此三象限，將目前之相關研究摘要整理於Table5中。而知識學習測驗類型的選擇題生成，則於這一兩年逐漸吸引相關研究投入。我們認為與本研究計畫較為相關之研究有[22][40][3]，以下我們針對個別文獻討論如下。首先，與我們有相同目標者為[22]，也是針對特定知識主題生成選擇題。其主要作法Table5:現有閱讀測驗與克漏字干擾選項生成研究整理表為：先由人工給定一個主題，程式使用該主題名稱的維基百科頁面作為起始點(例如給定“體育”後搜尋體育相關維基百科)，保留熱門文章並取出文章的第一段擷取摘要，由此產生大量句子。並將這些句子依單純英文文法規則生成簡單5W問句與答案，例如who問句是將第一個動詞前的名詞作為正確答案並從句子中移除，what問句是將第一個夾在動詞間的名詞移除作為正確答案並從句子中移除，移除答案後的句子再帶入問題模板生成制式問句。生出五種問句後再依英文文法的詞與詞的相關性去決定哪個問句最適合。在干擾選項生成的部分，先隨機選取其他句子所產生的答案，再藉由語言模型去排序與問題的相關性，取前三高之預測為干擾選項。但本論文並未使用問句生成模型，採取之作法也與本計畫所規劃有所不同。於論文中[40]，則探討如何讓干擾選項更加多樣且與正確答案相差不遠(以具誘導性)。對此，創造了一款監督式分類任務來找出文章中屬於關鍵句子(及對產生干擾選項生成有用的句子)，作者在訓練之前會將訓練用的干擾選項和文章中的每個句子做比對，若該句子和干擾選項相似度達到一定程度，則該句子將成為文章中的關鍵句，透過這個方式在文章中能被修改成為新的干擾選項的句子將會達到多樣性的效果，且透過相似度對比，干擾選項也不會跟原始文章相差太遠從而提升干擾選項的品質。本研究之作法可供我們借鏡參考對關鍵文章/句選擇設計，用以提升干擾選項之多樣性。而與本計畫研究項目五「使用Open-DomainQuestionAnswer錯誤結果之干擾選項」走非生成想法相似之研究為[3]。其主要想法為作者發現於干擾選項資料集中，有許多干擾選項一再被使用。促使論文作者想為新的問題檢索以重複使用干擾選項。作者提出一個Transformer-baseddistractorretrievalmodels，該模型通過考慮問題的上下文來選擇干擾選項模型包含三個部分，分別為D-SIM模型、Q-SIM模型以及DQ-SIM模型。在D-SIM模型中使用mBERT計算同一個MCQ中問題和答案以及對應的干擾選項的向量，並計算他們之間的相似度。而在Q-SIM模型中作者假設不同問題共享一個或多個干擾選項或答案，代表問題可能在語意上相關，因此他們相關的干擾選項可以用作彼此的良好候選干擾選項，因此作者將訓練資料重新排序，使這些共享至少一個干擾選項或答案的問題聚集在一起，接著將資料送進Q-SIM模型計算不同的MCQ中問題之間的相似度。在DQ-SIM模型線性結合前兩個模型，從各自的優勢中獲益，透過基於分數和基於排名的合併策略計算來自D-SIM模型和Q-SIM模型的分數，並設計演算法使得高排名之干擾選項有較大的權重。重複使用現有資料集中之干擾選項為一創新想法，但仍與我們之ODQA做法有所不同。[OpenDomainQuestionAnswering相關研究]本計畫的選擇題生成架構主要基於兩元件:(1)文章萃取與(2)問句生成。目前我們所使用的文章萃取機制為傳統之BM25檢索。而近年來由於ODQA研究領域之發展，基於深度學習之DenseRetrieval技巧也紛紛於ODQA研究領域中所提出。我們預期DenseRetrieval技術也將於我們知識類型選擇題自動出題中擔任關鍵角色。茲簡要回顧現有ODQA之研究如下。ODQA架構中Retriver之重要性不言可喻。不同層級的語意檢索也影響著ODQA的效能。於[28]研究中，作者提出一個簡單而有效的pipeline系統，研究段落和句子級別語義檢索及其對下游任務的潛在影響，作法上是先檢索段落級別的段落，然後從上一步檢索後取得的段落中再去檢索句子級別的段落。該系統在事實驗證和Multi-hopQA方面進行評估，實驗結果顯示QA任務與事實驗證皆仰來上游檢索之結果。於[23]論文中，作者在ODQA架構的retreiver端提出了一個有效率的弱監督式學習的方法(InverseClozeTask)來對retreiver進行預訓練，給予模型完全無人工標記的維基百科原始資料，藉由論文中的方法將資料切分成固定長度的段落，並隨機選取其中的一個句子當作標籤，讓模型去學習如何從給定的句子去資料庫中找尋與之最相關的文章。在實驗數據中此方法訓練出的ODQA模型分數高於傳統的BM25檢索方法。而於DPR[16]論文中，作者為解決傳統BM25無法檢索語意相似段落的問題，提出了基於深度學習模型之DensePassageRetrieval，並提出使用in-batchnegative的技術，在密集向量的檢索取得極佳的效果改進。我們也預計引入中文DRP模型來提升目前題幹生成所需之而於GAR[27]研究中，作者們探討傳統基於BM25的檢索無法檢索沒有單詞重疊或語意相似的段落的問題，而基於密集向量的檢索方式在計算上又過於複雜，且會有資訊損失的問題。該論文透過預訓練語言模型自動生成與查詢語句相關的內容，可增加查詢語句的資訊量，隨後透過BM25進行檢索，該方法比起傳統BM25能檢索到更精確的段落，且執行效率也快於基於密集向量的檢索方式。透過GAR中的PLM可對查詢語句的資訊進行補充，原論文中是補充答案、相關段落及段落標題，可基於該手法讓PLM生成問題與原始答案的關聯，對這些關聯進行組合或刪除即可檢索與原答案有相似關係的查詢語句，可檢索到適合製作干於[19]，作者觀察到基於語言模型之檢索技術雖然效果很好，但比以往的方法需要極高的計算成本，特別是在計算每個query與document間的relevancescore時。本篇論文作者提出了ColBERT，引入lateinteraction架構，對query與document進行獨立的encoding，於模型輸出最終階段才進行相似度運算。而[18]中，則使用近一步基於ColBERT當基礎模型來進行retreiver端的訓練，使用了Relevance-guidedSupervision(RGS)的方法來訓練retreiver的模型。相較於傳統的retreiver訓練資料，傳統方法需人工標註的訓練資料，但作者認為人工標住資料往往存在偏見，進而影響模型的效能，所以在論文中提出了用訓練好的模型來找尋最適合的訓練資料，並把這些資料用於訓練下一個模型，使用這個方式來進行後續的訓練，最後得出最佳的模型。此方法訓練出的模型分數明顯高於目前opendomain的其他方式。在找尋訓練資料時，模型會先搜尋前k筆資料，並把前20筆資料中含有shortanswer的資料當成possitiveexample，而前20筆以外剩餘的資料中不含有shortanswer的資料當成negativeexample，此方法尋找的負面訓練資料交由reader進行預測能得到與正確答案相關的錯誤答案，如能改良ranking的方式，應用於干擾選項生成，預期將能提升干擾選項之品質。[ContrastiveLearning於自然語言生成相關研究]對比式學習始見於電腦視覺領域，其於影像應用上有著顯著的效果提升。因此，許多自然語言處理之研究者也將其引用至自然語言生成領域，諸如[11][7][35]。於[11]研究中，作者們提出了使用ContrastiveLearning的作法來學習SentenceEmbedding，他們使用BERT作為基礎模型，透過不同的dropoutmask使模型能用同樣的輸入產生不同的SentenceEmbedding，但它們之間的距離會是近的，也就可作為PositiveSample。然後再使用其他in-batch的句子作為NegativeSample，以達到非監督式訓練。而在有訓練資料的情況下，如NLI資料集，則可以將Eentailment視為PositiveSample，Contradiction以及其他in-batch的句子視為Negative而再基於[11]研究後，於[7]研究中，作者們提出加上了Discriminator來加強SentenceEmbedding的學習效果。具體而言，對每筆輸入來說，會透過SentenceEncoder產生一個SentenceEmbedding，同時也會隨機的Masking輸入句子其中的幾個Token，並透過一個fixed的Generator來還原MaskToken，而Discriminator要試著透過沒被修改過的SentenceEmbedding的資訊去辨認修改後的句子中的哪一個Token有被修改過，整個框架會透過SentenceEmbedding的ContrastiveLearningLoss以及Discriminator的ReplacedTokenDetection而與我們預計引入對比式學習來提升句子等級的干擾選項生成效果想法接近的研究也可見於[35]。該研究指出發現了以往autoregressive模型使用BeamSearch去決定要生成的文本時，會產生語意不自然以及沒意義的重複文字，儘管後續有人使用取樣以及修改ObjectiveFunction來嘗試解決這個問題，但這個方法時常會產生語意不連貫的問題。因此作者提出了使用ContrastiveLearningLoss加上原先的MaximumLikelihoodEstimationLoss來訓練模型，並且使用ContrastiveSearch來作為decodingmethod。[Counter-FactualSentenceGeneration相關研究]於Counter-FactualGeneration研究中，[44,33]為相關研究之先驅。主要想法是使用神經網路來生成反事實敘述，這個概念背後的想法是同時使用語言模型和各種採樣的策略來達成生成反事實敘述的效果。接續之前的成果，[39]提出了Polyjuice架構，可以控制輸出的反事實敘述的類型。另外一種生成干擾選項的研究是使用干擾選項生成(DistractorGeneration)的手法，干擾選項生成(DistractorGeneration)的目標是給予了一篇文章、問題和正確答案後，模型能夠生成似是而非的干擾選項。於研究[24]中，作者最先提出使用了神經網路來生成干擾選項，而研究[8]則延續了前者的成果，把重點放在生成複數的干擾選項並提出了一個負樣本學習策略(negativetrainingstrategy)來加強干擾選項生成。但這上述兩個研究主要都著眼於閱讀理解題型中干擾選項之生成，與本研究知識類型選擇題生成目標所有不同。而在關於AbductiveInferenceGeneration的相關研究中，於[30]中作者提出了故事改寫的任務，此任務目標是要改寫一段故事的敘述並且導致產生與原先不同的結局，與顯永的論文的方式的差異為故事改寫任務是根據給定的誤導推論來生成不同的結局，在MIG任務中是給定敘述句與其前後文來生成誤導推論。[2]研究中是讓模型根據上下文來推論中間適合加入的句子，此研究主要是產生正確的推論敘述，而在MIG任務[29]主要是產生相反的誤導推論敘述。於我們先前的研究[29]中，我們提出一個自然語言的誤導推論生成任務，任務步驟是當給定了一個陳述事實的句子並給定其上下文，將其定義為(x,y,z)與誤導推論ˆy，模型會生成與該事實相反的推論句子，由此可以讓模型產生出多選題似是而非的干擾選項。然而這樣任務與我們所設定之反事實出題仍有所不同。而與我們生成Counter-Factual陳述句想法接近的研究為：[46]。於該研究中，作者探討有別於過往的是非題，將文章中原始句子作為True的問句並通過反義詞替換關鍵字生成False問句，本篇作者通過使用一種新穎的masking-and-infilling策略來生成更靈活與複雜的問句。要被mask的關鍵字找法有很多種，像是SRL結果中的predicate，句子中連接詞(”that”、”when”、”since”)之後的部分或是數字等等，來找出值得提問的句子。Infilling的作法則是以BART為基底作為生成模型，將原始句子的關鍵字mask後，提供前後句子作為BART的上下文後產生句子填入。作者為了找值得提問的句子所提出的方法亦可用來作為多選題產生題目的答案選擇方法，而infilling的想法如果使用得宜，在提供出題範圍的前後文後，也能將欲出題句子挖空讓BART模型填補後產生選項。雖然與我們目標相似，但仍與我整合知識圖譜與語言模型為近年語言模型訓練熱門關注議題。於[42]研究中，作者們提出一CounterfactualGenerationControllableCounterfactualGenerationDistractorGenerationMisleadingInferenceGeneration種能將文本和知識圖譜的資訊進行深度雙向、自我監督的預訓練的方法，透過作者的方法可以將一些特定領域的KnowledgeBase資料集結合相關文獻去訓練語言知識模型，讓語言模型和知識圖譜之間的資訊互相交換，並且在回答特定領域問答的任務上，表現優於現有的語言模型和知識圖譜增強模型。我們想透過作者提供的預訓練模型，來做多選題選項生成，透過知識圖譜所額外提供的資訊，讓在考慮生成選項時，除了題目和答案的文字外，用這些文字從知識圖譜萃取相關的知識圖譜子圖幫助生成選項有更多參考資訊。知識圖譜於問句生成之研究也見於[5][13]。於[5]研究中，作者之想法為使用知識圖譜進行問題生成任務時，通常只會取出資料與關係的三元組合，並不能完整利用知識圖譜中豐富的資訊，因此作者基於GraphNeuralNetworks提出了BidirectionalGatedGraphNeuralNetwork(BiGGNN)，將知識圖譜中的node及edge編碼成向量，使得每個node都包含了周圍其他node的資訊，並對答案的node進行標註，隨後透過RNN進行問句生成，生成過程中RNN會決定生成新文字或直接複製某個node的資訊放進問題。我們應可借鏡此研究論文的想法，可將知識圖譜及答案的資訊完整編碼，可基於此特性，在生成問題時同時考慮答案附近的node，讓模型在建立問題的同時也能根據附近的node產生干擾選項。而於[13]研究中，則提出的ISEEQ架構，主要目的是希望從簡短的敘述句中去尋找更多訊息來反問使用者是否符合關於敘述句背後未提及的情況，在使用時，使用者只需輸入簡短的敘述句，模型會先從知識圖譜擴展並增加query的關鍵字，透過這些關鍵字模型就能retrieve更多相關的文章進行ranking，在從這些文章中使用QG模型產生一些原始query中未提及但可能相關背景知識，例如當使用者說道:“我感到疲勞且渾身無力”，ISEEQ能回覆:“請問病徵持續了多久?”，或是“你最近14天有出國過嗎?”這類可能與其他知識相關的問句。這種方式最大的貢獻及是讓機器學習到”反問”的能力，而非一味的透過query生成出結果。這樣的想法，或許可引用來提升題幹生成的精確度，舉例來說:有位教師想出關於日治時期的歷史題目，我們就能先藉由ISEEQ來詢問是要出與日治時期戰爭相關的題目或是與日治時期建設相關的題目，以此來取得更精確的題幹生成需求。[1]J.Araki,D.Rajagopal,S.Sankaranarayanan,S.Holm,Y.Yamakawa,andT.Mitamura.Gen-eratingquestionsandmultiple-choiceanswersusingsemanticanalysisoftexts.InProceedingsofCOLING2016,the26thInternationalConferenceonComputationalLinguistics:TechnicalPapers,pages1125–1136,2016.[2]C.Bhagavatula,R.L.Bras,C.Malaviya,K.Sakaguchi,A.Holtzman,H.Rashkin,D.Downey,S.W.-t.Yih,andY.Choi.Abductivecommonsensereasoning.arXivpreprintarXiv:1908.05739,[3]S.K.Bitew,A.Hadifar,L.Sterckx,J.Deleu,C.Develder,andT.Demeester.Learningtoreusedistractorstosupportmultiplechoicequestiongenerationineducation.IEEETransactionsonLearningTechnologies,2022.[4]Y.-H.ChanandY.-C.Fan.Arecurrentbert-basedmodelforquestiongeneration.InProceedingsofthe2ndWorkshoponMachineReadingforQuestionAnswering,pages154–162,2019.[5]Y.Chen,L.Wu,andM.J.Zaki.Towardsubgraphguidedknowledgegraphquestiongenerationwithgraphneuralnetworks.arXivpreprintarXiv:2004.06015,2020.[6]S.-H.Chiang,S.-C.Wang,andY.-C.Fan.Cdgp:Automaticclozedistractorgenerationbasedonpre-trainedlanugagemodel.InFindingsoftheAssociationforComputationalLinguistics:[7]Y.-S.Chuang,R.Dangovski,H.Luo,Y.Zhang,S.Chang,M.Soljac￿ic￿,S.-W.Li,W.-t.Yih,Y.Kim,andJ.Glass.Diffcse:Difference-basedcontrastivelearningforsentenceembeddings.arXivpreprintarXiv:2204.10298,2022.[8]H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Abert-baseddistractorgenerationschemewithmulti-taskingandnegativeanswertrainingstrategies.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2020,pages4390–4400,2020.[9]B.Dhingra,K.Mazaitis,andW.W.Cohen.Quasar:Datasetsforquestionansweringbysearchandreading.arXivpreprintarXiv:1707.03904,2017.[10]D.Dua,Y.Wang,P.Dasigi,G.Stanovsky,S.Singh,andM.Gardner.ingcomprehensionbenchmarkrequiringdiscretereasoningoverparagraphs.arXiv:1903.00161,2019.[11]T.Gao,X.Yao,andD.Chen.Simcse:Simplecontrastivelearningofsentenceembeddings.arXivpreprintarXiv:2104.08821,2021.[12]Y.Gao,L.Bing,P.Li,I.King,andM.R.Lyu.Generatingdistractorsforreadingcomprehen-sionquestionsfromrealexaminations.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume33,pages6423–6430,2019.[13]M.Gaur,K.Gunaratna,V.Srinivasan,andH.Jin.Iseeq:Informationseekingquestiongenerationusingdynamicmeta-informationretrievalandknowledgegraphs.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume36,pages10672–10680,2022.[14]Q.Guo,C.Kulkarni,A.Kittur,J.P.Bigham,andE.Brunskill.Questimator:Generatingknowl-edgeassessmentsforarbitrarytopics.InIJCAI-16:ProceedingsoftheAAAITwenty-FifthInternationalJointConferenceonArtificialIntelligence,2016.[15]D.Jin,E.Pan,N.Oufattole,W.-H.Weng,H.Fang,andP.Szolovits.Whatdiseasedoesthispa-tienthave?alarge-scaleopendomainquestionansweringdatasetfrommedicalexams.AppliedSciences,11(14):6421,2021.[16]V.Karpukhin,B.Og￿uz,S.Min,P.Lewis,L.Wu,S.Edunov,D.Chen,andW.-t.Yih.Densepassageretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2004.04906,2020.[17]D.Khashabi,S.Chaturvedi,M.Roth,S.Upadhyay,andD.Roth.Lookingbeyondthesurface:Achallengesetforreadingcomprehensionovermultiplesentences.InProceedingsofthe2018ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongPapers),pages252–262,2018.[18]O.Khattab,C.Potts,andM.Zaharia.Relevance-guidedsupervisionforopenqawithcolbert.TransactionsoftheAssociationforComputationalLinguistics,9:929–944,2021.[19]O.KhattabandM.Zaharia.Colbert:Efficientandeffectivepassagesearchviacontextualizedlateinteractionoverbert.InProceedingsofthe43rdInternationalACMSIGIRconferenceonresearchanddevelopmentinInformationRetrieval,pages39–48,2020.[20]G.Kumar,R.E.Banchs,andL.F.D’Haro.Revup:Automaticgap-fillquestiongenerationfromeducationaltexts.InProceedingsoftheTenthWorkshoponInnovativeUseofNLPforBuildingEducationalApplications,pages154–161,2015.[21]G.Lai,Q.Xie,H.Liu,Y.Yang,andE.Hovy.Race:Large-scalereadingcomprehensiondatasetfromexaminations.arXivpreprintarXiv:1704.04683,2017.[22]G.LeBerre,C.Cerisara,P.Langlais,andG.Lapalme.Unsupervisedmultiple-choicequestiongenerationforout-of-domainq&afine-tuning.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages732–738,2022.[23]K.Lee,M.-W.Chang,andK.Toutanova.Latentretrievalforweaklysupervisedopendomainquestionanswering.arXivpreprintarXiv:1906.00300,2019.[24]C.Liang,X.Yang,N.Dave,D.Wham,B.Pursel,andC.L.Giles.Distractorgenerationformultiplechoicequestionsusinglearningtorank.InProceedingsofthethirteenthworkshoponinnovativeuseofNLPforbuildingeducationalapplications,pages284–290,2018.[25]C.Liang,X.Yang,D.Wham,B.Pursel,R.Passonneaur,andC.L.Giles.Distractorgenera-tionwithgenerativeadversarialnetsforautomaticallycreatingfill-in-the-blankquestions.InProceedingsoftheKnowledgeCaptureConference,pages1–4,2017.[26]V.Liévin,C.E.Hother,andO.Winther.Canlargelanguagemodelsreasonaboutmedicalquestions?arXivpreprintarXiv:2207.08143,2022.[27]Y.Mao,P.He,X.Liu,Y.Shen,J.Gao,J.Han,andW.Chen.Generation-augmentedretrievalforopen-domainquestionanswering.arXivpreprintarXiv:2009.08553,2020.[28]Y.Nie,S.Wang,andM.Bansal.Revealingtheimportanceofsemanticretrievalformachinereadingatscale.arXivpreprintarXiv:1909.08041,2019.[29]H.-Y.Peng,H.-L.Chung,Y.-H.Chan,andY.-C.Fan.Misleadinginferencegenerationviaproxi-malpolicyoptimization.InPacific-AsiaConferenceonKnowledgeDiscoveryandDataMining,pages497–509.Springer,2022.[30]L.Qin,A.Bosselut,A.Holtzman,C.Bhagavatula,E.Clark,andY.Choi.Counterfactualstoryreasoningandgeneration.arXivpreprintarXiv:1909.04076,2019.[31]P.Rajpurkar,R.Jia,andP.Liang.Knowwhatyoudon’tknow:Unanswerablequestionsforsquad.arXivpreprintarXiv:1806.03822,2018.[32]P.Rajpurkar,J.Zhang,K.Lopyrev,andP.Liang.Squad:100,000+questionsformachinecomprehensionoftext.arXivpreprintarXiv:1606.05250,2016.[33]S.Ren,Y.Deng,K.He,andW.Che.Generatingnaturallanguageadversarialexamplesthroughprobabilityweightedwordsaliency.InProceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1085–1097,2019.[34]S.RenandK.Q.Zhu.Knowledge-drivendistractorgenerationforcloze-stylemultiplechoicequestions.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume35,pages[35]Y.Su,T.Lan,Y.Wang,D.Yogatama,L.Kong,andN.Collier.Acontrastiveframeworkforneuraltextgeneration.arXivpreprintarXiv:2202.06417,2022.[36]A.Talmor,J.Herzig,N.Lourie,andJ.Berant.Commonsenseqa:Aquestionansweringchallengetargetingcommonsenseknowledge.arXivpreprintarXiv:1811.00937,2018.[37]J.Welbl,N.F.Liu,andM.Gardner.Crowdsourcingmultiplechoicesciencequestions.arXivpreprintarXiv:1707.06209,2017.[38]J.Welbl,P.Stenetorp,andS.Riedel.Constructingdatasetsformulti-hopreadingcomprehensionacrossdocuments.TransactionsoftheAssociationforComputationalLinguistics,6:287–302,[39]T.Wu,M.T.Ribeiro,J.Heer,andD.S.Weld.Polyjuice:Automated,general-purposecounter-factualgeneration.arXivpreprintarXiv:2101.00288,1(2),2021.[40]J.Xie,N.Peng,Y.Cai,T.Wang,andQ.Huang.Diversedistractorgenerationforconstruct-inghigh-qualitymultiplechoicequestions.IEEE/ACMTransactionsonAudio,Speech,andLanguageProcessing,30:280–291,2021.[41]Z.Yang,P.Qi,S.Zhang,Y.Bengio,W.W.Cohen,R.Salakhutdinov,andC.D.Manning.Hotpotqa:Adatasetfordiverse,explainablemulti-hopquestionanswering.arXiv:1809.09600,2018.[42]M.Yasunaga,A.Bosselut,H.Ren,X.Zhang,C.D.Manning,P.Liang,andJ.Leskovec.Deepbidirectionallanguage-knowledgegraphpretraining.arXivpreprintarXiv:2210.09338,2022.[43]C.Y.Yeung,J.S.Lee,andB.K.Tsou.Difficulty-awaredistractorgenerationforgap-fillitems.InProceedingsoftheThe17thAnnualWorkshopoftheAustralasianLanguageTechnologyAssociation,pages159–164,2019.[44]C.Zhang,Y.Sun,H.Chen,andJ.Wang.Generatingadequatedistractorsformultiple-choicequestions.arXivpreprintarXiv:2010.12658,2020.[45]X.Zhou,S.Luo,andY.Wu.Co-attentionhierarchicalnetwork:Generatingcoherentlongdistractorsforreadingcomprehension.InProceedingsoftheAAAIConferenceonArtificialIntelligence,volume34,pages9725–9732,2020.[46]B.Zou,P.Li,L.Pan,andA.Aw.Automatictrue/falsequestiongenerationforeducationalpur-pose.InProceedingsofthe17thWorkshoponInnovativeUseofNLPforBuildingEducationalApplications(BEA2022),pages61–70,2022.於本研究計畫中，我們目標基於自然語言生成技術進行選擇題自動出題研究。"}, "1676341016.4204295": {"單位": "", "標題": "伍動螞蟻-", "作者": "", "發布日": 0, "摘要": "", "全文": "螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側(KahootQ&A、google問卷編1.\t前測問卷發放-小學生的螞蟻知識知多少?\t(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題講及臭巨山蟻來更了解螞蟻的日常習性，並藉此螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻知識知多少》的螞蟻知識推廣的更懂螞蟻，所以我在專題講座後請參語的同學在我煩惱要做什麼當我的獨立研究時，忽然看到了螞蟻相關報告，讓我彷彿撥雲見日，我決定要以螞蟻當作我的獨立研究主題。在文獻探討中，我將其分為八個章節，在網路上搜尋有關螞蟻的知識。並在閒暇的時間進行有關螞蟻的小實驗，目的就是要讓我的報告更完整，且更有價值。經過了一段艱辛的路程後，我完成了我的獨立研究。希望能讓大家更了解螞蟻，且更尊重牠們。螞蟻會對我們造成很大的影響。入侵紅火蟻在澳洲、台灣肆虐，攻擊任何在牠們巢穴附近的生物；黃瘋蟻在耶誕島獵捕紅地蟹，造成耶誕島紅地蟹的浩劫；熱帶大頭家蟻在澳洲是最強勢的入侵物種，牠們會保護介殼蟲及蚜蟲，造成農民的損失……螞蟻至少有260屬，18000種，所以我會藉由相關文獻及實地研究探討螞蟻的不同習性與生活型態，希望能讓大家了解，螞蟻對我們的(二)讓大家了解螞蟻之餘，能更尊重牠們。為蟻窩中具有生殖能力的雌性螞蟻，整個蟻群都為蟻后的後代。有時不需要雄蟻介入也能進行孤雌生殖，不過在這種情況下所產出來的卵為未受精的卵，只會孵化出雄蟻。大多數的蟻后和雄蟻都會進行婚飛，也就是在特定時間讓蟻后與型蟻同時飛出巢外，並且進行交配，而不同螞蟻進行婚飛的時間也不盡相同。依照種類的不同，有些種一個蟻窩中只會有一隻蟻后，也有些種類的螞蟻在一個蟻窩中同時會有上百隻具有生殖能力的蟻后。蟻后可生存長達30年，紀錄中由德國昆蟲學家HermannAppel所飼養的黑褐毛山蟻蟻后活了28¾年。雖然蟻后被稱為「蟻后」，但不能將人類社會當中上下階級和統治的觀念給帶入螞蟻社會中。事實上，蟻后在蟻巢中只是個產卵機器，在部分情況下甚至會被推翻。由此可證蟻后不一定在蟻巢中絕對的權勢。雄蟻的主要工作是與蟻后交配。由未受精的卵細胞發育而來，性染色體為X(人類男性的性染色體為XY)，大部分有翅，交配完不久後便會死去。工蟻的主要工作為負責搜尋食物、照顧蟻卵、幼蟲等大部分的工作，體型比兵蟻小。是由受精的卵細胞發育而來，染色體雙套（2n），大部分在一出生就就受到蟻后分泌的費洛蒙影響，所以不會產卵，在蟻后死亡後可能會產下未受精卵。未受精卵有營養卵或是雄蟻卵兩種，營養卵是食物，雄蟻卵則會孵化成雄蟻；而某些物種的工蟻卵巢能夠發育，交配後能夠產下能發育的受精卵。部分物種的工蟻產卵管特化為螫針，可以用來制服獵物或是防衛蟻窩。在螞蟻巢中，較年輕的工蟻會負責照顧蟻后；而幾乎所有的螞蟻都具有年齡多形性（Agepolytheism）的分工機制，除了兩個物種以外，分別是Amblyoponepallipes和大眼擬鬥牛犬蟻（Nothomyrmeciamacrops）。1.和工蟻一起保衛蟻巢。如熱帶火蟻、收穫蟻屬。2.在工蟻出外覓食的時候，幫忙擔任清除雜物的「推土機」並非每一種螞蟻都有兵蟻，沒有兵蟻的物種包括針蟻亞科、琉璃蟻亞科、擬家蟻亞科等。兵蟻是由受精的卵細胞發育而來，染色體雙套，為沒有生殖能力的雌蟲。某些物種的兵蟻頭部及大顎高度骨化且發達。一般來說頭部異速生長的大型個體稱作兵蟻，而頭部沒有異速生長的大型個體則稱作大工蟻，但這兩個詞彙之間還是有難以區分的灰色地帶。具有兵蟻的物種如大頭家蟻屬，具在蟻巢中，除生殖階級外，所有個體無翅。觸角為膝狀，某些物種觸角末端膨大，稱作「垂節」，牠們的觸角，牠們也用觸角判斷彼此身分。大部分物種胸部和腹部之間隘縮，形成腰節，實則屬於胸部的延伸，或稱腹柄節，具有三個腹節。胸節與前伸腹節合稱「中軀」），腹垂節稱作「後軀」。螞蟻的體型範圍平均大約為0.75~52mm，目前已知體型最大的螞蟻為已滅絕的古巨蟻亞科，蟻后體長可達6cm，翅膀長度可達15cm。螞蟻可以透過費洛蒙溝通，一隻螞蟻如果發現了食物，它就會在回家的路上留下一路的氣味，其他的螞蟻就會沿著這條氣味路線去找食物，並不斷地留下氣味加強氣味。如果這裡的食物被採集完了，沒有螞蟻再來，氣味就會逐漸消散。如果一隻螞蟻被碾碎，就會散發出強烈的警戒費洛蒙(註一)引起其他螞蟻進入緊戒狀態；如果一隻螞蟻散發出死亡費洛蒙，不管那隻螞蟻是活的還是螞蟻和其他昆蟲一樣透過觸角辨識氣味，觸角的末幾節膨大，呈膝狀彎曲，非常靈活。由於觸角是一對，因此既能辨别氣味的強度，也能辨識氣味來源的方向距離。但是也造就了蟻客(專門寄生於螞蟻巢內的生物，部分蟻客對螞蟻沒有害處，不過有一部分的蟻客對螞蟻有明顯危害)成蟲互相交哺並通過其氣味了解對方的健康狀況，對方發現的食物等資訊。同時也能區別對方屬於從事哪個分工的階級。如負責餵養蟻后及幼蟲的螞蟻，或是負責搜集食物的螞蟻后會不斷地分泌費洛蒙，這種費洛蒙能抑制工蟻的卵巢發育並讓工蟻知道蟻后還在巢內，一旦以這種氣味消失，有些物種會出現新的蟻后，有些物種的工蟻則會開始產卵，填補蟻后的功能。某些螞蟻用大顎啃咬以攻擊或自衛，山蟻亞科的物種能從腹部末端分泌蟻酸（甲酸），刺激被叮咬的傷口紅腫疼痛；部分物種腹部末端具有螫針。螞蟻亦是全世界力氣最大的昆蟲之一，牠的負重能力相當驚人，能拖動比牠體重還重1400倍的物品，也能背負自身體重註一:警戒費洛蒙分成己醛、己醇、正十一酮和丁基辛酮。己醛會最先出現，提醒工蟻提高警覺；己醇是與酒精(乙醇)類似的物質，會促使工蟻尋找問題來源；正十一酮會吸引工蟻接近問題來源，並在碰到外來物時張口就咬；丁基辛酮最後才會出現，會讓工蟻展開攻擊與咬噬的行動。蠻蟻亞科Agroecomyrmecinae鈍針蟻亞科Amblyoponinae（包含新蟻亞科Apomyrminae）†布朗長蟻亞科†Brownimeciinae異針蟻亞科Heteroponerinae鬥牛犬蟻亞科Myrmeciinae（包含：擬鬥牛犬蟻亞擬家蟻亞科Pseudomyrmecinae†蜂蟻亞科†Sphecomyrminae†幽冥蟻亞科†Haidomyrmecini†阿爾曼蟻亞科†Armaniinae，有些文獻將牠列入蟻科，有些則獨立一科，但無論如何，該亞科都在蟻總科（Formicoidea）之下目前已確定有21亞科283屬，11700種。茲舉幾種以說明:(一)行軍蟻:牠們會一直移居，並且吞食路上遇到的獵物。在移居過程中，1.又名弓背蟻屬或木匠蟻屬，是蟻科山蟻亞科的一個屬。2.牠們不喜歡築巢在乾燥的地方，而巢穴可能建於房屋的橫樑、地板或巢穴中。牠們是雜食性的螞蟻，以食物碎屑或其他昆蟲為食，也會食3.巨山蟻屬的成員眾多，台灣目前本屬有十七種，巨山蟻屬以牠們獨特的習性聞名。牠們會在木材裡挖洞，並以這些通道為生活重心，因為牠們這種特殊的生活習性，所以規模較大的巨山蟻群落會造成房屋結構性毀損，但通常不像白蟻破壞過的那麼嚴重。4.一個成熟的巨山蟻群落一般會有一隻蟻后，許多待孵化的卵，超過兩千隻以上的工蟻，和一個只有工蟻的附屬群落。5.目前發現的蟻后體型最大者為1.91公分。而屋裡的巨山蟻可能是來自主群落或附屬群落，例如：巨山蟻可能來自戶外已枯萎的大樹，陸6.本屬的膨咕巨山蟻跟蜜瓶蟻一樣有貯蜜蟻階級(蜜瓶蟻中的貯蜜蟻又稱蜜缽階級工蟻)它們會收集糖蜜並儲存它們。而在鬧飢荒時，這些貯蜜蟻就派上用場了:牠們會把這些花蜜回哺給同伴食用。7.被巨山蟻在裡面築巢的木材會有木屑遺落在附近，而被白蟻破壞過的木材則會有含泥類物質，當發現附近有上述的木屑(通常會包含已死亡的螞蟻和部分被巨山蟻吃掉的昆蟲殘骸)，就代表附近可能有巨山蟻的巢穴。巨山蟻喜歡築巢在較潮濕的木頭中。(三)針蟻:這種螞蟻包含世界最大的螞蟻:巨人恐針蟻。牠們是少數沒有蟻后的螞蟻，交配過的工蟻會取代蟻后，可以透過解剖牠(四)蜜瓶蟻:牠們的部分大型工蟻會吸飽蜜，在鬧飢荒的時候回吐花蜜，因此被稱為蜜缽階級工蟻。牠們也是澳洲居民的美食，澳洲居民會從牠們的屁股吸取花蜜，但是被人類吸食的蜜瓶蟻也會因為人類破壞式的取(五)火蟻:火蟻屬中有惡名昭彰的入侵紅火蟻，但是火蟻屬中，在台灣已發現1.獵食紅火蟻：生活在森林邊緣，都市綠地、海邊、草地、農地等。在石頭下或土中常常可以發現牠們的蟻巢。牠們是多后制體系的螞蟻，成熟蟻巢由數隻具生殖能力的蟻后和數百隻工蟻組成。牠們分布在台灣中低海拔地區，牠們的食性是雜食偏素食性，主要食物是花蜜、蜜腺分泌和小型昆蟲屍體。牠們除了。會讓工蟻組成小組出外覓食，還會用蟻賊的方式，偷取附近蟻巢的資源。目前未發現有2.知本火蟻：牠們是一種分布在廣西、湖南、湖北天堂寨和台灣。牠們跟原生於南美洲、中美洲、墨西哥和部分美國南部地區的切葉蟻有親戚關係。牠們原生於美洲的熱帶與亞熱帶地區，後來隨著交通工具入侵印度、非洲、太平洋島嶼等地區。牠們攻擊性較強，會出現主動攻擊人畜與莊稼，甚至會咬破電線，破壞供電系統。牠們的毒腺中含有大量生物鹼，叮咬人時會造成劇烈疼痛。會危害當地的農林業生產、人體健康、公共安全及生態環境。3.入侵紅火蟻：牠們的英文簡稱為RIFA，是Redimportedfireant的縮寫，原分布在巴拉那河流域，由於生活在河邊，所以發展出「蟻筏」，也就是讓工蟻互相咬住對方，變成一個蟻筏，並且把蟻后、卵、幼蟲及蛹放在上面，載牠們渡河。由於牠們體表防水，所以不會淹死。紅火蟻在二十世紀初入侵美國南部，造成美國十二個州超過一億公畝(一百億平方公尺)被入侵紅火蟻佔領，每年損失約數十億美元以上。且目前未發現能夠有效防治入侵紅火蟻的生物。火蟻屬成員的毒液大多含有大量生物鹼，叮咬人時會產生如火燒般的劇痛，這也是牠們被取名為「火蟻」的原因。紅火蟻的成熟群落約有二十萬隻至五十萬隻，所以入侵者往往會被大量的火蟻叮咬。被火蟻叮咬後，大部分的人除了會感到劇痛，還會產生水泡，若把它抓破，則會造成二次性的感染。少部分的人甚至會產生嚴重的過螞蟻是靠氣味溝通的。所以蟻客就是掌握了螞蟻的費洛蒙，才能滲透進蟻巢。有些蟻客寄生在蟻巢內純粹是為了尋求庇護，如寄生家蟻；有些蟻客則是為了取得食物，如:黑隱翅蟲的幼蟲會寄生在蟻巢內，並吞食正牌的螞蟻幼蟲。牠們沒有消滅整個蟻巢，是因為牠們也會自相殘殺。甚至有一種蜘蛛會偽有些植物也跟螞蟻有共生關係。如:有一種植物會分泌蜜露，供螞蟻食用，和讓螞蟻築巢在裡面。而螞蟻則會趕走要吃牠們的動物，並且清除雜草。而這有助於植物生長。形成互利共生的關係。螞蟻可以簡單分為頭胸腹三部分，但是更細微的部分呢?以下是我從網路抓(KahootQ&A、google問卷編1.前測問卷發放-小學生的螞蟻知識知多少?(1)分析問卷中的答對率，並從中了解小學生對螞蟻知識了解的的程度，針對錯比較多的題目，進行內容的蒐集與整理，製作成專題2.螞蟻習性觀察:我透過飼養高雄巨山蟻、希氏巨山蟻，以及臭巨山蟻來更了解螞蟻的日常習性，並藉此驗證我所查到的文獻內容是否正3.校內演講:螞蟻知識推廣-(kahoot機智問答)我於民國一一○年三月三十日星期二舉辦了一場《伍動螞蟻－螞蟻4.後測問卷發放-我了解舉辦一場專題講座是否能夠讓同學更懂螞蟻，所以我在專題講座後請參語的同學幫我填寫回饋問卷，也給我一些一、前測問卷分析-小學生的螞蟻知識知多少?我為了想要了解小學生對螞蟻的認識，因此特地發了這份問卷，並請高年級的電腦老師鍾佑聆老師於電腦課的時候花幾分鐘的時間請大家填寫。下表顯示我於二零二零年十二月二十一日所發出，並於二零二零年十二月三十日回收的問卷共527筆的結果如下，請詳細閱讀。由此表可知，在527人中，有480個人回答了正確答案(正確答案:六隻腳)，21人回答螞蟻有四隻腳，26人回答螞蟻有八隻腳。難度:低由此表可知，在527人中，有491個人回答了正確答案(正確答案:蟻后)，6個人回答兵蟻，9個人回答雄蟻，17個人回答工蟻。難度:低由此表可知，在527人中，有十三人回答蟻后、四百八十一人回答工蟻、四十人回答雄蟻及一百八十二人回答兵蟻(正確答案:工蟻和兵蟻)。難度:低由此表可知，在527人中，有475個人回答了正確答案(正確答案:兵蟻)，7人回答蟻后，36人回答工蟻，8人回答雄蟻。難度:低由此表可知，在527人中，有489個人回答了正確答案(正確答案:雄蟻)，5人回答兵蟻，14人回答蟻后，19人回答工蟻。難度:低由此表可知，在525人中，有192個人回答了正確答案(正確答案:亞全山蟻)，125人回答狂蟻(小黑蟻)，53人回答亞絲山蟻，154人回答都不是。難度:高由此表可知，在523人中，有168個人回答了正確答案(正確答案:亞絲山蟻)，170人回答狂蟻(小黑蟻)，99人回答都不是，85人回答亞全山蟻。難度:高由此表可知，在523人中，有317個人回答了正確答案(正確答案:蜜瓶蟻)，78人回答狂蟻(小黑蟻)，43人回答亞絲山蟻，84人回答都不是，難度:中由此表可知，在523人中，有211個人回答了正確答案(正確答案:火家蟻)，130人回答黃瘋蟻，35人回答蜜瓶蟻，83人回答都不是，63人回答白霜前琉璃由此表可知，在523人中，有110人回答了正確答案(正確答案:蜈蚣)，67人回答青蛙，154人回答都不是，120人回答蜘蛛，72人回答蠍子。難度:高由此表可知，在523人中，有181個人回答了正確答案(正確答案:不是)，342由此表可知，在518人中，有179人回答了正確答案(正確答案:黃瘋蟻)，196人回答白霜前琉璃蟻，62人回答蜜瓶蟻，83人回答狂蟻。難度:高由此表可知，在518人中，有324人回答了正確答案(正確答案:鋸針蟻)，61人回答黃瘋蟻，100人回答狂蟻，33人回答蜜瓶蟻。難度:中1.螞蟻遇到石膏粉與滑石粉時，會因為摩擦力降低而無法爬上斜坡。2.不同種或同種不同窩的螞蟻在相遇時有可能會打起來，也可能會互相忽略，但是在其中一方確定自己有百分之百的勝算時，便會征服另一個群落。(三)專題講座後的搶答活動:後測kahoot問答:螞蟻冷知識知多少?在我進行完螞蟻專題講座後，我用kahoot進行機智問答。以下是我的題1.螞蟻有幾隻腳(選項:四隻腳、六隻腳、八隻腳、十隻腳)2.一般來說，什麼螞蟻會產卵(選項:雄蟻、蟻后、工蟻、兵蟻)3.請問何種螞蟻是由非受精卵孵化而成?(選項:工蟻、蟻后、雄蟻、兵4.以下何者是「蟻客」?(選項:獨角仙、鍬形蟲、黑隱翅蟲(幼蟲)、蟑5.下列何者會捕食螞蟻(選項:草齡幼蟲、蝴蝶、蜜蜂、以上皆非)6.下列敘述何者正確?(選項:螞蟻為群落服務並不為任何好處、所有的螞蟻都具有兵蟻階級、螞蟻群都是雜食性的昆蟲、螞蟻是一種真社會7.螞蟻的一生為何?(選項:卵-幼蟲-蛹-成蟲、卵-若蟲-成蟲、卵-若蟲8.古代有一種「蚳醢」，為帝王食補。請問蚳醢為下列何者?(選項:螞9.螞蟻和下列何者有親戚關係?(選項:蟑螂、白蟻、螳螂、胡蜂)10.白蟻和下列何者有親戚關係?選項:蟑螂、獨角仙、天蛾、胡蜂)11.請問螞蟻透過甚麼溝通?(選項:費洛蒙、聲音、震動、以上皆是)12.請問下列何種螞蟻會使用蟻酸攻擊?(選項:蠻蟻亞科、家蟻亞科、此為我於民國一一○年三月三十號螞蟻講座後發出的滿意度調查問卷:由此表可知，有四個人對於我在台上的表現給三分、二個人給我四分、五個人由此表可知，有四個人對於我在台上的表現給三分、三個人給我四分、四個人由此表可知，有十一個人在這次專題演講後，對於螞蟻知識有更深的了解、零由此表可知，有七個人在這次專題演講後，不會想要進一步了解螞蟻的相關知識或主動閱讀相關書籍、四個人會想要進一步了解螞蟻的相關知識或主動閱讀此為我對同學們發出的專題講座滿意度調查問卷:簡報得稍微有點多，我還沒看完就換下一頁。可以講得再慢一點搶答部分應先設定好平板、電腦，以免讓大家等太久由此表可知，有六個人認為不用改進、兩個人認為可以先把平板和電腦設定好、一個人認為我講太快了、一個人認為簡報上面的字有點多、一個人認為簡根據我發出的表格，有五題難度為低，三題難度為中，五題難度為高，平均難度為中。卻有很多題目連一半的答對率都不到，我覺得是因為我的問卷題目太刁鑽而且太難。下次可以考慮把題目的難度降低且不要出那麼刁鑽，會更我將研究結果統一整理成一個表格，來表達我的結果與討論，還有結論與此次有關螞蟻的獨立研究，我主要是以文獻探討中內容分析的方式呈現簡報。並且加入問卷測試小學生對於螞蟻知識的了解程度。以下是我針對文獻探討、前測問卷、講座推廣和後側問答的結果、結論和建議製作的表格:一、維基百科https://reurl.cc/6yV2xO二、超罕見的詭異螞蟻！澳洲原住民最愛的甜食「蜜罐蟻」，號稱行走食物櫃https://reurl.cc/R1Dao6三、臺灣生命大百科:獵食火家蟻https://reurl.cc/7oLnKN四、知本火蟻https://reurl.cc/r84Ga4五、認識火蟻https://reurl.cc/e87lGb六、巨山蟻屬https://reurl.cc/Q3xlpZ七、下課花路米第749集-小小螞蟻大世界(上)https://reurl.cc/VXVoW6八、下課花路米第750集-小小螞蟻大世界(下)https://reurl.cc/OqWom9九、下課花路米第1181集-台灣還有紅火蟻?https://reurl.cc/odG3K3十、流言追追追第51集-螞蟻剋星https://reurl.cc/9X8A5j流言追追追第4集https://reurl.cc/KjZg3e螞蟻的構造https://reurl.cc/pmndVZ螞蟻亞科列表https://reurl.cc/5ox9qv"}, "1676358325.425173": {"單位": "", "標題": "土壤與農作物雨害防護", "作者": "", "發布日": 0, "摘要": "", "全文": "農作物所遭受的水害種類又可概分(1)因河流氾濫沖毀或埋沒、(2)因地勢低窪積水不退、(3)因雨點打擊、以及(4)因地下水位高或土壤內部排水不良等因素所造成。其中由第(1)、(2)類所造成的災害需由增設堤防及改善排水系統等水利工程方面予以解決，第(3)類因素所造成的傷害可由設置遮雨棚以獲得舒解。但是雖然政府近年已投入大筆經費進行有關排水與防洪工程的增建與改善工作，農民也普遍投資設置遮雨棚，可是因水害導致的農業損失與物價波動並沒有顯著的減少。以西螺地區蔬菜生產專業區為例，專業區內雖經農地重劃，設有地面排水系統，農民為避免臨時性的淹水為害，菜園地面多又填土提高，且採用遮雨棚處理以防葉片遭雨打傷害，然於梅雨和颱風季節仍常遭受水害，不僅損害農民收益，嚴重時甚至造成全省蔬菜價格及物價的波動。顯見為減低因降雨所造成的水害，除進行相關的工程建設外，土壤本身的管理技術也需加強改進。\n在當地進行的土壤內部排水特性調查指出，當地土壤多屬沖積土，具有明顯的質地層理，且土壤剖面中普遍有銹斑的存在，顯示土壤內部排水不良，常有短暫時期因土壤中水分過多，阻斷空氣之進入，導致土壤處於還原狀態，因此發生鐵之移動與聚集，其後當土壤中過多的水分逐漸退去，空氣進入後再轉為氧化狀態，因而造成銹斑。另由於底土多未呈現灰藍色，顯示當地地下水位並不高。因此可推知，當每年雨季土壤中水分出現短期過多的情形時，將阻斷土壤中氧氣供應，使得蔬菜根系發生缺氧傷害，不僅影響養分和水分的吸收，葉片也因無法得到足夠蒸散的水分而萎凋，導致蔬菜生長不良或死亡。\n就雨害的防護措施言，農民現行的填土措施雖可減少豪大雨時土表浸水的時間，但並不能阻止雨水進入土壤中，由於土壤內部排水能力不好，平日灌溉進入的水量已逐漸累積於土層中，因此不論土表是否浸水，只要進入土壤中的雨水過多也會對根系產生傷害，所以綿綿細雨的梅雨期間，蔬菜的價格照樣可能飛漲。另由於當地地下水位並不高，所以也不適合應用暗管排水技術改善表土中的通氣孔隙量。因此欲改善雨後表土的通氣不良問題，唯有設法減少土表的入滲速率，並打破沖積土中質地層理對土壤內部排水的阻礙，使表土大孔隙中的水儘速向下排掉，才是有效的防護方法。"}, "1676358386.2668562": {"單位": "", "標題": "土壤與農作物旱害防護", "作者": "", "發布日": 0, "摘要": "", "全文": "臺灣地區易發生乾旱為害的地區主要在西南部平原地區，除梅雨和颱風時期有雨水可供利用外，當地的灌溉水源主要依靠曾文水庫、烏山頭水庫供水，當供水吃緊時，必需以民生用水和工業用水為優先供應對象，因此未來可供農業使用的水量勢必因人口增加和工業發展而逐漸減少，而發生旱害的頻率將逐年增加。但是目前區內可供建設為水庫的處所並不多，少數可供設置水庫的地點又面臨地方民眾反對訴求的壓力，因此未來必將使用地下水源以因應整地、灌溉等短期間內需要大量用水的需求，但若無法將抽用的地下水予以補注，將會產生地層下陷的危害。\n因此在有關旱害的防護措施上，除需發展節水灌溉技術，以及提高作物的水分利用效率外，也必需發展適當的土壤水分管理技術，使在旱季可減少土面的蒸發，並將底土中儲存的水分引入表土供應作物根系吸收利用，以減少旱季時抽用地下水灌溉的需求；在雨季則需儘量截留雨水進入土壤，利用深厚土壤中的大量孔隙做為自然的水庫，並將多餘的重力水快速導入地下水層中，不僅可以補充旱季時所抽用的地下水資源，也可以避免作物根系發生缺氧傷害。"}, "1676358423.9361486": {"單位": "", "標題": "土壤與農作物寒害防護", "作者": "", "發布日": 0, "摘要": "", "全文": "台灣地區寒霜害多發生於輻射冷卻強烈的冬季夜間，因此提供熱源以補充作物植冠經由長波輻射所損失的熱量也是可行的防護方法之一。由於輻射冷卻強烈的夜間其白天亦多為晴天，因此可利用土壤儘量儲存白天所獲得的日射能量，到夜間再將儲存的熱能釋出供防護使用。適當的管理土壤水分不僅可提高土壤中的可儲存熱量，也可提高熱能在土壤中進出的移動速率。此種防護方法對糧食與飼料作物最為適用，因為這些作物的栽培面積大但經濟價值並不高，因此並不適合採用一些高投入的防護方法，但是由於這些作物的高度並不高，土壤中蓄積的熱量要上傳到植冠上部並不困難，因此利用土壤水分管理的技巧，使土壤成為夜間的熱源，將是一種經濟有效的防護方法。"}, "1676358513.8236718": {"單位": "", "標題": "葉面施肥", "作者": "", "發布日": 0, "摘要": "", "全文": "葉面施肥的肥料\n(一)氮肥\n    幾種形態的氮(銨態氮、硝態氮、醯胺態氮，甚至氨基酸)都能為葉面所吸收和代謝。當作物吸收這四種形態氮時，能促進對鐵、鋅等微量營養元素的吸收。常用的葉面氮肥有尿素、硫酸銨、硝酸鉀。\n(二)磷肥\n    葉面吸收磷酸比其它無機和有機化合物更快。聚磷酸鹽施用量可比正磷酸鹽高三倍，也不會燒傷葉片;聚磷酸銨的中性溶液可以在葉面上維持幾天供葉片吸收，而不致蒸乾或晶析，而正磷酸銨的中性溶液就易蒸乾留下殘渣。常用的葉面磷肥有過磷酸鈣、磷酸一鉀、磷酸一銨。\n(三)鉀肥\n    葉面吸收鉀素的範圍很廣，如無機和有機鉀化合物，而傳統使用的是氯化鉀、硫酸鉀、硝酸鉀等。試驗證明，葉面對正磷酸鉀鹽、焦磷酸鉀鹽等的吸收率明顯高於傳統鉀鹽。常用的葉面鉀肥有硝酸鉀、磷酸一鉀、硫酸鉀。\n(四)微量元素\n    常用的微量營養元素是硫酸鹽，近來多採用鉗合型如木質素磺酸、氨基酸、腐植酸、EDTA、CDTA、DTPA等，使銅、鋅、鐵、錳等鉗合物更易溶解，有利於葉面吸收，並加快微量營養元素的轉移性能，更易於與農藥混溶，有可能產生協同效應，增強各自的作用，微量營養元素的鉗合物比無機鹽更適宜有效。\n(五)不適於葉面施肥的肥料\n1.非水溶性的化肥\n2.具有揮發性氨的肥料\n3.含氯根的肥料"}, "1676358624.5781932": {"單位": "", "標題": "葉面施肥的時機與位置", "作者": "", "發布日": 0, "摘要": "", "全文": "葉面施肥的時機與位置\n(一)葉面施肥的位置\n    要使葉面噴施收效顯著，必須盡量把液肥噴到嫩葉上，形成液膜，停留在葉上至少數小時。在選擇有利自然條件下，滲入一些潤濕劑(或展著劑)於液肥中，防止噴施時的流失現象。流失過程中，液肥集中在作物葉緣，會損傷葉子。\n1.在植物體中移動比較慢的元素，應噴在新葉上，效果較好；\n2.葉背的組織較疏鬆，噴施於葉背面，養分吸收快些。\n(二)掌握噴施的時間\n    為保證肥料的最佳效果，不要在強烈的陽光下施用，避免蒸發，造成溶液濃度增高而燒傷葉面，也避免有露水或下雨時施用。最適宜噴施時間要選擇每日濕度較高的時間，一般在上午出太陽前後的清晨和太陽要下山的傍晚進行。\n(三)葉面施肥的時期\n    由於各類作物生長期不一樣，營養生長和生殖生長時期也不同，很難規定具體的最佳噴施時期。一般禾谷類作物苗期到灌漿期前都可以噴施；瓜、果類作物在初花到第一生理幼果形成到幼果膨大時，都可以噴施葉面肥。\n    微量元素葉面肥料允許在任何期間噴施。\n(四)施用量\n    以量少、次多、濃度低為原則，否則易發生葉燒現象。\n(五)葉面吸收營養元素的速率\n    葉面施肥方便，效果快，可以進行多次噴施作為土壤施肥的補充。選擇適宜的噴施間隔期，將有助於肥料效率的提高，葉面吸收營養元素所需要時間。"}, "1676358692.242433": {"單位": "", "標題": "葉面施肥的濃度", "作者": "", "發布日": 0, "摘要": "", "全文": "https://sstc.nchu.edu.tw/zh_TW/spread-content/node/1564579303001\n\n(一)葉面肥料的濃度\n\n    掌握濃度既要不傷害作物葉面，又要節省肥料，提高功效。\n\n    各種作物均應有不同施肥率，如一般休眠樹較無性樹可用較高施肥率進行噴施液肥；老葉較嫩葉可用噴施較高濃度的液肥。如果液肥pH值接近中性時，一次可噴施含有多種營養元素的液肥。\n\n(二)依作物需求調整濃度\n\n    葉面噴施濃度並非一成不變，因作物種類、生育期、氣候等而異，以尿素為例，一般噴施濃度為0.2-2%，禾本科作物的適宜濃度較寬，可從0.5-5%，常用1%左右，生長不良及幼苗時期可適當降低，蔬菜類較禾本科作物低，桑、茶、果樹和溫室蔬菜應再低一些。即雙子葉植物較低，單子葉植物高些。尿素以晴天早晨有霧水時或傍晚施用效果較好。"}, "1676358757.1483529": {"單位": "", "標題": "葉面施肥的優點", "作者": "", "發布日": 0, "摘要": "", "全文": "https://sstc.nchu.edu.tw/zh_TW/spread-content/node/1564579346001\n\n    葉面肥料使用時均配製成液體肥料，其優點是：\n(一)肥效高\n    一般情況，施用氮、磷、鉀化肥後，常常受土壤酸度、土壤含水量和土壤微生物等因素的影響，而被固定、淋失，降低了肥效。葉面施肥就能避免這種現象，提高肥效。葉面肥料直接噴施在葉面上，不接觸土壤，避免由於土壤吸附、淋洗等帶來的不利因素，因此利用率較高，可以減少肥料總用量。\n    葉面施肥具有較高的利用率，還有刺激根部吸收的作用。在保持同等產量的條件下，通過多次葉面噴施可節約土施氮磷鉀肥料的25%。\n(二)省時省工\n    把葉面肥料與農藥混合進行一次作業，不僅可節省操作費用，還能提高某些農藥的功效。經研究證明，葉面肥料中的無機和有機氮化合物對農藥的吸收和轉移有促進作用；表面活化劑能改善肥藥在葉面的擴散性和延長易溶養分的吸收時間，葉面肥料的酸鹼值能產生緩衝作用，提高某些農藥的吸收率。\n(三)作用快\n    葉面肥料比根系肥料作用快，葉面施肥可以及時迅速的改善植物營養狀況。一般來說，葉面施肥要比根部吸收快，如葉面噴施1-2%濃度的尿素水溶液，經測定在24小時後便可以吸收1/3；噴施2%濃度的過磷酸鈣浸提液，經過5分鐘後便可以轉送到植株各個部位。由此看出，葉面施肥可以在短時間內補充植物需要的養分，保證植物正常生長。\n(四)污染低\n    硝酸鹽是導致致癌物質之一。由於不科學和過量施用氮肥，促使硝酸鹽在地表水系和蔬菜類作物中存在和積累，已引起人們日益加劇的關注。人吸入的硝酸鹽有75%來自於蔬菜類作物，因此採用葉面施肥於蔬菜種植，不但可以減少土施氮肥，保持既定產量，還可得到減免污染的蔬菜。\n(五)針對性強\n    作物缺什麼就補什麼？植物生長發育過程中，如果缺乏某一種元素，它的缺乏症會很快從葉面上反應出來。例如，作物缺氮素時，往往出現苗黃；缺磷素時，苗發紅；缺鉀素時，植株發育遲緩，葉色暗綠，最後出現橘紅色褪綠斑點。可以根據作物葉片缺乏特徵，及時噴施補充缺少的元素改善症狀。\n(六)補充根部對養分吸收的不足\n    植物苗期，根系不發達，吸收能力弱，容易出現苗黃、苗弱現象。植物生長後期由於根功能衰退，吸收養分能力差。藉由葉面施肥可以增加產量的作用。尤其是對果樹、蔬菜類作物，葉面施肥效果較為明顯。\n    但葉面肥料的濃度和一次用量均有限制，不能大量噴施，特別是大量養分元素和次量養分元素，因此適用於用量較少的微量元素。"}, "1676358801.1421945": {"單位": "", "標題": "影響葉面施肥效應的因子", "作者": "", "發布日": 0, "摘要": "", "全文": "https://sstc.nchu.edu.tw/zh_TW/spread-content/node/1564579376001\n\n(一)環境的影響\n    環境因素包括溫度、光照、濕度、雨量等。由於葉面肥一般施用量少，而且水溶液濃度低，所以噴在葉面上要保持一定時間的濕潤狀態，才能通過葉面吸收進入葉片的角質層，以溶液態在角質層及原生質膜外圍發揮其養分源的作用。如果環境不合適會或多或少地影響其效果。一般在高溫、強光、乾燥、雨天等環境中噴施葉面肥，效果差，因此，噴施葉面肥的時間，一般在午後或傍晚前噴施為宜。\n(二)葉面肥質量的影響\n    葉面肥成分比較復雜，在生產過程中如何保證各種養分之間的標準與比例，是葉面肥質量的關鍵。由於生產廠家生產工藝技術差等因素，必定影響葉面肥的質量。葉面肥質量差，當然使用效果就差，所以在選用某一種葉面肥時，一定要注意其產品質量。\n  另外，由於葉面肥的有效成分和營養元素不同，如不根據作物生長情況和要求使用，也達不到增產目的。一般情況下，為促進作物生長，應選用氮、磷、鉀元素為主的葉面肥；改善品質，應選用以磷、鉀元素為主的葉面肥；如果是以糾正或補缺作物某一種元素，應選用能補充某一種元素的葉面肥等。同時，在使用過程中也可以使用多種葉面肥作對比試驗，從中選擇效果最好的品種。\n(三)使用技術的影響\n    使用技術包括使用濃度、次數、時期、部位等。\n1.使用濃度與次數\n    葉面肥中植物生長調節劑，只在植物體內起補充養分和調節作用，一般使用濃度低和用量少，它不能代替施肥。由於不同作物對濃度有不同的要求，濃度過低達不到效果，過高往往會造成藥害，因此，不同作物選擇適宜的濃度，對提高使用效果是十分重要的。使用次數也要根據作物生長期長短來考慮，一般作物生長期短的噴1-2次，生長期長的作物和果樹通常要噴2-3次，也可以適當多噴1-2次。\n2.使用時期\n    由於各類作物生長期不一樣，營養生長和生殖生長時期也不同，很難規定具體的最佳噴施時期。一般禾谷類作物苗期到灌漿期前都可以噴施；瓜、果類作物在初花到第一生理幼果形成、再到幼果膨大時，都可以噴施葉面肥。要按照葉面肥的使用說明書進行，也可做試驗，找到效果最佳使用時期。\n3.使用部位\n    葉面肥一般要噴在葉、花、果上。噴在葉面上要求均勻，上、中部最為重要，尤其是嫩葉、頂部葉片一定要噴到，最好把葉面葉背都噴到。噴花、果時要注意保護花蕾，使用濃度不宜過高。噴果時幼果和果柄一齊噴，效果會更好些。"}, "1676359946.2875745": {"單位": "", "標題": "氮", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n氮為蛋白質中胺基酸及葉綠素的主要成分。\n\n氮缺乏時的共通徵狀為生長受阻，主根長卻無側根，發育不良，葉片小而硬。\n\n輕微時，老葉黃化，幼葉呈淡綠色；嚴重時，由老葉漸向幼葉黃化，且老葉易枯乾脫落。\n\n因氮在植物體內之移動性屬中等，缺乏時葉片的黃化遍及全株，但下位葉有較嚴重的傾向。\n\n氮過量時易造成植株生長旺盛，葉片大而薄，莖葉軟弱，生殖生長延遲，抗病蟲害能力降低。\n\n二、發生條件\n\n(一)氮缺乏：\n\n當土壤肥力貧瘠。\n\n當土壤酸鹼度過高(pH值7.0以上)時，氮肥易揮散。\n\n氮肥施用量不足時。\n\n施用碳氮比過高的未腐熟堆肥及遭大量雨水或灌溉水淋洗的粗質地土壤。\n\n(二)氮過量：\n\n化學氮肥及含高氮有機質肥料施用過量。\n\n長期引灌含氮過高如食品廠廢水及禽畜場的糞尿水。\n\n三、改善方法\n\n(一)氮缺乏：\n\n依據「作物施肥手冊」不同作物氮肥推荐量施用，並應以基肥及追肥分次施用。\n\n粗質地及肥力貧瘠土壤可施用大量肥分較低且腐熟較高的有機質肥料；如落葉堆肥、樹皮堆肥、泥炭等等。\n\n若缺氮係屬土壤過於乾旱所引起時，應適量灌溉或噴灌，以維持土壤濕潤。\n\n若因缺水無法灌溉或噴灌時，可用尿素溶液0.2-0.5%作葉面施肥，每週1-2次。\n\n發現作物植株缺氮時，可用250-500ppm的氮素溶液，即約尿素5-10克溶於10公升水中，多次噴灌於土表，可快速補充作物所需的氮肥。\n\n一般作物適宜的土壤酸鹼度(pH)為5.6-6.8之間，土壤酸鹼度在6.8以上時，勿再施用石灰質材或鹼性物質，以減少土壤中氮肥的揮散損失。\n\n(二)氮過量：\n\n減少氮肥施用量。\n\n土壤中氮肥含量過高時，可灌水淋洗除去過量之氮素。\n\n酌量提高磷及鉀肥的比例用量。\n\n豆科作物根部會自然著生根瘤菌，固定空氣中氮素，以供應植株生長所需，過量施用氮肥易造成植株葉片生長茂盛，而影響結莢數量及品質，各種豆科作物氮肥需要量可參考作物施肥手冊的推荐量施用。"}, "1676360013.4471753": {"單位": "", "標題": "磷", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n磷為構成細胞核酸的重要成分，對細胞之分裂、碳水化合物及蛋白質之合成 及呼吸作用等均有密切關係。\n\n作物磷缺乏時葉片變小呈暗綠色，成熟延遲，葉柄可能產生花青素而呈紅色或紫色， 同時葉柄、葉片及果實上會發生壞疽斑點。\n\n磷在作物體內的移動性中等與氮相近，因此缺磷時徵狀也遍及全株， 通常老葉較新葉嚴重。徵狀發生從葉尖往葉基發展，最後葉變成褐色而死亡。\n\n缺磷時植株生育受阻，根部發育不良，根數少且短並呈褐色。\n\n至於磷過量情形在台灣地區並不多見。\n\n二、發生條件\n\n土壤母質不同，磷的含量也不同。在酸性及鹼性土壤，磷易變成不溶性形態而導致缺磷。\n\n強酸性土壤(pH 5.5以下)的鐵及鋁離子活性高，容易與磷形成不溶性形態的磷酸鐵及磷酸鋁而導致缺磷； 當土壤有機質含量低時，缺磷更為嚴重。\n\n土壤酸鹼度高(pH 7.0以上)者，土壤中的鈣含量高，磷容易被固定形成磷酸三鈣或磷石灰，而發生缺磷。\n\n磷肥施用量不足時。\n\n溫度低或土壤排水不良時，作物根對磷的吸收力減弱，會導致磷的缺乏。\n\n土壤中過多的鉀、鎂、銅及鋅會抑制磷的吸收，而導致磷缺乏現象。\n\n三、改善方法\n\n調整土壤的酸鹼度至微酸性或中性，通常土壤pH值低於5.5以下時， 可施用石灰石粉、白雲石粉(苦土石灰)或矽酸爐渣，具良好的改善效果， 施用量宜配合該土壤的石灰需要量。\n\n施用有機質肥料，利用其分解時產生的有機酸，與鐵、鋁形成有機鉗合物， 減少磷的固定量及使已被固定的磷釋出，供作物吸收利用。\n\n在磷固定量大的土壤(如紅壤、紅黃壤)，磷宜深施或條施，避免表面撒施。\n\n依據「作物施肥手冊」不同作物磷肥推荐量施用，多數中短期作物對磷肥的大量吸收時期， 均集中在生育前中期，因此，磷肥最好在施基肥時全量施用，最慢也應在生育前中期施畢。\n\n發現作物缺磷時，可用液態磷肥(如磷酸一鉀、磷酸一銨等) 60-120ppm，多次灌施於表土。\n\n或用磷酸一鉀、磷酸一銨、磷酸一鈉等溶液0.3-0.5%濃度，每週葉面施肥1-2次。\n\n引入菌根菌及溶磷菌，以增進作物對磷的吸收及增加磷的溶解性。"}, "1676360064.649018": {"單位": "", "標題": "鉀", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n鉀在作物體內移動容易，因此缺鉀的徵狀都先發生在老葉。\n\n作物缺鉀初期植株生長速率減緩，葉片呈現暗綠色，之後在老葉的葉緣及葉尖處出現白、黃或橘色的點或條紋，繼而發生褐變或壞死。\n\n作物缺鉀嚴重時，徵狀會逐漸擴延至新葉，最後整株作物枯死。\n\n根系的伸展也會因缺鉀而受阻，且根系容易腐爛。\n\n作物缺鉀時，對乾旱及病蟲害的抵抗力會減弱，同時作物的品質會嚴重受損，尤其是蔬菜及果樹。\n\n至於鉀過量情形在台灣地區並不多見。\n\n二、發生條件\n\n鉀肥施用量不足。\n\n砂質或腐植質少的土壤，鉀容易隨雨水或灌溉水流失。\n\n強風化的熱帶酸性土壤對鉀的固持能力較低，因此鉀容易淋洗流失。\n\n腐植質過多而排水不良的土壤，因土壤呈還原狀態(空氣進入量少)而缺氧，容易產生硫化氫、有機酸、二氧化碳、甲烷等有害物質，致使鉀的吸收受阻而缺鉀。\n\n鉀固定力強的粘質土壤。\n\n鹽分地或石灰質土壤有過多的鈉及鈣離子，因拮抗作用會阻礙鉀的吸收。\n\n土壤過乾或土溫底，鉀在土壤中的移動及作物根系生長將受抑制，導致鉀的吸收受阻。\n\n土壤中含過量的氮、鈣或鎂使鉀的吸收不良。\n\n三、改善方法\n\n依據「作物施肥手冊」不同作物鉀肥推荐量及方法施用。\n\n作物缺鉀時可施用氯化鉀或硫酸鉀，若在淋洗嚴重的地區可採用緩效性鉀肥(如裹硫氯化鉀及裹硫硫酸鉀等)。\n\n砂質地土壤鉀肥容易流失，鉀肥宜分多次施用。\n\n發現作物缺鉀時，可用液態鉀肥(如氯化鉀、硫酸鉀等) 500-750ppm，多次灌施於表土。\n\n或用0.5 %濃度硫酸鉀溶液，每週葉面施肥1-2次。\n\n土壤表面可採取敷蓋或覆蓋植物殘株，以減少鉀肥的淋失。\n\n在強酸性土壤宜施用石灰資材，調整土壤酸鹼度(pH值)至5.6-6.8之間，以增進鉀被土壤膠體固持的機會。"}, "1676360114.4488046": {"單位": "", "標題": "鈣", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n鈣主要存在於作物細胞膜或細胞壁中，其功能為中和作物體內過剩的有機酸， 強化細胞壁組織及調節體內水分。\n\n因移動性小，故缺鈣時老葉仍正常，但新葉及新根無法正常生長；缺鈣障害開始發生時葉片尖端部分黃白化，伸展停止，老葉則不變，根部變短而粗，嚴重時黃白化的幼葉漸漸褐變且葉緣部分枯死，極端缺鈣時葉易縐捲，根尖褐變枯死。\n\n果菜類的代表性缺鈣症狀，如番茄的尻腐病，白菜、芹菜及蘿蔔等的心腐病。\n\n至於鈣過量在台灣地區並不多見。\n\n二、發生條件\n\n特定作物如番茄、青椒、結球白菜、甘藍等，栽培期間遇高溫時，植體生長量加大，而鈣無法足量吸收供應時，最容易發生鈣的缺乏。\n\n酸性岩(如花崗岩)風化而成的土壤，多數鈣含量偏低。多雨時土壤鈣容易流失而導致缺鈣，尤其是在坡地果園土壤。\n\n交換性鈣含量偏低的強酸性土壤或砂質土壤，在有機質肥料施用少，化學肥料施用多時的情形下，隨化學肥料施入而產生的硫酸、鹽酸與硝酸離子將助長鈣的流失。\n\n銨態氮肥、鎂與鉀肥施用過多時，將影響作物對鈣的吸收而引起鈣缺乏的現象，尤其是在果園施用過多的銨態氮及鉀肥時，更容易引起缺鈣。\n\n當氣溫高昇，作物的蒸散作用劇烈時，吸收的鈣與水分同時移動至蒸散劇烈的成熟老葉，因此鈣無法充分運送到先端的幼葉，致幼葉容易發生鈣缺乏。\n\n雨量過少的乾旱年，土壤水分不足，土壤中的氮素與鹽類濃度增加，致使鈣的吸收變差。\n\n尤其在氮素肥料施用過量且乾旱延續時，土壤微生物的活動受抑制，銨氮態無法硝化，根吸收過多的銨態氮而使鈣的吸收變差，進而導致缺鈣。\n\n三、改善方法\n\n強酸性(pH 5.5以下)土壤可於作物栽種前，每公頃施用農用石灰2-3公噸，翻犁時與土壤充分混合， 以調整土壤酸鹼度同時補充鈣肥。\n\n以0.3-0.5 %氯化鈣溶液，或0.3 %磷酸一鈣溶液葉面施肥於新葉部分。\n\n土壤中鈣含量充足，但土壤水分不足時，鈣的吸收會明顯受阻，應適量補充水分，尤其乾旱年應特別注意適當的灌溉。\n\n易缺鈣的果園應控制氮及鉀肥的施用量，切勿過量。\n\n肥料一次施用量過多時，土壤鹽類濃度過高，鈣的吸收變差，為避免在土壤中引起高濃度的鹽害，肥料應採取全層混施或分次施用。\n\n防止作物鈣缺乏的根本對策，除調整土壤酸鹼度外，施用堆廄肥等有機質肥料，維持適宜的土壤水分含量，及不連作鈣吸收量多的作物，均能避免作物發生缺鈣徵狀。\n\n引入菌根菌及溶磷菌，以增進作物對磷的吸收及增加磷的溶解性。"}, "1676360161.0932362": {"單位": "", "標題": "鎂", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n鎂為葉綠素的重要成分，直接影響光合成作用，同時也是若干酵素的成分，幫助磷在作物體內移動，並參與油脂的合成。\n\n因鎂在作物體內的移動性大，故缺鎂時徵狀先呈現於老葉。\n\n一般中短期作物葉緣及葉脈間部份引起黃化，與葉脈周圍的綠色成明顯對比。\n\n果樹缺鎂徵狀自老葉或果實枝條附近的葉片出現，缺乏時生育初期正常，直至果實或子實肥大期徵狀開始顯現，老葉的葉緣部份開始黃化，而後展延至葉脈間，然葉脈仍呈綠色，嚴重時，發生褐變及壞死終而落葉。\n\n一般鎂缺乏除葉部症狀以外，其他器官並無異常。\n\n至於鎂過量在台灣地區並不多見。\n\n二、發生條件\n\n含交換性鎂少的強酸性砂質土壤，容易產生缺鎂。尤其在土壤中交換性鉀及交換性鈣含量多時，使鈣鎂比大於6－8，或鎂鉀比小於2時易發生鎂的缺乏。\n\n坡地的酸性紅壤及黃壤，土壤中的鎂易因降雨而流失。氮肥使用過多使土壤酸化也會加劇鎂的流失，而易發生缺鎂現象。\n\n需鎂肥較多的果樹，在產量增加時，鎂被果樹吸收的量也會增加，若無添加鎂肥，則易缺鎂。\n\n果樹結果過多，若不實行疏果，則會加重鎂的缺乏。一般而言，有種子者比無種子者較易出現缺鎂症，種子多的較種子少的易出現缺鎂症。\n\n作物根系生長受抑制，如土壤積水、發生病蟲害等，會造成根系鎂肥的吸收量不足，而產生鎂缺乏現象。\n\n養液或介質栽培作物，鎂肥供應量不足時也易引起鎂的缺乏。\n\n三、改善方法\n\n作物發生缺鎂症狀時應儘早以1－2 %硫酸鎂溶液每隔7－10天葉面噴施一次，連續噴施5－6次。\n酸性土壤施含鎂資材，每公頃苦土石灰(白雲石灰)約1,000公斤或氫氧化鎂600公斤，溶於適量水中均勻灑施，為節省勞力也可直接以粉末施用後再行灌溉，以提昇土壤酸鹼度(pH值)並補充鎂素。土壤酸鹼度在6以上缺鎂時，每公頃可施用硫酸鎂200公斤。一般果園石灰質材的施用，建議於冬季休眠期時，撒施後再翻入土中。\n石灰質土壤果樹缺鎂，可施用硫酸鎂，每株0.5－1.0公斤或行葉面施肥。\n應避免過量施用鉀肥及鈣肥，以維持適當的陽離子平衡，若土壤中鉀與鈣含量多時，應酌量增加鎂肥的施用。\n防止鎂缺乏的根本對策，可於每年每公頃施用氧化鎂150－300公斤，使土壤中交換性鎂維持在30－50 ppm，或葉片鎂含量在0.2 %以上。"}, "1676360205.8997884": {"單位": "", "標題": "鐵", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n作物缺鐵的共通徵狀，新葉黃化，嚴重時黃白化。\n\n葉片中肋與側脈保存綠色，而葉脈間成淺綠至黃白化，缺鐵轉劇時整片葉片黃白化，但老葉不發生缺乏症狀，若不予補救，則新生之葉片小型化，新芽伸長緩慢甚至停止。\n\n二、發生條件\n\n土壤為中性至鹼性，或施石灰過多時，土壤中的鐵變為不溶性。一般而言，土壤酸鹼度升高一單位，鐵的活性(Activity)降低一千倍，而減少鐵被作物之吸收，易引起缺鐵。\n\n栽培介質鹽分含量高，且pH值近中性至鹼性，使作物根部吸收鐵的能力降低，極易導致鐵缺乏。\n\n鐵在作物體內移動性慢，土壤過分乾燥，或鹽類異常累積時，鐵之吸收受阻，新芽及葉極易出現鐵之缺乏症狀。\n\n磷肥施用過量，易使過多的磷與鐵在根組織內外形成沈澱，使作物體內鐵輸送受阻，導致上位葉鐵不足而產生缺乏症狀。\n\n錳及銅元素吸收過多時，使作物體內的鐵易被氧化成三價的不活性鐵，導致鐵的缺乏。\n\n養液或介質栽培作物，鐵供應量不足時也易引起鐵的缺乏。\n\n三、改善方法\n\n作物發生缺鐵症狀時，應儘早以0.1－0.5 %硫酸亞鐵或0.05 % EDTA鉗合鐵溶液，每隔一週葉面噴施一次，連續噴施數次，噴施時間以黃昏太陽較弱時為佳。由於鐵在作物體內移動性不佳，葉面施肥時沒有噴到的部分不易恢復綠色，因此，宜以低濃度溶液連續噴施數次，至葉片全部轉綠為止。\n果樹新梢出現黃白葉時，可在樹幹打入鐵釘，或在樹幹上開直徑5厘米深10厘米左右之穴，放入適量之檸檬酸鐵或磷酸鐵，再覆蓋原樹皮或以臘封之。\n施用生理酸性肥料如硫酸銨、氯化銨及氯化鉀等，可降低土壤酸鹼度，而增加鐵之活性。若過量施用石灰質肥料使土壤成為鹼性或鹼性土壤，則可在作物種植前視土壤酸鹼度高低，每分地施用硫磺粉100－300公斤，並充分與土壤混合，降低pH值，增加鐵的活性。\n中性至鹼性土壤，鐵的活性容易降低，但鉗合鐵則不會，因此，每分地可施用2－3公斤的鉗合鐵，或施用較為便宜的硫酸亞鐵5－6公斤。\n多施堆肥，除可增加土壤有機質提高緩衝能力外，堆肥分解時亦能溶解土壤中的鐵及產生鐵鉗劑化合物，可被植物吸收利用。"}, "1676360254.2243948": {"單位": "", "標題": "錳", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n缺錳徵狀常出現於新葉或老葉，葉脈間黃化而呈淡綠色，僅與中肋及主要葉脈鄰接部分仍保持綠色，與缺鐵徵狀類似，但葉脈週邊殘留之綠色較缺鐵明顯，且嚴重缺乏時也不會呈現白化，此有別於鐵缺乏。\n\n缺錳葉片陽光透過葉背時，徵狀更為清晰可見，嫩葉之葉脈呈綠色細網狀而葉肉為淡綠色。\n\n輕微缺乏時，徵狀於生長後期即消失，嚴重缺乏時，葉脈轉為灰暗綠色，葉肉仍保持淡綠色，徵狀持續至生長後期仍不消失。\n\n許多作物之成熟葉片錳含量若低於20 ppm，即呈現缺錳徵狀。\n\n作物種類不同錳缺乏出現部位會有極大差異，多數果樹及長期作物錳缺乏徵狀均由新葉先發生，再漸次擴展至下位葉，老葉維持正常，但短期葉菜類錳缺乏徵狀新葉及老葉均可能出現。\n\n二、發生條件\n\n石灰質土壤或為矯正土壤酸度而施用過量石灰時，土壤酸鹼度(pH)偏鹼，作物容易缺錳。\n\n錳在土壤中通常以氧化物存在，其溶解度隨土壤pH升高而降低，又作物僅能吸收二價錳，當土壤pH大於6.5時，二價錳易被微生物氧化為四價錳，而無法為作物吸收利用，因此，許多酸鹼度高於6.5之土壤，作物易發生錳缺乏症。\n\n排水不良且有機質含量豐富之石灰質土壤，作物更易缺錳。\n\n錳含量原本較低之土壤，例如酸性之砂質土壤，經長期淋洗其錳含量甚低。\n\n乾旱時，易發生缺錳症。\n\n養液或介質栽培作物，錳供應量不足時也易引起錳的缺乏。\n\n三、改善方法\n\n當出現缺錳徵狀時，儘快於葉面噴施0.25－0.50 % 硫酸錳水溶液(先分別配製0.5－1.0 %之硫酸錳液和0.25－0.5 %之消石灰液，再等量混合而成，以防藥害)，每隔7－10天噴施一次，直到症狀消失為止。若噴施錳乃浦或鋅錳乃浦等藥劑以防治病害時，亦有防治缺錳的放果。\n酸性土壤缺錳時，以土壤施用硫酸錳200－400公斤/公頃或葉面噴施來防治，鹼性土壤缺錳仍以葉面噴施效果較佳。\n石灰質土壤或石灰施用過量引起的缺錳，除以葉面噴施硫酸錳外，可採用生理酸性肥料如硫酸銨等，以降低根圈土壤pH值，而提高土壤錳的有效性。"}, "1676360304.304769": {"單位": "", "標題": "銅", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n銅為氧化還原酵素的成分。因銅移動性差，缺乏時如同多數微量元素一樣，缺乏會立即引起葉片黃化。\n\n果樹症狀首先出現新梢葉片，葉色深綠而捲曲，但在葉基處下方綠色枝條， 常因碳水化合物的聚積而產生黃色斑點。\n\n此黃色斑點將逐漸擴大而使莖幹或枝條遭受環割，繼而流出水溶性的棕色樹膠，致葉片脫落而遺留黃色椏枝，最後椏枝在未完全發育前即枯死。\n\n在原來嫩枝或嫩芽枯死處將再長出許多新芽，而後生成窄小的徒長葉。\n\n銅缺乏不但影響葉部的發展，同時亦會影響果實的外形和品質。\n\n缺銅時，聚積在果實外表皮的流膠將使得果實出現紅棕色的斑點或形成裂果，缺乏嚴重時，果實在尚未成形前即已掉落。\n\n蔬菜缺銅一般新葉變小，細長，葉肉黃化，葉片自葉緣向內捲曲，但也有老葉向下捲曲者如青江菜。\n\n二、發生條件\n\n施用量隨土壤酸鹼度，作物的種類及以往有否施用而異。由於作物每年吸收的量很少，且銅淋失量甚微，故施用一次後，可發揮數年的殘效，因此不需要每年施用，否則將產生銅之毒害。\n\n果樹每公頃施用硫酸銅7公斤，或於早春時每棵施用硫酸銅40－80公克，蔬菜每公頃施用硫酸銅5－10公斤，每五年撒施一次即可。\n\n葉面噴施：\n\n果樹以0.1－0.5 %硫酸銅溶液每年噴施一次，蔬菜以0.05－0.1 %硫酸銅溶液每週一次，連續噴施3－5次，既可補充銅也具有殺菌的效果。\n\n同時，若噴施含銅的病害防治藥劑，如波爾多液，亦具補充銅之效應。\n\nCuOCl、CuO及Cu—EDTA亦可用於葉面噴施。在有機質土、鹼性土壤或不利根系發展的環境下，葉面施肥的效果較佳。\n\n施用豬糞製造的有機質肥料，但不可每年連續大量施用，以免引起毒害。\n\n長期作物如果樹等可於適當時期採取葉片，送本場分析化驗，據以提供第二年的施肥參考。\n\n各種果樹葉片採樣時期及方法，請洽詢本場土壤肥料研究室，電話為(03)4768216轉330-335。\n\n三、改善方法\n\n調整土壤的酸鹼度至微酸性或中性，通常土壤pH值低於5.5以下時， 可施用石灰石粉、白雲石粉(苦土石灰)或矽酸爐渣，具良好的改善效果， 施用量宜配合該土壤的石灰需要量。\n\n施用有機質肥料，利用其分解時產生的有機酸，與鐵、鋁形成有機鉗合物， 減少磷的固定量及使已被固定的磷釋出，供作物吸收利用。\n\n在磷固定量大的土壤(如紅壤、紅黃壤)，磷宜深施或條施，避免表面撒施。\n\n依據「作物施肥手冊」不同作物磷肥推荐量施用，多數中短期作物對磷肥的大量吸收時期， 均集中在生育前中期，因此，磷肥最好在施基肥時全量施用，最慢也應在生育前中期施畢。\n\n發現作物缺磷時，可用液態磷肥(如磷酸一鉀、磷酸一銨等) 60-120ppm，多次灌施於表土。\n\n或用磷酸一鉀、磷酸一銨、磷酸一鈉等溶液0.3-0.5%濃度，每週葉面施肥1-2次。\n\n引入菌根菌及溶磷菌，以增進作物對磷的吸收及增加磷的溶解性。"}, "1676360351.5831017": {"單位": "", "標題": "鋅", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n鋅是若干酵素的成分，具有氧化還原反應之接觸作用，其最重要的功能為參與生長荷爾蒙主成分Tryptophan的合成。\n\n因移動性差，鋅缺乏徵狀首先出現於新梢葉片或上位葉，徵狀會因作物種類不同而略有差異。\n\n一般而言，中度至嚴重缺乏時，葉片變小而畸型，節間縮短而呈小葉簇生狀(Little leaf and resetting)，有些作物尚伴有葉片黃化徵狀，葉脈間黃化而呈黃綠色，但與葉脈緊鄰部分則保持綠色。\n\n一般作物的成熟葉片鋅含量低於20ppm，即呈現缺鋅徵狀。\n\n二、發生條件\n\n鹼性且經長期淋洗作物之砂質土壤，鋅含量偏低，作物容易缺鋅。\n\n石灰質或石灰施用過量的土壤，鋅的有效性低，作物容易缺鋅。因在高pH值和游離碳酸鈣存在下，鋅易被土壤粘粒和碳酸鈣吸附，且鋅的氧化物溶解度降低，因而此等土壤鋅的有效性低。\n\n另土壤中碳酸氫根(HCO3)會抑制作物對鋅的吸收，而加重鋅的缺乏。\n\n有機質土壤，鋅與有機物形成穩定化合物，致作物無法吸收利用而導致缺鋅。\n\n土壤磷含量過高或長期施用過量磷肥，使土壤中的鋅更易被吸附而降低其有效性，導致作物缺鋅。\n\n作物罹患毒素病或柑桔罹患立枯病，使鋅在作物體內的運送受阻而引起缺鋅，其缺乏與土壤中鋅的含量及有效性無關。\n\n養液栽培作物，鋅用量不足。\n\n三、改善方法\n\n土壤施用：\n\n每公頃施用硫酸鋅40－80公斤或氧化鋅30－50公斤，以條施或穴施可減少土壤固定，效果較佳，土壤施鋅應避免過量，以防引起毒害。\n\n葉面噴施：\n\n發生缺鋅徵狀時，儘快以0.25－0.50%硫酸鋅水溶液加半量消石灰以防藥害，每隔7－10天噴施於葉面，直到症狀消失為止，防治病害的藥劑如鋅錳乃浦亦有防治缺鋅的效果。\n\n施用牛糞製造的有機質肥料，但不可每年連續大量施用，以免引起毒害。\n\n土壤中鋅的有效性以pH值在5.6－6.8之間為最高，過酸或過鹼土壤宜以石灰或硫磺調整土壤pH值至適宜的範圍內。"}, "1676360408.335319": {"單位": "", "標題": "硼", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n硼與細胞分裂、花粉受精、養分吸收及糖分之輸送等有密切關係。\n\n因硼移動性較慢，其徵狀發生在頂梢之生長點、幼葉、塊根、莖、或果實等生長發育中的組織，其徵狀因作物而異，歸納如下：\n\n(1)頂梢的生長點和心葉生長受阻，白化或褐化而壞死，刺激側芽生長(部份側芽也隨即壞死)而呈叢生或簇生狀。\n(2)葉柄或莖增厚變粗短，有裂痕且木栓化，或有水浸狀壞死。\n(3)葉片畸型，變厚易碎，或皺縮捲曲，部份作物兼有葉脈間黃化徵狀。\n(4)缺硼抑制花粉、花蜜形成及花粉管發育而影響受粉，造成嚴重落花及落果。\n(5)果實畸型，發育緩慢，果皮或果肉局部木栓化或壞死而凹陷呈腫瘤狀，或果肉局部呈水浸狀，果皮增厚，果汁率低，種子發育不良。\n(6)塊根或塊莖內木栓化或黑心。\n一般作物對硼的忍受性低，施用過多即引起毒害，其徵狀為成熟葉的葉緣或葉尖黃化、燒焦、捲曲或乾枯，或呈褐色斑點，毒害嚴重時極易造成落葉。\n\n二、發生條件\n\n(一)硼缺乏：\n\n雨量豐地區的河床地、石礫地、砂質土、或紅壤等，因長期淋洗作用使土壤中硼含量極低，作物容易缺硼。\n\n酸鹼度(pH值)高的石灰質土壤，硼易被固定，有效性降低，而引起作物缺硼。\n\n乾旱時，硼在土壤中的移動性和作物的吸收受阻，更易發缺硼。\n\n氮及鉀肥過量施用也易造成硼的吸收不良。\n\n養液栽培作物，硼用量不足。\n\n(二)硼過量：\n\n硼施用過量。\n\n灌溉水中含硼過高。\n\n三、改善方法\n\n(一)硼缺乏：\n\n(1)土壤施用：\n缺硼土壤每公頃施用硼砂5－10公斤，缺乏嚴重地區可酌量增加用量。\n十年生或每株果實收量約60公斤之柑桔缺硼時，每株可施用硼砂50公克。\n壤土或更粘土壤，其殘效可維持3至4年以上，硼砂不可施用過量以防毒害。\n(2)葉面噴施：\n經診斷為缺硼或出現缺硼徵狀時。蔬菜以0.1－0.2 %硼砂或硼酸溶液，每週噴施一次，噴施3－5次即可。果樹自開花前至果實發育初期，以0.25%硼砂或硼酸溶液，每隔一週行葉面施肥，噴施2－3次即可達到防治效果。注意不可過量或連年噴施，以防毒害。\n(3)乾早季節，注意灌溉。\n(4)酸鹼度(pH)高之土壤採用生理酸性肥料，如硫銨等，以降低根圈土壤pH值，提高硼的有效性。\n(5)長期作物如果樹等可於適當時期採取葉片，送本場分析化驗，據以提供第二年的施肥參考。\n各種果樹葉片採樣時期及方法，請洽詢本場土壤肥料研究室，電話為(03)4768216轉330-335。\n\n(二)硼過量：\n\n(1)避免過量施硼。\n(2)若因施硼過量而引起毒害時，短期內可增施氮肥及加強灌溉，以促進枝葉生長， 稀釋作物體內硼濃度，減輕毒害程度。"}, "1676360456.0725477": {"單位": "", "標題": "鉬", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n鉬在植體內主要參與硝酸還原作用及豆科作物的固氮作用，缺乏時，氮的新陳代謝即受阻，因此，鉬缺乏症狀頗似氮的缺乏。\n\n鉬因參與豆科作物的固氮作用，一般而言，豆科作物較常發生鉬缺乏，但一般作物及園藝作物也可能發生。\n\n鉬缺乏時老葉顏色變淡或出現黃化，隨著缺乏程度的加深，其他部位的葉片也會顯現缺乏症狀，通常在葉綠尚未發生捲曲和枯萎前，葉脈間先顯現黃綠色或黃色斑點，嚴重時斑點數激增，且在葉片未完全成熟前即已掉落。\n\n鉬缺乏症狀主要顯現於葉部，而果實部份則不大受影響。\n\n二、發生條件\n\n有機質低的粗質地土壤，其鉬含量甚低，生長中之作物容易缺乏。\n\n土壤屬強酸性(pH＜5.5)者，常有缺鉬現象，主要原因為鉬與土壤中的鐵、鋁結合成不溶性的鉬酸鐵或鉬酸鋁，使作物無法吸收。\n\n土壤中磷酸多時，鉬較容易被作物吸收，而磷酸不足時，鉬易缺乏。\n\n鉬在土壤中移動至作物根部的機制，在土壤溶液鉬高於4 ppb時，主要靠質流作用，而當低於4 ppb時則靠擴散作用。土壤水分含量低時，質流及擴散均將受阻，而影響鉬在土壤中的移動和根系的吸收，故易導致作物缺鉬。\n\n根圈附近若存在高濃硫酸根(SO4-2)、銅、錳或銨態氮(NH4-N)，將抑制作物對鉬的吸收，而誘發作物鉬缺乏症狀。\n\n三、改善方法\n\n(1)酸性土壤施用石灰石粉或白雲石粉，可提高土壤中鉬的有效性，以矯正鉬的缺乏。其中又以白雲石粉的效果較佳。\n(2)鎂可促進作物對鉬的吸收，含鎂肥料的施用可減輕鉬的缺乏。\n(3)鉬含量偏低的土壤，應避免大量施用含硫酸根的肥料，且儘可能以硝酸態氮取代銨態氮肥。\n(4)施用磷肥可增加土壤溶液中鉬的濃度，可增進作物根部對鉬的吸收，有助於鉬缺乏的改善，但其原因未明。\n(5)乾旱季節土壤水分偏低，應適時合宜的灌溉，以促進鉬在土壤中的移動。\n(6)土壤施用：\n缺鉬土壤每公頃可施用鉬酸鈉或鉬酸銨200－300公克，唯實際施用量應隨土壤及作物種類而異。\n由於施用量少，宜與大量元素肥料混合均勻後，再施用。鉬肥除含氧化鐵、氧化鋁多，且固定能力強的酸性土壤，需酌予增加施用次數外，一般土壤不需每年施用，每施用一次即可發揮數年的殘效。\n(7)葉面噴施：\n經診斷為缺鉬或出現缺鉬徵狀時，以0.05－0.1 %鉬酸鈉或鉬酸銨溶液噴撒葉面，每隔7－10噴施一次，直至症狀消失為止。"}, "1676360501.8416157": {"單位": "", "標題": "鹽類", "作者": "", "發布日": 0, "摘要": "", "全文": "https://cook.tydares.gov.tw/dystrophy.aspx\n\n一、徵狀\n\n當土壤中的可溶性鹽類達到某種濃度時，即對作物根部水分及養分吸收產生障礙，主要係因土壤溶液濃度過高引起滲透壓升高，而阻止作物根部吸收水分，導致作物無法正常生長甚至枯死。\n\n土壤鹽類累積可由土壤及作物受害所表現的徵狀加以判定，歸納如下：\n\n(1)種子發芽不良或發芽後枯萎：種子經發芽試驗確認發芽率正常，播種後呈現種子發芽不良或發芽後枯萎，即表示土壤中可溶性鹽類過高而產生肥害。\n(2)凋萎現象：作物因施肥過量或土壤長期鹽類的累積，使根部無法正常吸收水分，而導致葉片凋萎，此種凋萎即使大量澆水於土壤中也不會恢復。\n(3)根部褐化或伸展受阻：作物發生上述凋萎現象時，若將根部挖出，便可發現根部變為褐色(通常為白色)，此種狀態持久下去作物就會枯死。\n另外一種現象是根部伸展受阻，其中以移植型的作物最明顯，當作物移植一段時日後生長仍遲緩，將植株挖掘出來觀察根部，根部由於土壤可溶性鹽類過高，仍侷限於原育苗介質中無法伸展。\n(4)葉片邊緣乾枯：此種情形作物根部並沒有嚴重受害，僅係葉片中鹽類濃度偏高，隨著水分的蒸散，葉的周緣鹽類濃度高，造成部分細胞死亡。\n(5)植株軟弱、徒長及葉色濃綠：發生此一徵狀主要係氮肥施用過量，容易使作物抵抗病蟲害的能力降低。\n(6)葉片呈現小斑點，嚴重時則出現塊狀或帶狀褐化乾枯，甚至整片葉枯乾掉落，此種徵狀的發生主要為微量元素(如鐵、錳、硼等)的毒害。\n二、發生條件\n\n(1)缺乏雨水淋洗及高溫環境：\n一般農民設施栽培肥料施肥用量與露天栽培無異，然而，因設施栽培缺少雨水淋洗，縱使有灌溉措施，灌溉水量不足以將可溶性鹽類淋洗到較深的土層，或經由排水而移除多餘的鹽類，造成可溶性鹽類累積在表土情形。另外，設施中的溫度常高於設施外的溫度，土壤水分蒸發量大，底土中的可溶性盬類隨水分的毛細管作用往上移動至表土，待水分蒸發後，可溶性鹽類便累積在表土。\n(2)單位面積投入高肥料量：\n設施栽培在高溫多濕的環境下，作物生長快速，複種指數增加，單位面積肥料投入量也隨之增加，土壤中可溶性鹽類累積更加嚴重。\n(3)不當的施肥措施：\n土壤中過量的鹽類累積，容易造成作物生長不良，農民常誤認為係肥料量不足，而投入更多的肥料，此一增施肥料措施，將使土壤鹽類累積問題益形嚴重。\n(4)有機質肥料品質不佳及過量施用：\n據調查分析資料顯示，市售的有機質肥料品質並不穩定，加上農民長期大量施用時，也會因施用不當而導致土壤累積多量鹽類，致使作物種子發芽及生長不良。\n三、改善方法\n\n(一)預防措施\n\n(1)定期採取土壤樣本送改良場分析，瞭解土壤性質及肥力情形，並依據推荐的方法管理土壤及施肥。\n(2)儘可能選用粗質且成分低的有機質肥料，藉以改善土壤物理、化學及生物性。\n(3)一般蔬菜適宜的土壤酸鹼度(pH值)為5.6-6.8之間，除非土壤酸鹼度低於5.6(強酸性)或明顯的缺乏鈣及鎂元素，可依據改良場推荐的石灰資材種類及用量施用外，千萬不可盲目施用，以免造成土壤酸鹼度過高及鈣、鎂元素的累積。\n(4)肥料三要素中氮肥最容易流失及揮散，需適時適量補充，磷及鉀肥較不易流失，土壤中常存有高量的磷及鉀肥，因此，有機質肥料或化學肥料應選用氮肥高而磷及鉀肥低的種類或配方。\n(5)以雞糞、豆粕、魚粕及動物殘體為原料製成的高成分有機質肥料，不可過量及長期連續施用，以避免土壤中可溶性鹽類累積。\n(二)改良方法\n\n(1)浸水：\n以大量的水進行多次反復的灌溉浸泡及排水，沖去鹽類離子，或採取夏天雨季時掀開塑膠布讓雨水充分的淋洗，所需淋洗時間視鹽類累積程度不同而異，但至少應有2-3個月的淋洗時間。\n(2)深耕或客土：\n依據土壤分析結果如表土(0-15公分)鹽類累積較高，且底土(16-30公分)無鹽類累積現象時，可採取深耕混合表底土方法以稀釋鹽類離子的濃度，或採取換入外處移來的乾淨土壤。\n(3)刮除0-5公分的表土：\n一般土壤中可溶性鹽類會隨毛細管水上升至0-5公分的表土中，意即0-5公分的表土鹽類含量最高，因此，可採取刮除0-5公分表土的方法降低鹽類含量。\n(4)種植耐鹽作物或綠肥作物：\n土壤可溶性鹽類累積尚不至於太嚴重時，可連續種植數作的玉米、田菁等吸收土壤中累積的鹽類離子，並將植株砍除移走供給其他田區當綠肥之用。\n"}, "1676360917.8784578": {"單位": "", "標題": "增進土壤肥力的觀念及管理要領", "作者": "", "發布日": 0, "摘要": "", "全文": "https://book.tndais.gov.tw/Magazine/mag16-3.htm\n增進土壤肥力的觀念及管理要領\n文/圖  卓家榮  \n\n農藝作物、園藝作物及畜牧飼料作物是農業生產的重心，然而影響各種作物產量及品質的因素，不外乎有：土壤因子、作物品種、環境氣候、栽培管理及病蟲害防治。也就是指任何地區的「土壤生產力」要好，就需要重視這五大因素，從經濟的觀念上看，有投資才有收益，所以當選擇最好的作物與土壤配合。土壤是作物生產之母，要增進土壤生產力首先要認識土壤，知道怎樣才是肥沃的土壤，進而要去知道自己耕作的土壤有什麼缺點或限制作物生產的因子，再加以改善那些缺點，並消除生產的限制因子，使成為肥沃的土壤。從認識土壤到瞭解缺失因子，從保育到增進土壤肥力，都是確保作物增產及高品質的基礎。\n\n什麼是「肥沃的土壤」\n\n土壤是培育作物的培養基，因此，所謂「肥沃的土壤」是指最能滿足作物生產需求的土壤，它需要充分供應作物所需的「營養分」及「水分」。這些營養分包括氮、磷、鉀、鈣、鎂、硫、錳、鐵、硼、鋅、銅、鉬、氯等，至於其他功能元素，如鈉、釩、鈷、矽、硒等微量元素，依植物不同需要也有差異。\n\n除了營養分及水分充分供應以外，「氧氣」的供應亦不可忽略，尤其旱作的需要尤切，作物的根系都需要氧氣供應呼吸作用，因此，土壤的通氣性在旱作中為一重要因子。\n\n肥沃的土壤還要能提供適當的環境（包括生物性及非生物性），使植物根部發揮其功能，並且提供根系伸展的孔隙及環境的緩衝性（包括酸鹼度、鹽度及溫度等緩衝性）。\n\n從上所敘，可知「肥沃的土壤」，並不難求，只要有良好的土壤管理，都有希望把貧瘠的土壤改成肥沃的土壤，使土壤充分供應作物所需的營養分、水分及氧氣三大要件，加上保持良好的土壤物理性、化學性及生物性，將有助土壤肥力的維持及保育。有了充分的土壤肥力，再加上選擇適應該地區氣候的作物及品種，兼之有良好的栽培管理方法，要達到高生產力是不難做到的事情。\n\n如何管理土壤達到增進土壤地力\n\n台灣位於亞熱帶～熱帶地區，高溫、多雨、多濕的環境，加上高度密集耕作的利用土壤，與溫帶之一年一期作物是不同的，致使本省農地容易引起地力衰退、土壤疲乏或忌地症的發生，尤其旱作及蔬菜連作引起的土壤問題是值得重視及加以研究解決的。\n\n每一個地區的土壤，因氣候環境、耕作系統及土壤母質均不同，加上不同之施肥及管理，土壤特性也會有或多或少的差異，有的地力較好，有的地力較差，要增進土壤地力或肥力，首先要知道該塊田有什麼毛病或限制生產的因子存在，以下將本省常見的土壤問題列出，從問題的發生如何診斷及如何解決，分別說明如下：\n\n一.土壤酸鹼度不適合及土壤酸化現象\n\n（一）問題發生：本省部分太酸（PH在5.0以下）或太鹼（PH在7.5以上）的土壤，易使土壤中的植物營養分轉變為無效性，使作物不能適應，尤其土壤酸化最為常見，其原因不外雨水大量淋洗及母質酸性、植物吸走大量正離子養分、不當的施用過多酸性肥料、及過量有機酸所致，加上土壤緩衝力不佳時，更易顯現酸化現象。\n\n（二）診斷土壤酸鹼度：常用酸鹼度電極測定法及石蕊試紙顏色測定法。測定酸鹼度時，應使土壤與水混合攪拌後測定，不應在土壤乾燥下測定，因為測定土壤酸鹼值是測定在水溶液中的氫離子濃度。\n\n（三）解決要領：\n\n施用中和劑：酸土施用石灰鹼性質材（如農用石灰、苦土石灰、白雲粉、蚵殼粉等），中和土壤則應配合有機質施用。鹼土施用酸性材質（如硫磺粉、稀硫酸等），中和土壤則不應過量，可採用逐年漸進中和方式去改良。\n施用有機質在酸土或鹼土中，有助各種營養之有效性。\n緊急補充葉面施肥可暫時改善太酸或太鹼的土壤性質，這是治標的方法，徹底改善土壤才是治本之道。\n二.缺乏土壤有機質\n\n（一）問題發生：台灣位在多雨高溫及多濕的環境下，土壤有機質分解較快，尤其是旱田或山坡地更是缺乏有機質，在農田耕地中，本省約有65﹪之土壤缺乏有機質，旱作或果樹的生產力會降低，農民施用化學肥料量會增加，造成浪費，甚至無法提高生產力，反而使土壤病害增加及污染環境。這種問題土壤要增進施肥效果。必需從增加土壤有機質著手，才能收事半功倍的效果。要提高旱作生產力必需更加注意土壤有機質的保護，因為土壤有機質的功效甚多，能夠：\n\n改善土壤物理特性：改良土壤團粒構造，使土壤鬆軟及穩定土壤，以促進通氣及排水。\n增加土壤保水能力。\n緩慢釋放植物所需之營養元素。\n鉗合微量營養元素可協助植物營養元素之溶解度。\n增加土壤之緩衝能力，使土壤之酸鹼反應緩和。\n吸附及交換植物營養元素，提高肥料緩效性。\n提供土壤有益微生物之活動，使土壤微生物能抵抗大量病菌的發展。\n減少人為或天然之毒性物質及作用。\n部分成分有助植物生長之功效。\n色黑有助吸熱及早春種植等。\n從上述可知，土壤要達到以上十點功效，就必須增加土壤的有機質含量。\n\n（二）診斷缺乏有機質之方法：除了寄送有關農業機構，分析土壤有機質的含量之外，也可以略用肉眼觀察，如土壤乾燥後很硬，或顏色很紅、很黃，沒有團粒構造，這些都可能是缺乏有機質的特徵。土壤有機質含量愈多，一般的顏色都較為暗色。\n\n（三）解決缺乏有機質的要領：需要施用有機物或有機肥料，以增加土壤有機質的來源，也可種植綠肥作物（如太陽麻、田菁、紫雲英、虎瓜豆等）。在栽培系統中要採用輪作系統，尤其以豆科輪作最利於增進土壤有機質。在管理上應增加覆蓋，減少土壤沖刷及表土流失，這也是保養土壤有機質的方法之一。稻田轉作時，應減少耕犁，於不整地狀況下栽培旱作，對土壤有機質之保存甚為有利。近年來腐植酸及泥炭土的應用，對土壤有機質的增加穩定頗有幫助。\n\n三.土壤物理性不良　\n\n（一）問題的發生：台灣之山坡地土壤常見紅壤或黃棕壤，土壤屬酸性又缺乏有機質，物理性甚差，團粒構造有待改善，且保水力差，甚易乾旱，乾燥時頗為堅硬，這是典型的貧瘠土壤。土壤質地太粗或太黏，也會構成問題土壤，太粗則保水差，太黏重的土則太密實，易排水不良，引起根系生長不良。地區性排水不良或地下水位過高，易使土壤缺乏氧氣，旱作的根系則生長很淺，也易發生倒伏。有的地區及山坡地有乾旱現象，旱季時就更為明顯或提早發生旱害，致使作物或果樹養分吸收不良，也成了問題所在。\n\n（二）診斷土壤物理性不良之方法：測定土壤質地（砂粒、坋粒、黏粒含量）常見以沈降機械分析、浮秤法及用手觸摸分級之方法，判斷是否太黏或太砂；觀察土壤孔隙度，是否太密實。以感覺觸摸時，取少量土樣，以水濕潤後搓捏，呈砂礫感是砂土；若呈滑膩感覺則含坋質高；很黏重，可搓捏成條的則含黏粒多。土壤的孔隙度、土塊或團粒構造，很容易用肉眼觀察，其土壤通氣或排水的情形。\n\n（三）解決土壤物理性之不良：\n\n排水不良：地區性排水不良較經濟的方法，是選擇耐水作物或品種，或利用高畦栽培。排水系統可採用簡便排水式或暗管排水方法，排水系統之建設應特別注意排水效率及使用年限的經濟效益。\n土壤構造不良：土壤孔隙度或團粒構造不良，一般都增施有機質及石灰配合，如較鹼性土壤則只施有機質即可。土壤深層改良，可用深犁或氣壓式或水壓式，將深土疏鬆或深層施肥。\n土壤太砂或太黏：除了選擇能適應這種不良土壤之作物或品種外，可採用客土及施用有機質來改善這種不良的質地。太砂的土壤保水性及保肥力均差，有機質可大力協助；太黏的土壤孔隙度差，濕時如泥漿乾時如石，有機質可使團粒構造形成，增加孔隙以利進水或排水。客土可多利用建築房屋時表土，以免寶貴的表土，埋入建築的下面。\n四.土壤營養分不平衡\n\n土壤營養分不平衡所造成的情況1（一）問題的發生：不平衡或過量施用化學肥料，將造成營養元素間吸收的擷抗作用，或引起元素吸收的障礙及植體內代謝問題，無論巨量、次量、微量元素都不能過量，例如：氮過多作物易徒長，枝葉繁茂，易遭病害，不易開花或落果，產期調節不易成功；磷太多將使作物生長慢，使微量元素吸收不足；而鉀施用太多，則使作物缺乏鎂、鈣等元素，微量元素施用過多，則作物中毒引土壤營養分不平衡所造成的情況起生長障礙。長期施用肥料，應注意土壤營養是否有某些元素過量，以免發生問題。\n\n（二）診斷營養分之不平衡：土壤中營養不平衡不能用肉眼看出，但植物的症狀可以偵察出來，或以植體化學分析配合土壤分析診斷也可得知。土壤也要定期分析診斷檢查，就如人的身體檢查一樣重要，尤其是密集耕作系統，至少每三、四年須診斷檢查一次。問題土壤或植物分析診斷之採樣，應採取有代表問題的土壤或植體，最好也能採到沒問題的隔壁或附近之土壤或植體,將更能使診斷者快速找到問題所在,分開二包分裝,一起寄送各農業改良場及大專有關土壤診斷服務單位分析。\n\n（三）解決土壤營養分不平衡之要領：\n\n瞭解作物品種的特性：因為各種作物對土壤中的營養需求有差異，經診斷症狀後，即可採取作業，缺乏營養者則以緊急葉面補充，再進而改善土壤施肥之治本方法，如酸鹼不適者可以加以調整，使營養吸收平衡。如因某些營養過量不平衡所引起，則需花費較長的時間去改良，可施用腐熟度較高的有機質（如各種堆肥、腐植泥炭土等），去吸附，減少過量的危害，使其控制達到平衡。\n配合輪作系統：土壤營養不平衡，可利用不同輪作作物能吸收多量養分而減少土壤的危害，或以旱田水田輪作系統，使達營養均衡的狀態，再配合適當的施肥，即可改善土壤養分不平衡的缺失。\n抗衡的施肥：山坡地無法以水田輪作時，只靠雨水淋洗過多的營養是不易的，除上述所提施用高腐熟度之有機質外，可以依過量的頡抗元素補救，如磷過量所引起的微量元素缺乏，即以深灌施肥或葉面施肥補充；如鉀肥過量易引起缺鎂，則採用硫酸鎂或矽酸鎂等鎂肥的抗衡作用，以大量減少某種養分過多所引起之危害。\n五.鹽類及重金屬累積的問題及污染\n\n（一）問題的發生：污染及不當的灌溉水，或是化學肥料之鹽類使用過多，都會引起土壤鹽類及重金屬累積。因為土壤有吸附的能力，鹽類及重金屬雖每日少量灌入或施入除被水流失或作物吸走外，長期日積月累的結果，勢必引起問題，這是保育土壤必須重視的問題。\n\n（二）診斷鹽類及重金屬污染之累積：最準確的是用化學分析測定所含鹽類及重金屬量。其他尚可用電導度計測定，在電導度大於4mmhos/cm時，多數作物生長會受到阻礙。鹽類的累積可用肉眼觀察，診斷時從曬乾的表土，可觀察到白色粉末或晶體狀的鹽類，鹽類累積過多者有白色物出現，許多蔬菜當然種不好。另外須從灌溉水源加予注意，以便觀察灌溉用水是否受工廠之污染。\n\n（三）解決鹽類及重金屬污染之累積：因密集耕種作物時，大量施用鹽類肥料所引起的累積，可採用旱田水田輪作，水田耕作時可洗去大量的可溶性鹽類；或選擇較耐鹽的作物，因作物的耐鹽性有差異；施用有機質對洗鹽類也有助益，因有機質分解之有機酸，可增加鹽的溶解度。重金屬累積之污染則不易洗去或去除，少量污染尚可加入有機質吸附，以稀釋作用減少作物吸收；如嚴重污染則不應種植食用作物或飼料作物，要避免污染進入人類的食物鏈；如要種植則需慎選非食用植物，如林木植物、纖維特用作物等。客土也可解決鹽類或輕度重金屬污染之問題，以稀釋土壤的方式，減少高濃度鹽類或重金屬之危害，如困難客到表土，而使用底土時，客土後施用大量有機質即可大大改善底土，再施用肥料後即可增加肥效。\n\n六.表土流失問題\n\n（一）問題的發生：土壤肥力在台灣坡地土壤受流失的威脅影響甚鉅，尤其山坡地高墾為果園後的水土保持甚為重要，表土是歷經長年自然改良的寶貴土壤，山坡地如表面植物保護缺乏時，優良的表土很薄，大多會被沖刷洗走，不只是個人的土壤肥力損失，也將引起水庫、河川及水源之污染或汙積泥砂。表土的流失同時伴隨著肥料的流失，肥料減少的損失不可忽略。\n\n（二）診斷表土流失：這是相當容易的判斷，只要看在雨中流出的水，是否帶有泥色或混濁，即可知表土是否流失。\n\n（三）解決表土流失的要領：表土要有保護，可採用覆蓋或草生栽培，尤其是以果園的草生栽培最為有效，而且雨季時不必除草，表面上看草生會吸收競爭部份施入的肥料，但吸入肥料經砍割覆蓋或犁入後，肥分又回到土壤，對多年生果樹的表土肥力，甚有助益，草生栽培又可使雨水深入土層，增加有機質、使土鬆、保肥性好，實為一舉數得之效。\n\n七.土壤病蟲害問題\n\n（一）問題的發生：引起土壤病蟲害的因子甚多，可能因土壤物理性、化學性或生物性不良所引起。因為病菌大量繁殖或植物的耐病力降低，就易引起作物根系病害。土壤病害的發生與氣候環境及灌溉水來源有密切關係；種苗的傳染病菌也不應忽視，健康的育苗是很重要的。\n\n（二）診斷土壤病蟲害：要精確瞭解根系發生之病害，以鑑別病菌之種類，需要專門的鑑別方法。根系枯死的原因，可能是生物性或非生物性所引起，或互為因果關係。線蟲的危害根系較易觀察出來，在根上會有膨大凸起或瘤狀的症狀發生。\n\n（三）解決土壤病蟲害之要領：治療土壤病蟲害，包括化學藥劑處理、物理處理（如高溫）、生物處理等方法，另外可利用土壤改良劑，以化學、物理、生物性等不同方式改良土壤，使病蟲害不易繁殖或增加作物抗性，而達到控制土壤病蟲害的目的。例如施用石灰質材，使土壤由酸調整後，也有改善病蟲害之效果；施用有機質使土壤改良，也可減少土壤病害發生，但應注意糞便類有機質，如未經處理，易致多種菌或蟲的感染，當埋入土中為宜，也可減少臭氣發生。\n\n化學藥劑是現代農業生產不可少的藥方，安全使用並無大問題。土壤微生物之保育，有益微生物對抗病菌，這種生物制衡不可忽略，不當或過量使用藥劑，對土壤中有益微生物及根圈微生物是有害的。\n\n八.連作的土壤問題\n\n（一）問題的發生：許多旱作常因連作引起問題土壤，因不同作物或栽培、管理、施肥，都可能引起不同的連作問題，一般不外乎在土壤物理性，化學性或生物性上發生問題，常見的是病菌或蟲體孳生過多、有毒物質、鹽類累積或養分不平衡所致。\n\n（二）診斷連作問題：一種或同類作物連作次數後，發生生長不良，施肥並不能完全改善，常見如幼苗的枯萎及爛根。生長點或新葉不正常或不伸展的問題發生。\n\n（三）解決連作之問題土壤：連作常發生問題土壤的作物，就不宜採連作，輪作栽培的好處甚多，尤其旱田水田輪作最好。連作之問題土壤除改種其他作物，也可在酸性土壤施用石灰質材改善酸化或改善土壤微生物環境；可施用有機質改善或種植綠肥，有機質吸附有毒物及分解有毒物質，並有制衡土壤微生物之功效，加上補充巨量、次量及微量元素，可減少營養分之不平衡。生物性之制衡作用，也可採用施入有益微生物的應用。另外改變土壤環境（如浸水、翻曬等），也可防止部分連作問題之發生。連作田常有大量的地上部或地下根部，這些殘質也可能是問題的根源，因此，清除田間殘質，可減少毒物質或病蟲害的危害。\n\n結 論\n\n以上所常見的八大問題，不是所有的土壤都會存在，因此，首先須從您自己耕作的田中判斷，可能有那些問題或限制地力的因子存在，進而解決這些危害地力的瓶頸，土壤的地力或肥力，自然會改觀，有了健全的保育土壤，才有健康的土質，也才能增進土壤的生產力。因應當前農業生產，產期調節及高品質是重要的條件，需要進行產期調節及高品質生產時，土壤的配合是需要的，多做觀察、試驗及記錄，需要有更多的「試驗的精神」，我們的農業將展現更美好的明天。"}, "1678416770.822171": {"單位": "", "標題": "水稻箱育秧苗立枯病(白絹病)", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌學名：有性世代 Athelia rolfsii (Curzi) Tu & Kimbr.無性世代 Sclerotium rolfsii Sacc.Pythium spp.、Fusarium spp、Mucorspp.、Rhizopus spp.英名：Seedling blight in nursery boxes.\n箱育秧苗立枯病之病原菌種類甚多且複雜，有來自稻種帶菌，亦有來自土壤棲息菌類。有關病原菌之研究，大部分僅止於鑑定其所歸之屬別，每一屬常有多種病原菌，各菌之分類、分布、寄主及生活史等之研究則不多。近年來，觀察田間箱育秧苗立枯病發生之類別，臺灣以S. rolfsii, Fusarium spp., Pythium spp., Mucor spp.及Rhizopus spp.等為主要病原菌，這5屬病原菌均屬於土壤棲息真菌，由稻種帶菌引起立枯病之案例不多。\n箱育秧苗立枯病之病原菌大多為土壤棲息菌，育苗箱所用栽培土或育苗時之氣候環境不同，則秧苗立枯病之病原菌就會有不同。各病原菌感染不同生育期間之秧苗，其症狀及病株在育苗箱中分布型式均會不同。稻種播種後在堆積期間受害，嚴重者將無法發芽，縱能發芽長出之芽亦因已受病菌危害而呈黃褐色，移出綠化時即枯死，未枯死之病苗生育嚴重受阻，移出約一星期亦常褐枯死亡。綠化後秧苗，一般以叢集型危害方式，病苗在育苗箱中呈類似圓形之分佈，並向外擴展。病苗最初由下位葉開始枯黃或從葉尖開始呈缺水青枯症狀，被害苗隨之枯死並轉變為赤褐色，拔取病苗可見其葉鞘基部、根冠及根組織都已枯死。本病之病原菌多屬於土壤棲息菌，普遍存活於各土壤中。本病之病原菌多屬於腐生力強之兼性寄生菌，偶發性引起植物病害，寄主範圍廣。\nAthelia rolfsii 有性世代為擔孢子，自然界不易發現，擔子器棍棒狀，著生於分枝菌絲頂端，2-4個擔子柄，其上產生擔孢子。擔孢子梨形或橢圓形、無色、單孢、表面平滑。無性世代為Sclerotium rolfsii，營養菌絲呈絹白色，直徑5.5-8.5µm，有明顯扣子體（Clamp connection），細胞有2個細胞核。另可產生較纖細直徑3.0-5.0µm的白色菌絲，細胞壁較薄有隔膜，無扣子體，經常由3-12條平行排列成菌絲束，不形成分生孢子，主要繁殖體為菌核。菌核由上述之菌絲束互相纏繞而成，大小為0.5-0.8公釐，結構可分為4層，最外層是由暗褐色厚壁細胞所形成的厚皮層，次層稱為殼層由2-4層厚壁細胞連接排列而成，第三層為皮下層由6-8層薄壁細胞所構成，最內層為髓部由菌絲狀長形細胞疏鬆地組成，菌核之細胞均含有2個細胞核。\nPythium spp. 管狀菌絲無色或白色、透明、分枝多、細長無隔膜，菌絲生長快速，在顯微鏡下常可見透明無色菌絲中之原生質快速流動。孢子囊在菌絲頂端或中間形成，球形、橢圓形、長形或香腸形。孢子囊發芽長出一至數條發芽管或長出一短菌絲後在其頂端形成孢囊（Vesicle），孢子囊中之原生質移入孢囊中，再分化成100個以上之游走孢子。游走孢子釋放出後，遇水數分鐘即澎脹、靜止並圓化而包在囊內（Encyst），再產生發芽管，發芽管可感染寄主組織或形成孢囊及游走子，反覆發芽數次。有性世代係由藏精器產生授精管直接伸入藏卵器，藏精器之細胞核經由其授精管移入藏卵器中，並結合成厚壁之結合子（Zygote），又稱卵孢子（Oospore），卵孢子為休眠體，可抵抗不良環境。卵孢子經休眠後發芽時與孢子囊一樣可直接發芽成菌絲或產生孢囊及游走子。各種繁殖體之大小及形狀，種間差異很大，可作為分類之依據。引起秧苗立枯病之腐霉菌，受地區、季節及前作不同而異。Fusarium spp.引起秧苗立枯病者，常見者為F. oxysporum。在馬鈴薯煎汁瓊酯培養基上，光照適溫培養時，菌絲棉狀，白色至淡粉紅色，會產生淡橙黃色或紫色之色素於培養基中，有大小二種分生孢子，大孢子4-6個細胞，透明、鐮刀狀、彎曲不大、頂端細胞略彎、基部明顯；大孢子堆橙色。小孢子透明，通常單細胞，卵形至腎形，小孢子連續形成會推擠呈假頭狀。菌絲或大孢子會形成厚膜孢子，厚膜孢子單細胞或雙細胞，可抗惡劣環境，有利於存活。Mucor spp.氣生菌絲少，菌絲白色或略帶淡黃褐色，不形成匍匐根狀菌絲，在顯微鏡下觀察，菌絲透明無色、無隔膜，孢子囊柄細長，直接由菌絲單生，孢子囊褐色，內有數千之囊孢子。Rhizopus spp.有白色氣生菌絲，菌絲呈匍匐根狀，在顯微鏡下觀察，菌絲透明無色無隔膜，孢子囊柄細長，常叢生，其頂端生黑色孢子囊，內有數千之囊孢子。二屬菌之有性世代由菌絲結為結合子，細胞壁加厚為結合孢子（Zygospore），有休眠性及可抗不良環境，結合孢子發芽產生孢子囊及囊孢子。箱育秧苗立枯病為一統稱，診斷為立枯病不難，堆積期間及綠化初期，最容易發生立枯病，要研判病原菌之類別，可由受害稻種及稚苗之分布情形開始著手。不同藥劑對各病原菌之防治效果會有差異，實務上，判別主要病原菌甚為重要。\n被害秧苗幾乎均勻地散佈在育苗箱中，乍看下以為稻種發芽率不良所致，土壤表面未見到有明顯病菌之菌絲，撥開覆土後可見被害稻種上長有粉紅或深紅之菌絲及孢子（圖二），此極可能是由Fusariumspp.所引起之秧苗立枯病。被害秧苗在育苗箱中成圓形叢集狀分布，土壤表面未見明顯之菌絲，可能為Pythium spp.或水生菌所引起，病苗葉鞘及根褐變呈水浸狀腐敗現象，不產生紅色黴狀物，但土壤在高濕環境下，水生菌類會伴隨有膠狀分泌物，其上又棲息大量藻類而呈現鐵銹色，頗似水秧田之苗腐敗病。被害秧苗在育苗箱中亦成圓形叢集狀分佈，土壤表面有白絹色菌絲，菌絲生長快速，遇秧苗時即密集纏繞在葉鞘外表，被菌絲纏繞之秧苗從外面葉鞘開始枯萎，終使全苗枯死，病菌生長4-5天後會產生直徑大小約0.5-0.8公釐、褐色、表面有光澤之圓球形菌核，此係S. rolfsii引起之秧苗立枯病。稻種播種後堆積期間，育苗箱之土壤表面，長出略帶透明之白色菌絲，菌絲上有黑色或褐色孢囊，此即為Rhizopus spp.或Mucor spp.屬真菌之菌絲及其孢子囊。出現這二屬真菌之育苗箱，大多採用種過蔬菜的栽培土，尤其栽種塊根類、塊莖類及十字花科等作物之栽培土，最容易出現。這二屬真菌遍存於自然界各角落，平時行腐生偶爾弱寄生於植物儲藏器官，育苗箱栽培土中植物殘體多時，於育苗箱堆積期間在稻種及植物殘體上大量繁殖，稻芽被其菌絲覆被，組織受其分泌物如酵素等之作用而崩解，細胞死亡，在育苗箱移出綠化時，病苗及這兩種病菌經陽光曝曬後常乾枯死亡（圖六）。Rhizopus spp.一般發生於較高溫，菌絲白色而孢子囊黑色；Mucor spp.則發生於較低溫，菌絲白色至淡黃褐色，孢子囊為褐色。秧苗立枯病原菌感染綠化後秧苗，一般以叢集型危害方式，即病苗在育苗箱中呈圓形分佈，並向外擴展。被Pythium spp.及水生菌類感染，育苗箱中之土壤表面無明顯菌絲，被害秧苗最初從葉尖開始呈缺水青枯症狀，被害苗隨之枯死並轉變為赤褐色（圖七），拔取病苗可見其葉鞘基部、根冠及根都已呈淡褐色軟腐。被Fusarium spp.感染時，被害面積較小，一般直徑小於5公分，但育苗箱中被害點數多而散，被害秧苗附近之土壤表面偶有白粉紅色、深紅色或紫色菌絲叢，病苗生育不良、矮化，拔取病苗可見稻種上、莖基部及根冠上有粉紅至深紅色之菌叢，苗根數少而短，並由根尖至全根、地下部葉鞘及莖開始呈紅褐色病變，地上部由外面葉鞘開始枯萎，嚴重時秧苗全株死亡有粉紅色菌叢，但土壤表面之菌絲叢不多（圖二）。S. rolfsii感染綠化後秧苗時，一般可見其絹白色菌絲在土壤表面及秧苗間生長，菌絲接觸到秧苗，約2天後，苗常青枯死亡，最後轉為赤褐色。插秧機所用秧苗係於育苗箱中培育，育苗箱長60公分寬30公分高3公分，其栽培土淺，稻種播種量多，播種後堆積催芽4~5天，等待秧苗長出土面後再移出田間綠化，此種育苗環境很適合微生物滋長，因而多種兼性寄生之弱病原菌能迅速增加族群密度並引起病害。秧苗立枯病之發生與否，非常符合植物病害發生之三角生態關係，即寄主植物、病菌及環境三者間互動結果。稻種及秧苗為寄主植物，生長勢強則抗性強，相對生育受阻時受危害之機會增加。本病之病菌種類很複雜，不同栽培土而有不同的病菌，各種病菌是否會引起立枯病，則視環境是否適合病菌生長而定。播種與育苗管理，請參考紋枯病防治方法之耕種栽培管理部分。植物保護手冊登記之秧苗立枯病防治藥劑，對秧苗立枯病大多數病原菌之防治效果良好，只對S. rolfsii 引起之秧苗立枯病效果比較不好。如果發現主要病原為S. rolfsii，可由登記為紋枯病防治藥劑之滅普寧、福多寧及賓克隆等三種中選用一種做防治，使用時參考原登記之使用方法及注意事項。\n"}, "1678425157.8081253": {"單位": "", "標題": "如何分辨苗立枯病的發生症狀，有使用預防立枯病藥劑仍會發病的原因", "作者": "", "發布日": 0, "摘要": "", "全文": "苗立枯病於第一期作育苗箱秧苗較易發生，主要為低溫導致秧苗生育受阻，抗病力弱。本病於育苗箱中呈現類似圓形之分布，並向外擴展，罹病秧苗生育不良呈萎凋狀，隨後褐化枯死，拔取病苗可見葉鞘基部、根冠及根組織已枯死，在高濕環境下可發現病原菌絲纏繞為害。\n但若於育苗箱堆積期間，積箱作業堆疊過高，或稻種播種量及秕粒過多，積溫或發酵造成育苗箱溫度過高，導致稻種無法發芽或秧苗褐化，則屬於苗箱管理不當所致。稻種播種覆土前後已使用預防立枯病藥劑仍會發病，其原因為氣溫太低，育苗箱堆積時藥劑效果較慢，此時宜延長床土浸藥時間，另覆蓋土亦要藥劑消毒，藥劑與苗土充分混合均勻；另綠化期淹水防寒，亦會造成藥劑流失，建議再選擇推薦藥劑於排水後進行藥劑防治。"}, "1678426244.9069757": {"單位": "", "標題": "水稻育苗箱秧苗立枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "引起秧苗立枯病之病原菌除了此類病菌外尚有多種可引起類似的症狀，一般皆由殘存於土壤的病原菌感染秧苗而發生。防治方法可任選下列一種藥劑處理。以34%殺紋滅達樂溶液每箱施藥量 0.4cc 稀釋 1,250 倍，於播種後灌注藥液再行覆土。以 30%殺紋寧溶液每箱施藥量 0.5cc 稀釋 1,000 倍，施藥方法，(1)床土：播種後隨即灌注藥液，再行覆土。(2)覆蓋土：每箱覆蓋土（約 0.6 公斤）拌 5%滅達樂粒劑 0.5 克。播種前一、二天先將藥劑與覆蓋土混合均勻。"}, "1678431927.8813832": {"單位": "", "標題": "水稻白葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻白葉枯病為一種系統性病害，主要危害葉片、葉鞘，偶爾到達穗部。侵入途徑為傷口或自然開口，侵入後病原細菌經細胞間隙進入維管束中繁殖及擴散，故又稱維管束病害（vascular disease）。其病徵有三種型態，典型葉枯病徵（leaf blight）、急性萎凋型病徵（Kresek）和淡黃化型病徵（pale yellow），病害在田間通常發生於分 盛期之後，有時則在苗期就可發現病徵，主要在葉片或葉鞘，偶爾可在穀粒上出現。)幼苗期病徵：最初水浸狀小斑點在下位葉葉緣出現，高溫時斑點上出現菌泥，斑點後來延長，而漸變成黃色，病葉最後枯萎而很難和自然老化枯葉分辨，在熱帶地區幼苗可能經由葉片或根部之傷口或水孔侵入而成系統性感染。病菌在幼苗內繁殖迅速，而很快侵入維管束而造成幼苗之死亡。本田期之病徵：本田最初出現病徵在插秧後 3~4 星期，而以分 盛期後出現較多，常在葉緣離葉尖5-6公分處出現水浸狀小斑，然後逐漸延長而變成黃或枯黃色，而在健全或病斑之間有一狹小水浸狀帶，這些病斑通常沿一邊或兩邊葉緣，並向中肋擴大，最後可能到達葉鞘，黃色病斑最後變成白或灰白色，而在高溫狀態下易被腐生真菌所佔據，並出現很多大小不一黑斑，並有菌泥由病斑上溢出，菌泥乾燥呈黃色小球型，直徑約1.22公釐，很容易由病斑上脫落。在最適當發病條件下，看不到上述病徵，水浸狀和暗綠色病斑出現不久，罹病葉片即向內捲，病斑很快向下延伸，而上端葉片被害部份萎凋並成灰白色，有黏狀菌泥溢出，稱為急性型病徵，常在高氮肥地區及感病秈稻上出現。葉鞘上病徵主要由葉片往下延伸，最初呈黃綠或灰綠色條斑，再轉變成黃白色，在嚴重感染株整個葉鞘都褪色，枯萎，病株之根系發育不良，植株矮小，稔實率很低。急性萎凋型（Kresek）病徵：最初記錄在印尼有此病徵型之發生，受感染之幼苗外葉捲起，萎凋並成灰綠到淡褐或灰褐色，植株很明顯矮小，並呈冠腐，用手壓擠可感覺到充滿黏性黃色細菌，病株有的整株由地際處斷開，而飄浮在水面，此型病徵偶而出現在成株上，大都在孕穗或開花期，數條大白色斑紋出現在劍葉，往下延伸至葉鞘，幼穗萎凋。成白色，最後整株水稻枯死。急性萎凋型病徵在臺灣於1974年推廣嘉農秈8號和嘉農秈11號兩品種後在南部地區第二期大發生，停止栽培這兩品種後，田間再也沒有出現此型病徵。淡黃化型病徵（pale yellow）：此種病徵出現在最幼小的葉片上，為淡黃色或白色，然後變成黃褐色，最後萎凋。在菲律賓可見此病徵，徵狀和缺鐵類似。臺灣在1997年由作者在中部地區第二期稻首次發現此型病徵，2000年第一期稻在宜蘭地區也發現此型病徵，第二期稻在中部地區則普遍發生。自然寄主除水稻外，尚有Leersia oryzoidea，Leersia oryzoidea var. japonica Hack， Leersia sayanuka，茭白（Zizania latifolia Turez)，香附子，球花蒿草，李氏禾，游草(Leersia hexandra Swartz) ，以及下列野生稻Oryza australiensis，O. coarctata,\nO. jeyporensis，O . malampuzhensis，O. officinalis，O . penennis和 O . rufipogon。人工接種則下列雜草或野生稻會產生病斑，柳葉箬（Isachne globose Kuntze）， 假稻（Leersia japonica Mukino），皺稃雀稗（Paspalum scrobiculatum ），Phalaris arundinacea L，蘆茅（ Phragmites communis Trinius），千金子，畔茅，L. liliformia，虮子草（L. panicea），Zizania aquatica。野生稻有Oryza fatua，O. barthii，O. brachyantha，O. eichingeri，O. grandiglumis，O. granulata，O. latifolia，O. longiglumis，O. minuta\n，O. perrieri，O. punctata，O. ridleyi，O.sativa var. fatua，O. schweinfurthiana，O. subulata。\n白葉枯病菌，為短桿菌，兩端鈍圓，0.8~1.0 ×1.0~2.0µm，一條極生鞭毛長6~8µm，Gram陰性，不會產生孢子。Yoshimura and Tahara利用電子顯微鏡觀察培養基上之大小為0.55~0.75 × 1.35~2.17µm，比在寄主內0.45~0.60 × 0.65~1.40µm大，鞭毛直徑0.03µm，最長可達8.75µm。\n田間簡易診斷法:把疑似病葉剪約10公分，葉基部浸入水中，如有長條菌泥由葉片切口流出即表示感染有白葉枯病菌。把疑似病葉由田間採集後馬上插入含0.1％番紅溶液，經數小時後如整葉被染成紅色即表示沒有罹患白葉枯病，患有白葉枯病者則葉緣有不被染色之條狀斑，且內緣呈波浪狀。\n病原菌之生理生化特性、脂肪酸分析、噬菌體專一性測定、多元及單元抗體之免疫測試及發展半選擇性培養基等方法進行菌系分析鑑定與抗病性基因研究，但此等方法較為費時、費力或靈敏度不足。\n近年來由於分子生物技術發展迅速，如核酸探針在植物病原之偵測應用、限制輿圖多形性分析（RFLP）、聚合酵素連鎖反應（PCR）（1, 32）及隨機增幅核酸多形性分析（RAPD），為水稻白葉枯病之病理研究提供一條嶄新的方向及有利的工具。自1990 年RAPD 技術發展以後，為核酸分析技術提供了一更方便而有效之利器。RAPD-PCR 分析除可區分菌株、菌系（strain）、種內之不同生理小種（race）及不同物種（species）外，亦可應用於遺傳演化上之研究。而將RAPD分析所得之專一性核酸片段，進行選殖與核甘酸定序，由此序列衍生設計出專一性的引子對，再利用 PCR 技術，增幅出的\n特定核酸片段，可作為偵測或鑑定特定病原菌之標幟。另外，亦可將上述之分析技術，直接進行植物組織或其他田間樣本偵測，不但可由電泳膠體上觀察是否有專一性核酸片段增幅產生，並可用核酸探針雜合的方法予以進一步確認，而達到快速偵測診斷病原菌之目的。RAPD﹙隨機增幅核酸多型性分析﹚:先選取多個隨機引子﹙random primers﹚，利用隨機增幅核酸多型性分析以篩選水稻白葉枯病菌之專一性核酸片段。在選取的引子中以OPB-11（5' GTAGACCCGT 3'）自測試之白葉枯病菌株增幅得一約500bp專一性核酸片段。將此片段進行選殖並經非放射性標幟後製備為核酸探針Xo69-1 ，以進行南方漬染分析。結果Xo69-1皆可與Xoo供試菌株產生專一性核酸雜合訊號，而與其它對照菌株則無此訊號產生。再將此 500 bp 專一性核酸片段進行核甘酸定序，並由此序列設計出正向引子 Xf69-1 （ 5 'TCAAACGCCTGTCCACCATCAAGA3'）及反向引子Xr69-2（5' GGGTGACGCGCCGGACTTGAA 3'），這對引子可用於聚合酵素連鎖反應。PCR﹙聚合酵素連鎖反應﹚:利用引子對Xf69-1 /Xr69-2以PCR技術偵測水稻白葉枯病菌，可由供試之Xoo菌株增幅得一367 bp專一性核酸片段，而與非Xoo對照之菌株，則無此訊號產生。將此專一性引子對Xf69-1/Xr69-2，利用PCR技術偵測Xoo基因體核酸時，其靈敏度可達 500pg。稻白葉枯病發生於溫帶、亞熱帶及熱帶。在溫帶地區如日本，病害只發生在高溫季節，溫度25~30℃，病害發生嚴重，\n17℃則很少發生。熱帶地區則整年皆可發生，高溫多雨可增加病害嚴重性，特別如雨水淹沒稻田後發生更為嚴重；分櫱盛期如遇颱風挾帶高雨量則常常造成流行病害，高溫和高濕有利病菌由病組織內溢出，而高雨量及強風有助病菌之傳播並造成傷口供病菌侵入。株距太狹有利水稻生長早期病害之發生，而對後期之影響不大；使用高氮肥降低水稻對病害之抵抗性。水稻白葉枯病菌如同其他 Xanthomonas屬病原細菌在土壤中存活不長，石山早期報告，最長可存活四個月；後來的報告皆認為只能存活一 ~ 二個月(17, 26)，事實上在土壤內之存活受土壤含水量及溫度之影響，淹水土中在溫度 30，20，10 及 1~ 4 ℃分別可存活 4，32，80 和 92 天，而在含水20％土壤中溫度 30℃、20℃、10℃ 及 1~ 4℃。則可分別存活8、32、120 和160 天。病原菌可在稻椿內越冬而成為下一季稻之最初感染源，也可能長年存在於一些草類上，而把病原菌釋放到灌溉水做為第一次感染源。\n防治方法:（一）避免種植感病品種，秈稻較易感染本病，常發病地區及風大之地區，應避免種植秈稻。事實上臺灣目前推廣之品種很少有抵抗白葉枯病者，今後水稻育種應有計劃性地把已鑑定出之抗病基因導入，以便用於常發病地區之種植。自1967年開始水稻抗白葉枯病之基因有二十多個已被証實，即Xa1、Xa-2、Xa-3、Xa-4、xa-5、Xa6、Xa-7、Xa-8、Xa-9、Xa-10、Xa11、Xa-12、Xa-13、Xa-14、Xa16、Xa-17、Xa-18、Xa-19、Xa20、Xa-21和xa-nm (29, 30)，其中Xa-3、Xa-6和xa-9三個基因於成株才表現，而Ogawa等認為此三個基因應屬於同一個。xa-5、xa-8、xa-9、xa-13、xa-19 、xa-20 和xa-nm 屬於隱性基因，這些隱性基因後三個為誘變所獲得。而適合臺灣之抗病基因有Xa-4、xa-5 和X-7三種，目前臺灣存在之病菌都無法侵害具有這三種基因之水稻，有些菌株對具有Xa-1、Xa-2、Xa-3、Xa-Kg、Xa-10 或 Xa-11 水稻可造成中度以上之感病性，比較不適合作為育種之親本。（二）病菌大都由傷口侵入，儘量採用直播，或用機械插秧以減少移植時感染病菌。稻苗移植如用鏟秧方式，勿用手拔秧亦勿剪除秧葉尖，以免病原菌由傷口侵入。（三）避免偏用或使用過多氮素肥料。（四）雨後或晨露未乾前，避免進入稻田，以減少人為傳播病原菌。（五）發病稻田於收穫後，將稻樁燒燬，然後將稻田翻犁，連續浸水二週以消除病原菌，減少下一期水稻感染源。（六）藥劑防治：藥劑之使用必須在病害將\n發生或剛發生時使用才有效，在日本有幾種方法可預測病害發生，包括：1.設置預測田：預測田種植不同感病性品種，並經常以針刺製造傷口，並觀\n測其他寄主如Leersia spp. 之發病情形。2.依氣象條件：氣象條件如大雨水、颱風、溫度、強風等和病害發生有密切相關性。3.由病菌之數量：病菌之出現常在病害發生之前，因此定期採集稻葉，經磨碎，離心濃縮，再接種到感病品種。4.噬菌體數量：噬菌體可在灌溉水中於病害發生前偵測到，定點定期採集灌溉水，經離心及通過Millipore後加入病原細菌，在半固體培養基上，在20-25℃ 經 10-15小時即可看到plagues。"}, "1678432256.744879": {"單位": "", "標題": "水稻白葉枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "一、於常發病或風大地區避免種植感病品種，尤其秈稻較稉稻易感病。經台中改良場檢定，對白葉枯病具有耐病性之水稻品種有：台中秈糯1號、台南5號、台南6號、台 7號、高雄139號、高雄141號和嘉南8號等7種，其中只有高雄139號屬於目前良質米推廣品種。\n二、可用56℃溫湯處理30分鐘進行稻種消毒。\n三、避免行株距太窄，造成田間微氣候濕度過高。\n四、避免偏用或使用過多氮素肥料。\n五、清除田間雜草寄主。\n六、施肥及噴藥工作盡可能在傍晚進行，避免雨後及晨露未乾前避免進入已發病的稻田行走，以減少人為傳播病原菌。\n七、發病稻田於收穫後即進行翻犁，並連續浸水二週，降低下一期稻作之感染源。\n八、藥劑防治：利用10%克枯爛可濕性粉劑、10%鏈四環黴素水溶性粉劑和6%撲殺熱粒劑進行防治，藥劑使用必須在病害將發生或剛發生時使用才有效。\n※10%克枯爛可濕性粉劑不可與他種藥劑混用，否則易造成藥害。\n九、有機資材防治：\n（一）拮抗菌：可以利用Pseudomonas fluorescens與P. putida二種細菌來防治；在台灣也有學者利用枯草桿菌與放射線菌來防治，可增加水稻孕穗數，但在其他農藝性狀上無顯著差異。\n（二）植物抽出物：農試所進行對水稻白葉枯病菌之抑菌作用測試，結果以肉桂油、丁香油、尤加利油及香茅油等四種抑菌效果較佳。\n水稻白葉枯病多發生在高溫多雨時期，尤其是在水稻二期作分蘗盛期如遇颱風挾帶高雨量則常常造成流行性病害，農友們更應注意防範，在風雨前後進行防治措施。另外注意田間衛生，因本病原菌能在多種禾本科雜草、再生稻、稻樁或堆積稻草上越冬，形成第一次感染源，所以整地時應清除田間雜物，若有發病的田區應於插秧前淹水二週以抑制病原菌。而氮肥的管理很重要，若氮肥過多易誘發病害，對米質影響甚鉅。水稻白葉枯病為流行性病害，受氣候影響，常引起嚴重的災害損失，因此，要留意病害發生預測訊息。"}, "1678433176.3599603": {"單位": "", "標題": "臺灣水稻抗白葉枯病研究回顧與育種策略", "作者": "", "發布日": 0, "摘要": "", "全文": "自從1971年後，水稻臺灣育種者陸續將抗病基因導入，因當時栽培秈稻品種較不具抵抗性，所以許多育種家針對秈稻改良，而忽略了稉型稻育種。目\n前IRBB近同源系分有印度型稻、稉型稻及秈稉型稻，稉型稻組較適合臺灣之參考，未來應將之引進臺灣，並利用堆疊基因育成耐病品種；或是由國\n際間發現抗病基因導入臺灣流行感病品種，建立本土近同源系判別品種。依據於1996年提出的理論，表示臺灣水稻的抗白葉枯病性遺傳行為為複合式基因(multiplicative gene action)，其中加性作用、顯性作用、以及加性與顯性交感作用均相當重要。此些抗病基因之表現度與水稻栽培型式及種植環境有密切的關係，在實際抗病育種篩選應用上，基因綜合效應以及栽培環境對抗病性之表現度的潛在影響均應為評估要點。白葉枯病防治最佳策略以抗病品種降低病害為害，但目前普遍栽培品種對白葉枯病均無抗病性，所以建議防治方法：1.在曾嚴重發生及風大地區，應避免種植極感病品種，例如臺稉9號；2.因病原菌由傷口侵入，應儘量採用直播，減少移植時感染病原菌。3.避免清晨露水未乾前行走於已發病之稻株間，施肥或噴藥工作盡可能在下午進行。4.種植前施用矽酸爐渣及生育期間減施氮肥，以增加葉片強度，減少傷口發生。5.可於風雨來襲前後，選用克枯爛、鏈四環黴素、克枯三賽唑、或撲殺熱等藥劑進行預防防治。"}, "1678433605.9204729": {"單位": "", "標題": "白葉枯病對水稻產量與米質之影響及抗病品系之育成", "作者": "", "發布日": 0, "摘要": "", "全文": "由於白葉枯病嚴重發生，穗重、一穗粒數、稔實率及千粒重受顯著影響而造成產量降低，並使白米透明度降低、青米率及死米率顯著增加，糙米率、白米率及完整米率亦稍受影響，此外水稻在幼穗形成期遭受白葉枯病為害，其米粒之鹼性測驗之擴散程度及直鏈性澱粉含量稍降低，粗蛋白質含量稍提高，因此食味性比較差。將白葉枯病品種台中秈糯1號、台農秈20號及Suweon 333之抗病性導入感病品種台中秈10號及台秈1號，已育成五個新抗病品系，其稻穀產量及米質均較對照品種台中秈10號及台中秈糯1號為佳。"}, "1678435253.9195728": {"單位": "", "標題": "茶褐色圓星病", "作者": "", "發布日": 0, "摘要": "", "全文": "褐色圓星病 (Brown round spot)\n\n病原菌：Pseudocercospora ocellata (Deighton) Deighton\n\n病原生態：\n　　台灣全年都會發生，秋、冬落葉最嚴重，大部分品種都會感染本病，品種間抗病性差異不大，調查茶業改良場品種園中的品種，無一品種具抗病性。生育不良衰弱的茶樹易得到本病，會造成嚴重的落葉，而影響到下一次茶葉的產量，本病以菌絲在組織上越冬，以分生孢子為傳染源，病原菌的最適生長溫度為25℃，發病的氣候條件為潮濕、多雨，潛伏期約20～30天。\n\n病徵：\n　　茶褐色圓星病在葉片上形成二型的病斑，一為褐色圓斑，即葉片上形成褐色小點，漸漸擴大為圓形或不規則形之斑點，此型病斑可產生大量的分生孢子。另一為綠斑型，病斑呈彌漫性墨綠色小斑點，均勻的分布於葉背，主要發生在老葉及幼葉，在葉背初期為針狀，顏色呈淡綠色，將病葉對光看時，病斑上的顏色較淡，可擴大到2～3公厘大小，罹病組織的細胞較正常細胞為腫大，病斑隨著葉片的老化漸漸聚在一起，顏色變深，漸漸凸起，當年生枝條經過半年，不同葉齡的葉片發病率差異甚大，下位葉之發病情形較上位葉(靠近生長點的葉片)嚴重，台灣發現均為此類。\n防治方法：\n\n一、扦插茶苗時應選擇健康無病斑之母樹，培養健康種苗。\n二、注意茶園之田間衛生。\n三、藥劑防治:42.2%腈硫醌水懸劑，發病初期每隔7天施藥一次，連續三至四次"}, "1678441060.1669254": {"單位": "", "標題": "茶褐色圓星病利用拮抗菌防治", "作者": "", "發布日": 0, "摘要": "", "全文": "褐色圓星病田間發病率對扦插苗落葉之影響及田間，噴施 Bacillus subtilis(BS)、Streptomyces saracetics(SS)、Azoxystrobin、Triflunizole 及CK等四種處理對茶樹發生褐色圓星病之影響。褐色圓星病田間發病率調查結果顯示,大部份的小葉種之發病率皆較大葉種為高,其中以台茶 12 號及青心烏龍最高,分別為26.3%及24.5%;21個調查品種之病斑型態皆屬於產胞量較少的綠斑型病斑。青心烏龍、台茶12號及鐵觀音三品種扦插試驗中,母葉上病斑較多者,扦插初期有落葉的現象,其中又以鐵觀音之落葉情形最嚴種。田間無論青心烏龍或鐵觀音噴BS、SS、Azoxystrobin及 Triflunizole 等四種處理對茶褐色圓星病之發生皆有抑制的作用,其中以Azoxystrobin 及 Triflunizole 的效果最明顯。 \n"}, "1678441060.1803677": {"單位": "", "標題": "茶褐色圓星病利用拮抗菌防治", "作者": "", "發布日": 0, "摘要": "", "全文": "褐色圓星病田間發病率對扦插苗落葉之影響及田間，噴施 Bacillus subtilis(BS)、Streptomyces saracetics(SS)、Azoxystrobin、Triflunizole 及CK等四種處理對茶樹發生褐色圓星病之影響。褐色圓星病田間發病率調查結果顯示,大部份的小葉種之發病率皆較大葉種為高,其中以台茶 12 號及青心烏龍最高,分別為26.3%及24.5%;21個調查品種之病斑型態皆屬於產胞量較少的綠斑型病斑。青心烏龍、台茶12號及鐵觀音三品種扦插試驗中,母葉上病斑較多者,扦插初期有落葉的現象,其中又以鐵觀音之落葉情形最嚴種。田間無論青心烏龍或鐵觀音噴BS、SS、Azoxystrobin及 Triflunizole 等四種處理對茶褐色圓星病之發生皆有抑制的作用,其中以Azoxystrobin 及 Triflunizole 的效果最明顯。 \n"}, "1678441277.023921": {"單位": "", "標題": "茶褐色圓星病", "作者": "", "發布日": 0, "摘要": "", "全文": "臺灣各茶園中皆有褐色圓星病的發生,尤其老葉發生最嚴重,其對茶樹最大的影響 是造成茶樹的落葉,尤其是扦插苗母葉發病高,在扦插初期母葉會有脫落的現象,使得扦插苗死亡。茶褐色圓星病在葉片上形成二型的病斑,一為褐色圓斑,即葉片上形成褐色小點,漸漸擴大為圓型或不規則形之斑點,此型病斑可產生大量的分生孢子。另一為綠斑型,病斑呈彌漫性墨綠色小斑點,均勻的分布於葉背,主要發生在老葉及幼葉,在葉背初期為針狀,顏色呈淡綠色,將病葉對光看時,病斑上的顏色較淡,可擴大到2~3公釐大小,罹病組織的細胞較正常細胞為腫大,病斑隨著葉片的老化漸漸聚在一起,顏色變深,漸漸凸起,當年生枝條經過半年,不同葉齡的葉片發病率差異甚大,下位葉之發病情形較上位葉(靠近生長點的葉片)嚴重,臺灣發現均為此類。\n在罹病葉片之下表皮產生分生孢子,病斑上可形成黑色的分生孢子叢 (Sporodochium),分生孢子叢是由許多分生孢子柄聚集而成的,分生孢子柄的頂端長出分生孢子,無色或橄欖色,線狀、直或彎曲,末端粗大呈圓形至圓錐形。在馬鈴薯葡萄糖培養基(PDA)上形成之菌落為灰白色,生長緩慢,分生孢子大小為72.2 - 95.5 × 2.1 - 3.1um,有3~7個隔膜;分離自褐色圓斑的分生孢子為61.8-92.7。臺灣全年都會發生,秋、冬落葉最嚴重,大部分品種都會感染本病,品種間抗病性差異不大,調查茶業改良場品種園中的品種,無一品種具抗病性。生育不良衰弱的茶樹易得到本病,會造成嚴重的落葉,而影響到下一次茶葉的產量,本病以菌絲在組織上越冬,以分生孢子為傳染源,病原菌的最適生長溫度為25°C,發病的氣候條件為潮溼、多雨,潛伏期約20~30天。\n"}, "1678899917.5288289": {"單位": "", "標題": "水稻白尖病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "本病害於水稻生長初期病徵不明顯，\n攜帶此病原線蟲之水稻種子發芽率低並延\n遲出芽，苗株矮且單薄。典型病徵出現\n於分 盛期，使抽出之心葉尖端3~5 公分\n呈黃白至蒼白色，俟展開後即呈白化扭\n曲，與綠色部位交接處為波紋狀暗褐色之\n橫隔帶，且常從此處斷裂脫落，故又稱葉\n切病。於昏暗光線下，葉尖白化部\n位之反光宛若螢光，又稱螢稻熱病。稻白\n尖病罹病劍葉（flagleaf）短小扭曲，稻穗\n常無法完全自劍葉（flagleaf）中脫出；穀\n粒小且種仁 （kernel）龜裂變色。整體而言，此病害導致稻株矮化、稻\n穗變短、穀粒延遲成熟、穀粒數減少、授\n粉率降低及穀粒畸形殘破等症狀，造成稻\n作嚴重損失。田間估計，此病害對稻作的\n減損率為10~30％，高感受性品種甚至達70\n％，抗性品種亦有 2 0 ％減產程度。\nPopova估計蘇聯感受性稻米品種罹白尖病\n之減損率為54％；稻種感染率達80％時，\n田間減損率為31％。"}, "1678900078.3929799": {"單位": "", "標題": "水稻白尖病寄主", "作者": "", "發布日": 0, "摘要": "", "全文": "逾200種植物\n；臺灣已在6種蔬菜、13種花卉、4種雜\n草、1種牧草及水稻等作物上發現其寄生行\n為。其中在秋石斛、山蘇花及非洲堇上為\n內寄生，而於粉蔥、韭、茭白筍、荸薺、\n草莓、晚香玉、文殊蘭、水仙、康乃馨、\n百日菊、臺灣百合、仙克萊、報歲蘭、薑\n花、虎耳草、碎米莎草、小馬唐、鼠尾\n粟、天竺草、及水稻上為外寄生。其危害\n程度，則以草莓與水稻為最嚴重。"}, "1678900130.8619292": {"單位": "", "標題": "水稻白尖病", "作者": "", "發布日": 0, "摘要": "", "全文": "體形類似Aphelenchus屬，惟較細長。\n口針節球很小或無。中部食道球近於方形\n或長方形。後子宮囊之長短，依種類而\n異，為分類上的重要特徵。尾部逐漸尖\n細，具1~4個尾端突起。雄蟲交接刺玫瑰刺\n狀，不具副刺及交接囊，固定後尾部向腹"}, "1678900201.3878953": {"單位": "", "標題": "水稻白尖病生態", "作者": "", "發布日": 0, "摘要": "", "全文": "A. besseyi可以休眠（dormant）或脫水\n（anhydrobiotic）狀態殘存於植物組織、種子\n或殘株上，於採收後的穀粒中可存活8\n個月至3年之久。俟播種後，穀粒中A.\nbesseyi 旋即復甦，往生長點方向趨集。\n分糵後期此線蟲之數目達最高峰，並於開\n花前侵入花穗（spikelet），於劍葉（flagleaf）\n中行外寄生方式取食子房（ovary）雄蕊\n（stamen）、稃（lodicule）與胚（embryo）。\n當穀粒漸趨成熟，此線蟲即停止繁殖，然\n三齡線蟲仍持續成長為成蟲，而集中於穎\n部（glume）。復甦後的A. besseyi多為雌\n蟲，雄蟲數量偏低"}, "1678900238.6129045": {"單位": "", "標題": "水稻白尖病", "作者": "", "發布日": 0, "摘要": "", "全文": "由葉芽線蟲引起"}, "1678900283.5790453": {"單位": "", "標題": "水稻白尖病生活使", "作者": "", "發布日": 0, "摘要": "", "全文": "葉芽線蟲為兩性生殖，A. besseyi在24\n℃及28℃之最適溫度下8~9天即可完成一世代。A. besseyi 在稻種萌芽後，以內寄生方\n式存在於鞘葉可達7~10天之久，完成一世\n代，隨後游出鞘葉，迄水稻收穫為止皆於\n稻株中行外寄生行為。"}, "1678900317.3786097": {"單位": "", "標題": "水稻白尖病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻白尖病之發生，源自攜帶A. besseyi\n之稻種，若能在水稻收穫後之烘乾過程中\n順便除滅穀粒中的線蟲，將是最好的防治\n方法；可是本研究結果顯示即使穀粒在70\n℃下烘乾12 小時，依然有16 ％的線蟲存\n活，但發芽率卻降至44％，現行的40或50\n℃烘乾溫度線蟲存活率分別為 74 ％及 73\n％。倒是60℃烘乾溫度可將線蟲存活率降至40％，而不影響稻種發芽率，其實是較\n好的選擇。\n如以歐殺滅液劑及55℃，15分鐘之溫\n湯浸種方法處理稻種，相較之下歐殺滅殺\n線蟲劑效果較好。兩種處理方法在統計上\n雖無顯著差異，但感染率及田間實際生長\n情形仍以歐殺滅處理者為佳。溫湯浸種實\n際上在育苗場大量稻種處理技術上尚存甚\n多困難，而以化學藥劑之歐殺滅處理較為\n可行。因而若以歐殺滅之液劑及粒劑行稻\n種浸泡、苗期及本田期處理，在防治水稻\n白尖病之發生是較為實際的。試驗結果顯\n示在苗期及本田期皆處理或只於本田期施\n用之罹病率及穀粒中線蟲數均較浸種或苗\n期施用者為低，顯示水稻白尖病之防治自\n苗期至本田期皆有施藥必要。"}, "1678900351.937638": {"單位": "", "標題": "水稻白尖病", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻白尖病為水稻葉芽線蟲感染造成，水稻生長初期病徵不明顯，攜帶此病原線蟲之水稻種子發芽率低並延遲出芽，苗株矮且單薄。典型病徵出現於分蘗盛期，使抽出之新葉尖端 3 ～ 5 公分呈黃白至蒼白色，俟展開後即呈白化扭曲，與綠色部位交接處為波紋狀暗褐色之橫隔帶，且常從此處斷裂脫落，故又稱葉切病。於昏暗光線下，葉尖白化部位之反光宛若螢光，又稱螢稻熱病。稻白尖病罹病劍葉短小扭曲，稻穗常無法完全自劍葉中脫出；穀粒小且種仁龜裂變色。此病害導致稻株矮化、稻穗變短、穀粒延遲成熟、穀粒數減少、授粉率降低及穀粒畸形殘破等症狀，造成稻作嚴重損失。"}, "1678900389.5402153": {"單位": "", "標題": "水稻白尖病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "典型病徵出現於分蘗期，葉片抽出時，葉尖呈白色油浸狀透明，而後轉呈灰白色條狀\n螺旋形捲縮，長度約為2～5公分。被害稻株，穗變短小，多呈暗紅褐色乾枯形狀，嚴重者\n，常導致抽穗不正常，節上另生1～2小型稻穗。"}, "1678900402.6941676": {"單位": "", "標題": "水稻白尖病傳播", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻白尖病原線蟲可於稻榖內以休眠狀態殘存3年以上，俟稻種播下後，在有水份供吸\n溫度適宜情況下線蟲漸漸恢復活動力，且隨芽的生長沿葉鞘內側往上移動，因此蟲子是本\n線蟲最主要之傳播方式。\n"}, "1678900459.491846": {"單位": "", "標題": "水稻白尖病", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻線蟲白尖病亦為種子傳播性病害，係由水稻葉芽線蟲 (Aphelenchoides besseyi\nChristie)所引起，臺灣最早由洪氏於1959年所報導。此病害在水稻生長初期病徵不明顯，典\n型病徵出現於分蘗盛期，葉片抽出時危害葉尖，尖端呈現黃色至蒼白色，之後呈現白化扭曲\n之典型病徵，與綠色部位的交接處為波紋狀暗褐色之橫隔帶，常從此處斷裂脫落。此病害可\n造成被害稻株矮化、稻穗變短、穀粒延遲成熟、榖粒數減少、授粉率降低及穀粒畸形殘破等\n症狀、對水稻產量上會造成影響。"}, "1678900509.0866005": {"單位": "", "標題": "水稻白尖病生態與防治時期", "作者": "", "發布日": 0, "摘要": "", "全文": "線蟲白尖病須至分蘗期，葉尖才開始出現油浸狀病徵，而後呈螺旋形捲縮乾枯。病原線蟲，可於稻穀內休眠3年以上，稻穀播種後，蟲體獲得水份逐漸恢復活動力而造成感染，雖然秧苗期不會出現病徵，但唯有在育苗期防治才能收效。線蟲根瘤病則於苗期感染，造成根系結瘤且鬚根減少，苗期病徵不明顯，至成株因植株無法吸收足夠之養份，才呈現生育不良。此病害主要藉病原線蟲污染之土壤傳播，其防治重點也在秧苗期。"}, "1678900567.3760417": {"單位": "", "標題": "水稻白尖病", "作者": "", "發布日": 0, "摘要": "", "全文": "臺灣水稻白尖病最早於 1959 年調查發現，在屏東縣、新竹縣及臺北縣水稻栽培\n區普遍發生，其中以‘嘉農 242 號’、‘臺北 13 號’、‘高雄 10 號’及‘高雄 64 號’等水稻品\n種最容易感染，發生率高達 28-36%，造成 30-47%產量減損率。依據前人調查南投縣草屯鎮及臺中縣潭子鄉水稻白尖病發生情形，並進行病原線蟲形\n態、生態、生理性質、種子處理等研究，發現此病發生率因水稻品種及地區而有明顯\n的差異。"}, "1678900789.3540988": {"單位": "", "標題": "水稻白尖病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "0.3% 芬普尼粒劑(fipronil)育苗箱使用。插秧前24小時均勻撒佈，之後立即灑水至飽和狀。\n"}, "1678900804.717362": {"單位": "", "標題": "水稻白尖病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "40% 芬滅松乳劑(fenamiphos)稻種預浸24小時後，再浸藥處理2小時。\n"}, "1678900820.0565624": {"單位": "", "標題": "水稻白尖病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "10% 芬滅松粒劑(fenamiphos)於秧苗綠化期均勻撒佈，不可施用於本田。\n"}, "1678900850.6479378": {"單位": "", "標題": "水稻白尖病生態", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻白尖病病原經鑑定為葉芽線蟲\n(Aphelenchoides besseyi)，可於休眠狀態的\n稻穀內殘存3年以上，俟稻種浸水播種後，\n在溫度適宜情況下，線蟲漸漸恢復活動力，\n且隨芽的生長沿葉鞘內側往上移動。該線蟲\n經由種子傳播，典型病徵出現於水稻分 盛\n期至幼穗形成期，造成稻株心葉葉尖3∼5公\n分處呈黃白色，葉尖扭曲，與綠色交接處為\n波紋狀暗褐色之橫隔帶，約經20餘天後常從\n此處斷裂脫落，掉於水面上。至水稻抽穗後\n劍葉短小扭曲，稻穗常無法自劍葉抽出，稻\n穀穀粒變小，龜裂變色，影響米質，降低產\n量。"}, "1678900910.8602068": {"單位": "", "標題": "茶樹赤葉枯病生態", "作者": "", "發布日": 0, "摘要": "", "全文": "本病以分生孢子為其主要傳染源，隨雨露與灌溉水之飛濺傳播，風雨可擴大其傳播距離；品種間抗病性之差異極大，不同植株品種之生長狀況亦可影響其發病的程度。赤葉枯病菌(同炭疽病菌)是一種潛伏感染菌，外表健康的葉片上，在適當的環境下及寄主老化或衰弱時可表現病徵，故本病多發生在颱風過後的茶園或受害蟲危害之葉片。\n　　赤葉枯病菌(同炭疽病菌)之孢子有時也會在輪斑病病斑的邊緣被發現，輪斑病在日本非常嚴重，研究發現赤葉枯病菌可以抑制輪斑病病斑的進展與擴大，兩病原菌間具有拮抗關係；在台灣同一葉片上可同時發現赤葉枯病及輪斑病的病斑。"}, "1678900942.0799882": {"單位": "", "標題": "茶樹赤葉枯病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "葉片與幼嫩之條被害，葉片上的病徵初期為黃綠色小點，擴大後顏色加深呈赤褐色，上有灰黑色小點，老病斑則為灰色；嫩葉上的病斑呈褐色小斑點；在嫩芽上的病斑為褐色後期轉為黑褐色；在嫩枝條上，枝條變成黑色，容易折斷。"}, "1678900967.5401647": {"單位": "", "標題": "茶樹赤葉枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "一、\n\n改善茶園環境，增加日照及通風以降低茶園濕度，使成為不適發病之環境。\n\n二、\n\n機械採茶園及苗圃應特別注意防患本病之發生。\n\n三、\n\n種植抗病品種。\n\n四、\n\n扦插前母樹先噴施殺菌劑，可防止茶苗發生赤葉枯病。"}, "1678900991.9702673": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "嫩芽、葉之病徵初期為黃綠色小點，擴大後呈深褐色，成熟葉上的病徵，從葉緣開始\n向內或沿著葉脈發展，病斑初期為淺綠色，在潮溼的環境下進展快速，後期轉為赤褐色；\n在乾燥的狀況下病斑進展緩慢，顏色成灰白色。茶赤葉枯病病斑以感染點為中心，向外形\n成界限不明顯的輪紋，有黑色小點散生其上，大都集中在輪紋上，濕度高時會泌出肉色粘\n性的孢子團。本病除危害葉片外，尚可感染嫩枝條。\n"}, "1678900998.548311": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌由機剪或颱風過後造成的傷口侵入，風雨可加速本病的傳佈。"}, "1678901056.7284985": {"單位": "", "標題": "茶樹赤葉枯病學名", "作者": "", "發布日": 0, "摘要": "", "全文": "有性世代Glomerella cingulata\n無性世代Colletotrichum camelliae"}, "1678901077.153533": {"單位": "", "標題": "茶樹赤葉枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "1.改善茶園環境使增加日照時間及通風，以降低茶園濕度，減少本病發生之環境。\n2.種植抗病品種。\n3.注意肥料三要素之配合。"}, "1678901110.7273204": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "1×10^9 cfu/g 貝萊斯芽孢桿菌BF可溼性粉劑\n(Bacillus velezensis BF)"}, "1678901136.469421": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "50% 1X10^9 CFU/G 枯草桿菌\n可溼性粉劑"}, "1678901178.2068574": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "23.6% 百克敏水懸劑\n(pyraclostrobin)\n病害發生初期開始施藥，必要時隔7天施藥一次。"}, "1678901196.2680788": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "5% 保粒黴素丁\n水分散性油懸劑\n(polyoxorim)\n病害發生初期開始施藥，每隔7天施藥一次，連續三次。"}, "1678901212.8371048": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "11.6% 四克利水基乳劑\n(tetraconazole)\n病害發生初期開始施藥，每隔7天施藥一次，連續兩次。"}, "1678901231.521583": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "40% 克熱淨可溼性粉劑\n(iminoctadine tris (albesilate))\n發病初期開始施藥，每隔7天施藥一次，連續兩次"}, "1678901246.8132193": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "250 g/L (25% w/v) 得克利水基乳劑\n(tebuconazole)\n採茶後7天施藥，每隔7天施藥一次，連續二次。"}, "1678901261.6375418": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "50% 免賴得可溼性粉劑\n(benomyl)\n發病初期（病斑 0.5公分以內時）每隔7天施藥一次，連續三至四次"}, "1678901275.809626": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "10.7% 四克利乳劑\n(tetraconazole)\n病害發生初期開始施藥，每隔7天施藥一次。"}, "1678901293.7635305": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "39.5% 扶吉胺水懸劑\n(fluazinam)\n病害發生初期開始施藥，必要時隔7天施藥一次。"}, "1678901310.3005376": {"單位": "", "標題": "茶樹赤葉枯病防治藥劑", "作者": "", "發布日": 0, "摘要": "", "全文": "70% 甲基多保淨可溼性粉劑\n(thiophanate-methyl)\n發病時剪枝後立即施藥，萌芽初期再施藥一次。"}, "1678901343.489888": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "主要危害葉片與幼嫩枝條。罹病葉片初期出現黃綠色斑點，後擴大轉變為赤褐色，幼嫩枝條罹病後褐化、易斷。受感染的茶樹失去經濟價值，影響農友收成。"}, "1678901407.3604121": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "赤葉枯病主要危害葉片和幼嫩枝條，罹病葉片一開始會出現黃綠色塊狀斑點，後擴大成轉成赤褐色，幼嫩枝條罹病後則會變成黑色，容易折斷。\n換句話說，罹病的茶樹基本上已經沒有經濟價值了。赤葉枯病是常見的病害，必須提前防範，在太高溫多濕時噴殺菌劑預防，否則若罹病不只一棵樹死掉，真菌會隨著空氣飄散，嚴重的話整片茶園都不用收成。"}, "1678901441.1400826": {"單位": "", "標題": "茶樹赤葉枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "保持通風，可提高樹勢、修剪枝條，避免種得太密。"}, "1678901485.5606718": {"單位": "", "標題": "茶樹赤葉枯病生態", "作者": "", "發布日": 0, "摘要": "", "全文": "茶赤葉枯病是台灣茶樹極為普遍的病害，和果樹上常見的炭疽病來自同一屬，由真菌引起，會潛伏在作物上，即使外表看起來健康，在適當環境下仍會發病。茶樹生長環境有山間霧，若沒適當通風，濕度一高就容易罹病。"}, "1678901600.7843142": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "本病以分生孢子為其主要傳染源，隨雨露與灌溉水之飛濺傳播，風雨可擴大其傳播距離；品種間抗病性之差異極大，不同植株品種之生長狀況亦可影響其發病的程度。赤葉枯病菌(同炭疽病菌)是一種潛伏感染菌，外表健康的葉片往往可分離到本菌，即病原菌潛伏在外表健康的葉片上，在適當的環境下及寄主老化或衰弱時可表現病徵，故本病多發生在颱風過後的茶園或受害蟲危害之葉片。"}, "1678901613.8404856": {"單位": "", "標題": "茶樹赤葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "葉片與幼嫩枝條被害，葉片上的病徵初期為黃綠色小點，擴大後顏色加深呈赤褐色，上有灰黑色小點，老病斑則為灰色；嫩葉上的病斑呈褐色小斑點；在嫩芽上的病斑為褐色後期轉為黑褐色；在嫩枝條上，枝條變成黑色，容易折斷，大面積受危害則會造成茶菁減產。\n茶赤葉枯病病斑圓形至不規則形，病斑外圍赤褐色至紫褐色，病斑中心呈灰白色，有時會同心輪紋，感染後期病斑上出現黑色子囊殼，感染嚴重葉片容易落葉。"}, "1678901633.1361933": {"單位": "", "標題": "茶樹赤葉枯病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "改善茶園環境，增加日照及通風以降低茶園濕度，使成為不適發病之環境。機械採收茶園(容易有大量傷口)及苗圃(高濕環境)應特別注意防患本病之發生。"}, "1678901674.3107822": {"單位": "", "標題": "茶樹赤葉枯病病原形態", "作者": "", "發布日": 0, "摘要": "", "全文": "無性世代的分生孢子，在罹病葉片與馬鈴薯葡萄糖培養基(PDA)均可形成；分生孢子褥(堆)在培養基之邊緣產生，內有分生孢子，分生孢子單孢、無色、長筒狀，大小為12-17×4-4.5㎛，無論在罹病組織上或人工培養之分生孢子褥(堆)內皆無剛毛，在培養基尚可形成大量的有性世代子囊殼，子囊殼黑色內有子囊孢子，子囊孢子單孢、無色、長橢圓形，大小為10-20×4-6㎛"}, "1678901674.3277397": {"單位": "", "標題": "茶樹赤葉枯病病原形態", "作者": "", "發布日": 0, "摘要": "", "全文": "無性世代的分生孢子，在罹病葉片與馬鈴薯葡萄糖培養基(PDA)均可形成；分生孢子褥(堆)在培養基之邊緣產生，內有分生孢子，分生孢子單孢、無色、長筒狀，大小為12-17×4-4.5㎛，無論在罹病組織上或人工培養之分生孢子褥(堆)內皆無剛毛，在培養基尚可形成大量的有性世代子囊殼，子囊殼黑色內有子囊孢子，子囊孢子單孢、無色、長橢圓形，大小為10-20×4-6㎛"}, "1678901687.2995076": {"單位": "", "標題": "茶樹赤葉枯病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "葉片與幼嫩枝條被害，葉片上的病徵初期為黃綠色小點，擴大後顏色加深呈赤褐色，上有灰黑色小點，老病斑則為灰色；嫩葉上的病斑呈褐色小斑點；在嫩芽上的病斑為褐色後期轉為黑褐色；在嫩枝條上，枝條變成黑色，容易折斷，大面積受危害則會造成茶菁減產。\n茶赤葉枯病病斑圓形至不規則形，病斑外圍赤褐色至紫褐色，病斑中心呈灰白色，有時會同心輪紋，感染後期病斑上出現黑色子囊殼，感染嚴重葉片容易落葉。"}, "1678901706.5352812": {"單位": "", "標題": "茶樹赤葉枯病寄主", "作者": "", "發布日": 0, "摘要": "", "全文": "果樹、蔬菜、花卉、林木及草本植物等"}, "1678901726.6516387": {"單位": "", "標題": "茶樹赤葉枯病發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "本病以分生孢子為其主要傳染源，隨雨露與灌溉水之飛濺傳播，風雨可擴大其傳播距離；品種間抗病性之差異極大，不同植株品種之生長狀況亦可影響其發病的程度。赤葉枯病菌(同炭疽病菌)是一種潛伏感染菌，外表健康的葉片往往可分離到本菌，即病原菌潛伏在外表健康的葉片上，在適當的環境下及寄主老化或衰弱時可表現病徵，故本病多發生在颱風過後的茶園或受害蟲危害之葉片。\n"}, "1678902114.236048": {"單位": "", "標題": "茶樹輪斑病發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "最適合生長溫度為攝氏15-25度，好發於低溫多雨季節。病原菌可於組織上越冬，再經由風雨傳播，成為初次感染源"}, "1678902241.7514665": {"單位": "", "標題": "茶樹輪斑病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "葉片初期出現圓形水浸狀褐色壞疽病斑，受感染組織出現失濕軟的現象，部分病斑可見到同心輪紋，後期病斑擴大為褐色不規則狀乾癟病斑，中央出現灰白色扁圓形繁殖體"}, "1679413756.9882052": {"單位": "", "標題": "稻麴病", "作者": "", "發布日": 0, "摘要": "", "全文": "好發於高溫多雨的環境，發病部位為穀粒，通常發生於抽穗後一至二星期，罹病穀粒比健全穀粒大三至四倍，表面覆蓋黃綠至黃黑色的粉狀孢子，因重量而下垂。"}, "1679413824.1424935": {"單位": "", "標題": "稻麴病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "採用健康稻種，勿偏施氮肥；田間罹病時剪除病穗，移除感染源。"}, "1679414108.3382823": {"單位": "", "標題": "稻麴病發生史", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻稻麴病於1878年由Cooke首先報告，1887年以後，陸續有本病之報告。在中國古代亦有此病之記載，由於本病通常發生在適宜的氣候下，特別是高溫多雨的環境，一般農民稱「稻麴」為「穀母」。日本早在 1950 年代就有本病之研究報告出現，其後陸續出現之報告頗多。在臺灣，有關本病之研究報告不多，因為本病在過去僅零星發生，而且發病輕微，故不受重視。然而近年來在臺灣水稻田卻常普遍發生，影響稻穀產量及品質。"}, "1679414212.4271169": {"單位": "", "標題": "稻麴病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "本病發生的部位在穀粒，通常在稻抽穗開花後1~2星期，榖穎的間隙出現青淡黃色的小形肉塊，為病原菌的菌絲塊，使內、外穎腫脹，由縫合處露出灰綠色的菌塊，包圍穎面，而呈黃、黃綠及綠色等，最後病榖裂開如花，表面粉狀，稱為稻麴。病榖粒比健全榖粒大約3~4倍，因重量增加而下垂。菌塊表面有一層薄膜，膜破裂後，露出黃綠色或黃黑色的厚膜孢子。病原菌在穀粒尚有米漿時即可發現，成熟後將整個穀粒包住，其顏色變黑，極易脫落，越冬後繼續傳播。稻麴的分布，主要集中在中段及下段，罹病穗之穗重顯著減輕。"}, "1679414576.3754723": {"單位": "", "標題": "稻麴病分布", "作者": "", "發布日": 0, "摘要": "", "全文": "在全世界水稻栽培區均可發現，包括美國、亞洲的日本、臺灣、印尼、菲律賓、印度等國。"}, "1679414603.1439164": {"單位": "", "標題": "稻麴病寄主", "作者": "", "發布日": 0, "摘要": "", "全文": "主要危害水稻，但印度亦曾報導可發生於玉米上。"}, "1679414626.0682724": {"單位": "", "標題": "稻麴病診斷", "作者": "", "發布日": 0, "摘要": "", "全文": "通常在稻抽穗後1~2星期，榖穎的間隙出現青淡黃色的小形肉塊，為病原菌的菌絲塊，使內、外穎腫脹，由縫隙處露出灰綠色的菌塊，最後包圍穎穀外面，而呈黃、黃綠及綠色等，罹病稻榖裂開如爆玉米花，表面呈粉狀。"}, "1679414653.6303847": {"單位": "", "標題": "稻麴病生活史", "作者": "", "發布日": 0, "摘要": "", "全文": "稻麴菌在稻粒上存活，可經由育苗而感染植株，當孕穗時菌體在稻榖中生長繁殖，並裸露在稻穀之外，稻麴上的薄膜可裂開，將孢子釋放出來，經由雨水傳播至未成熟的稻穗上。稻穗上罹病的榖粒採收後，可經貯藏而維持活力，成為主要的初級感染源。"}, "1679414689.2904565": {"單位": "", "標題": "稻麴病發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "本菌厚膜孢子在無菌水及水瓊脂中的發芽率均達90％以上，發芽率在溫度25℃最佳，其次為30℃、再次為20℃。在pH值4~9下，厚膜孢子均可發芽，最適pH值在5~8之間。稻麴呈黃色者，厚膜孢子發芽率達93％，稻麴呈黑色者發芽率僅6％。病原菌菌絲在馬鈴薯葡萄糖瓊脂培養基上生長速度緩慢，約需5週才能長滿9公分的培養皿。厚膜孢子所產生之分生孢子在水瓊脂之發芽率最高可達10％，在馬鈴薯瓊脂培養基上可達80％；分生孢子在pH6~9均可發芽，而以pH 6時最適宜。\n臺灣在第二期稻發病比第一期稻普遍而且嚴重。日本報告有5-l0％之稻麴會帶有菌核，而由菌核產生之分生孢子做為第一次感染源，厚膜孢子為第二次感染源，或在秧苗期以厚膜孢子接種，在抽穗期亦會產生稻麴。但在臺灣由田間採回之稻麴尚未看到菌核，所以，在臺灣以何種形態之病原為感染源尚不清楚。\n根據1983第二期稻田間調查的結果，水稻稻麴病罹病叢率達14.8％，罹病穗率達10.0％。一稻穗中稻麴數1∼8個，其中以1個（64.7％）及2個（20.6％）最多。1988年第二期稻調查結果，罹病穗率最高為12.5％，最低為2.3％，每穗稻麴數最高為2.7個，最低為0.3個。\n"}, "1679414721.5915313": {"單位": "", "標題": "稻麴病防治方法", "作者": "", "發布日": 0, "摘要": "", "全文": "(一) 選用無病原稻種，生長期中勿偏施氮肥。\n(二) 剪除病穗。\n(三) 75％四氯異苯晴可濕性粉劑500倍及58％鋅錳減達樂可濕性粉劑400倍在抽穗期及齊穗期各施藥一次，可以減少稻麴病的危害。"}, "1679414836.672719": {"單位": "", "標題": "水稻稻麴病現蹤，防治對策健康稻種最重要", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻稻麴病為真菌性病害，主要危害水稻穀粒，農民常稱為「榖母」，通常在水稻抽穗開花後一至二星期發病，造成穀粒裂開，表面呈黃色或黑色粉狀，且碰觸容易造成粉狀物飛散，進而影響稻米品質與產量。稻麴菌可在稻穀上存活，罹病稻榖採收後，可經貯藏維持活力，成為本田期主要的初級感染源。當孕穗時菌體在稻榖中生長繁殖，並裸露於稻穀之外，稻麴上的薄膜可裂開，將孢子釋放出來，經由風雨傳播至未成熟的稻穗上。病原菌在穀粒尚有米漿時即可發現，成熟後將整個穀粒包住，後期顏色變黑，極易脫落，越冬後繼續傳播。\n    今年一期稻作稻麴病之發生狀況較往年普遍，桃園、新竹、苗栗及花蓮地區皆有發生，苗栗地區發生鄉鎮包括西湖鄉、銅鑼鄉及苗栗市等地，由於稻麴病會影響產量及品質，提醒農友採用健康稻種，種植期間勿偏施氮肥，巡田時如發現罹病稻穗，立即剪除並帶離田區，以減少感染源。\n"}, "1679414933.9849124": {"單位": "", "標題": "稻麴病", "作者": "", "發布日": 0, "摘要": "", "全文": "本病發生的部位在榖粒，稻麴菌在稻粒上存活，可經由育苗而感染植株，當孕穗時菌體在稻榖中生長繁殖，並裸露在稻榖外。稻穗上罹病的榖粒採收後，可經貯藏維持活力，成為主要的初級感染源。"}, "1679415347.4552047": {"單位": "", "標題": "稻麴病病徵和傳播", "作者": "", "發布日": 0, "摘要": "", "全文": "病菌通常在孕穗期開始生長繁殖，受感染的穀粒會不正常增生膨大，並呈現黃至暗綠色，高溫多雨的環境容易發生，雨水可將病菌孢子傳播至健康的稻穗。"}, "1679448228.7243934": {"單位": "", "標題": "水稻細菌性條斑病好發時節，請農友注意防治", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病在高溫高濕環境下容易發生，入秋以來氣溫仍然偏高，雲林縣動植物防疫所籲請農友留意田間植株生長情形，若發現病癥請儘速防治。\n據行政院農業委員會農業試驗所表示，水稻二期作種植期間常發生細菌性條斑病。病害為細菌所引起，在高溫高濕環境下容易發生，強風豪雨更是造成水稻葉片產生傷口及維持高濕環境，有利病菌侵入和擴散。"}, "1679448310.4177632": {"單位": "", "標題": "水稻「細菌性條斑病」好發時節，籲請農友注意防治", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻二期作種植期間常發生細菌性條斑病。病害為細菌所引起，在高溫高濕環境下容易發生，強風豪雨更是造成水稻葉片產生傷口及維持高濕環境，有利病菌侵入和擴散，入秋以來氣溫仍然偏高，惠請農友留意田間植株生長情形，若發現病癥請儘速防治。"}, "1679448846.6861062": {"單位": "", "標題": "水稻細菌性條斑病簡述", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病 (Xanthomonas oryzae pv. oryzicola) 原分布於中國 (福建、廣東、海南、湖南及浙江省)、印度、東南亞各國及澳洲等，為熱帶地區水稻栽培重要的病害。民國96年首度在臺灣中部靠山地區稻田零星發生，97、98年二期稻作在中部稻區亦見零星發生；99年二期稻作在中、雲、嘉、南水稻區普遍發生，尤以臺南白河、東山部份地區發生尤為嚴重。\n本病在臺灣因屬新發生的水稻病害，相關研究單位尚未累積足夠本地病害發生之研究資訊及防治對策經驗予指導農民。\n"}, "1679448967.0134606": {"單位": "", "標題": "水稻細菌性條斑病條斑型病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "發病初期在水稻葉片葉脈間出現短或長的水浸狀條痕，隨著病勢進展，水浸狀條痕漸轉呈黃褐色條斑；此一發病階段，發病的條斑範圍會逐漸擴大超越葉脈範圍，嚴重時，條斑會相互癒合而呈較大黃褐色條斑，在田間偶也可觀察到呈赤褐色條斑，此種病徵以秈稻較多；此一發病階段，病斑上亦會產生許多乳白色透明露水珠狀的菌泥，即病原細菌體，這些菌泥乾燥後仍粘附在病斑上；發病末期條斑會轉呈灰白色乾枯。"}, "1679448987.2891932": {"單位": "", "標題": "水稻細菌性條斑病黃化型病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "黃化型病斑在罹病葉黃化徵狀範圍較大，病斑較靠近葉緣，此類病徵在田間並不多見。外觀上，黃化型病斑頗似水稻白葉枯病，唯其病斑邊緣不呈波浪狀，且病斑會保持黃褐色的時間持續較久，不像白葉枯病病斑極易轉呈乾枯狀。"}, "1679449056.5275996": {"單位": "", "標題": "水稻細菌性條斑病傳播途徑", "作者": "", "發布日": 0, "摘要": "", "全文": "病菌主要由稻種 (種子傳播)、稻草和再生稻帶菌傳染以及田梗雜草如李氏禾都能成為初次感染源。病菌主要從傷口侵入，菌泥可藉由風、雨、露水等傳播後造成二次感染。"}, "1679449083.2515974": {"單位": "", "標題": "水稻細菌性條斑病病害發生模式", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻條斑病在田間最初發生多在靠近田梗或路邊，呈線狀發生，當天侯適宜時以面狀向田區中央蔓延，同一地區它的發生比較屬全面性的；而水稻白葉枯病如遇颱風夾帶豪雨或淹水常造成病害大發生，其餘發生多屬點狀，即發病地點集中，換言之，同一地區內可能僅集中在少數幾塊田區發生或同一塊田僅一或數點發生。"}, "1679449169.5521593": {"單位": "", "標題": "水稻細菌性條斑病殘存", "作者": "", "發布日": 0, "摘要": "", "全文": "初次感染源－稻種、田間再生稻或稻椿上之罹病組織的病原細菌可能是水稻條斑病及白葉枯病的共同初次感染源 (田間第一次引起發病的病原細菌)，值得注意的是在田間水稻條斑病一旦發生時，多從田梗或路邊呈線狀開始發生。\n二次感染源－水稻條斑病在田間發生，其罹病葉產生很多乳白色透明露水珠狀的菌泥，它就是田間發病後繼續蔓延發生的病原細菌。\n"}, "1679449260.5553157": {"單位": "", "標題": "水稻細菌性條斑病發生之氣象因子", "作者": "", "發布日": 0, "摘要": "", "全文": "氣象因子中以溫度、濕度、雨水、淹水及風 (颱風) 最為重要，但高溫及持續高濕是水稻條斑病大發生的關鍵。文獻記載水稻條斑病菌最適生長溫度為 28-30℃。由於水稻條斑病今年首次在國內局部大發生，文獻指出颱風豪雨易造成傷口，易造成病害大發生，但今年二期稻(九月)在臺南白河、東山地區颱風、大雨後，遇長期間陰雨的天侯造成病害持續地發生蔓延。而其他地區颱風過後也發現病害發生，但天氣轉晴、乾燥，病害的發生蔓延即受到抑制。"}, "1679449301.0407567": {"單位": "", "標題": "水稻細菌性條斑病田間管理", "作者": "", "發布日": 0, "摘要": "", "全文": "一般梗稻較秈稻、糯稻抗病。\n水稻分蘗盛期以後常於稻間走動，易造成傷口導致發病。\n氮肥過多會增加病害的發生；鉀肥則可減輕病害發生。\n灌水過深加重發病。"}, "1679449500.997083": {"單位": "", "標題": "水稻細菌性條斑病簡介", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病 (Xanthomonas oryzae pv. oryzicola) 原分布於中國(福建、廣東、海南、湖南及浙江省)、印度、東南亞各國及澳洲等，為熱帶地區水稻栽培重要的病害。民國 96 年首度在臺灣零星發生，今年 (97 年) 二期稻作在彰化縣社頭鄉、田中鎮、芳苑鄉、臺中縣龍井鄉及南投縣名間鄉等地再度發生。\n該病害於中國及印度等地造成水稻 5-30%不等的產量損失。水稻嚴重罹病時，外觀上與水稻白葉枯病 (Xanthomonas oryzae pv. oryzae) 極為相似。茲將此病害的危害徵狀、傳播途徑及管理對策作一陳述，供作後續因應之參考。"}, "1679449528.969654": {"單位": "", "標題": "水稻細菌性條斑病危害徵狀", "作者": "", "發布日": 0, "摘要": "", "全文": "初期病斑呈現暗綠色水浸狀半透明斑點，而後在葉脈間伸展形成半透明狀條斑，持續擴大可達寬 0.5-1.0mm、長 3-15mm 的條斑，最後轉為褐色病斑。條狀病斑會相互融合成橙黃色不規則斑塊，之後轉為灰白色，嚴重時全葉乾枯內捲。此外，病斑上常出現許多琥珀色細小露珠狀的病原菌流出物。受害葉片出現半透明狀條斑及病斑上溢出的病原菌物可作為與白葉枯病區分的依據。"}, "1679449580.042116": {"單位": "", "標題": "水稻細菌性條斑病傳播途徑及發病條件", "作者": "", "發布日": 0, "摘要": "", "全文": "帶病的稻種、遺留田間的帶病稻草及帶菌的再生稻苗均可能成為細菌性條斑病的初次傳染原。在田間，病原菌主要由氣孔或稻葉傷口侵入，在溫暖潮濕的環境下，會藉由風、雨水、露水及灌溉水來傳播，尤其是颱風造成稻葉的傷口或瘤野螟幼蟲取食後的食痕均會助長此病害的蔓延。稻種在長距離傳播扮演重要的角色，病原菌可存在稻穎，甚至可侵入胚乳部位。此外，偏施氮肥及深水灌溉的稻田罹病較為嚴重。"}, "1679449630.981859": {"單位": "", "標題": "水稻細菌性條斑病管理對策", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病雖然已在台灣多個鄉鎮被發現，然而呈現點狀的分布，尚無明顯擴展的跡象，如能妥善因應，或能減緩其危害及擴展的速度。由於稻種成為長距離傳播的媒介，應加強採種田的控管，避免由罹病田區採種。國內育種研究人員由菲律賓稻米研究所或東南亞各國引進育種材料應加強稻種消毒的程序，避免試驗改良場所反而成為該病害的傳染原。此外，罹病地區稻田應減施氮肥，可減輕病勢的發展。該病害為白葉枯病病原菌的變種，防治藥劑可選擇克枯爛或鏈四環黴素等。"}, "1679449889.7328405": {"單位": "", "標題": "臺南區農改場籲注意水稻細菌性條斑病的防治", "作者": "", "發布日": 0, "摘要": "", "全文": "雲嘉南地區水稻陸續抽穗，細菌性條斑病於田間零星可見，臺南區農業改良場籲請農友即時進行防治工作，以避免收成時產量損失，並注意藥劑安全採收期，避免農藥殘留之情事發生。\n　　細菌性條斑病罹病 初期病斑呈現暗綠色水浸狀半透明斑點，而後在葉脈間伸展形成半透明狀條斑，持續擴大可達寬 0.5-1.0mm、長 3-15mm 的條斑，最後轉為褐色病斑。條狀病斑會相互融合成橙黃色不規則斑塊，之後轉為灰白色，嚴重時全葉乾枯內捲。此外，病斑上常出現許多琥珀色細小露珠狀的病原菌流出物。受害葉片出現半透明狀條斑，及病斑上溢出的病原菌物，可作為與白葉枯病區分的依據。\n　　水稻罹患細菌性條斑病，避免清晨露水未乾前行走於已發病之稻株間是相當重要的，施肥或噴藥工作建議儘可能於下午進行。防治藥劑可選用下列之一進行防治： 14 ％嘉賜克枯爛可濕性粉劑 1500 倍、 33 ％克枯三賽唑可濕性粉劑 1000 倍、 10 ％克枯爛可濕性粉劑 1000 倍、 10 ％鏈四環黴素可溶性粉劑 1000 倍。\n"}, "1679451743.0230463": {"單位": "", "標題": "茶髮狀病描述", "作者": "", "發布日": 0, "摘要": "", "全文": "主要傳染源為黑色細絲狀菌索，菌索從發生點沿著枝葉往上攀附蔓延，嚴重者茶樹的中、下位葉層枝葉乾枯死亡，影響茶菁產量甚巨。"}, "1679452037.773886": {"單位": "", "標題": "茶髮狀病化學藥劑篩選與田間防治", "作者": "", "發布日": 0, "摘要": "", "全文": "茶髮狀病在臺灣各地茶區零星發生，包括新北市坪林、宜蘭冬山、南投名間與竹山、雲林林內、高雄那瑪夏、臺東鹿野等茶區。該病在發病初期茶樹生長不會明顯受影響，但罹病多年的茶樹則會出現芽葉密度低、成葉變小、植株生長遲緩、產量降低及樹勢衰弱等現象。而目前該病尚無核准登記使用之殺菌劑，故本研究擬針對茶樹上已核准登記使用之 11 種殺菌劑進行對茶髮狀病菌防治之評估，測試藥劑包括四克利、得克利、待克利、克熱淨、免賴得、甲基多保淨、百克敏、扶吉胺、腈硫醌、嘉賜貝芬及腈硫克敏。測試結果指出，除甲基多保淨、腈硫醌及嘉賜貝芬在有效濃度 1,000 ppm 下皆無法達到 50%菌絲生長抑制之效果外，其他 8 種藥劑皆對菌絲生長抑制具有良好效果；另測試 11 種供試藥劑對茶髮狀病菌索活力影響，顯示僅得克利可在有效濃度 100 ppm 處理後可達 50%以上抑制髮狀病菌索生長。進行得克利田間防治茶髮狀病效果評估，結果得知得克利對菌索活力之抑制情形於實驗室與田間測試相同，抑制率皆為 70%左右。茶髮狀病防治除了應用化學藥劑外，更整合應用多種防治策略，包括應注意避免自其他茶園帶入菌索、加強茶樹肥培管理及徹底清源管理等，方可有效降低茶髮狀病病原密度及維持茶樹樹勢之健康。"}, "1679452203.1530557": {"單位": "", "標題": "臺灣茶園常見病害－茶髮狀病", "作者": "", "發布日": 0, "摘要": "", "全文": "受茶髮狀病感染之枝條上會直接長出許多黑色絲狀物(菌索)，菌索可直接由罹病枝上長出，菌索遇固體，在接觸點長出金黃色的菌絲褥，緊密的附著其上。黑色菌索多生長在茶叢中上部位的枝條上，受害嚴重的茶樹，明顯可見枝條或葉片乾枯死亡，其上幾乎為黑色菌索所纏繞。\n茶髮狀病是一種高溫、高濕型病害，在溼度大的茶園較容易發生。目前臺灣各地茶區包括新北市坪林、宜蘭冬山、南投名間、南投竹山、嘉義林內、高雄娜瑪夏、臺東鹿野等茶區，皆有茶髮狀病發生情形。\n"}, "1679452413.3222294": {"單位": "", "標題": "茶樹髮狀病概述", "作者": "", "發布日": 0, "摘要": "", "全文": "茶髮狀病在高溫及溼度大的茶園較容易發生，主要的傳染源為菌索，菌索外層的菌絲含有黑色色素，對不良環境具有很高的耐受能力，室內藥劑試驗，以數種殺菌劑處理後，菌索仍具相當高之活性。"}, "1679452446.8665657": {"單位": "", "標題": "茶樹髮狀病防治", "作者": "", "發布日": 0, "摘要": "", "全文": "罹病茶園在發病初期即應儘速剪除附著有菌索的枝條，並將其燒毀，才是最適當的防治方法。\n夏威夷大學之柯文雄博士建議以火燄燒除法來清除茶叢間之菌索，火燄燒灼的時間以不傷及茶芽為度（進行第一次燒灼時，若能配合施行全園台刈，效果更佳）。\n"}, "1679454295.1373713": {"單位": "", "標題": "茶髮狀病病徵與發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "茶髮狀病最早於 1900 年 Mann 在印度的茶樹上發現，臺灣則首先於 1984 年由胡家儉分場長在茶樹上發現，當時僅發生於臺灣東部少數茶園，為害並不嚴重，然自 1984 年起，臺灣東西部，北至坪林，南至林內茶園均可以發現其蹤跡，近三十年內已逐漸在臺灣茶區蔓延，此病害一旦在茶園立足，則不易防除。髮狀病病原菌菌藉由菌絲聚合而成的菌索傳播，菌索上可長出附著菌絲，牢牢的附著在枝條上，不斷吸取枝條的養分，以耗弱茶樹的樹勢，發病初期茶樹生長不會明顯受影響，但罹病多年的茶樹則出現芽葉密度低、成葉變小、植株生長遲緩、產量降低及樹勢衰弱等現象。菌索為由菌絲間共用細胞壁而非常緊密的聚合在一起，外層的菌絲呈黑色，可以抵抗不良環境，在 6 至 9 月間菌索會產生子實體(菇體)。"}, "1679454339.1219397": {"單位": "", "標題": "茶髮狀病管理策略", "作者": "", "發布日": 0, "摘要": "", "全文": "　　健康茶園應防止本病之入侵。病原菌菌索一旦入侵茶園，可緊密的附著於茶樹枝條上，利用菌索或擔胞子傳播病害。\n　　發病茶園可利用火燄燒除茶叢間之髮狀菌索，燒除時火燄停留的時間以不傷及茶樹葉片或嫩芽為度。每半年燒除一次，連續進行數次。\n　　發病嚴重的茶園，建議進行台刈以徹底清除感染源，並以火燄燒除殘留在枝條上的菌索。\n　　目前尚無推薦之防治藥劑。"}, "1679454461.4205163": {"單位": "", "標題": "茶髮狀病病原生態", "作者": "", "發布日": 0, "摘要": "", "全文": "茶髮狀病是一種高溫、高濕型病害，在濕度大的茶園較容易發生。主要的傳染源為菌索，菌索是由許多菌絲聚合而成的，菌索外層的菌絲含有黑色色素，對不良環境具有很高的耐受能力，室內藥劑試驗，以數種殺菌劑處理後，菌索乃具相當高之活性。機採茶菁時，若混入菌索時，將影響成茶的品質。菌絲的最適生長溫度為24～28℃，最適生長pH4.8～5.8，致死溫度為45℃時5～10分鐘，50℃時5分鐘以內菌絲即死亡，乾熱狀態下，處理5分鐘菌絲即死滅。"}, "1679454601.4613442": {"單位": "", "標題": "茶髮狀病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "受害枝條上會直接長出許多細長黑色絲狀物，菌索可直接由罹病枝上長出，菌索遇固體，在接觸點長出金黃色的菌絲褥，緊密的附著其上。黑色菌索多生長在茶叢中上部位的枝條上，受害嚴重的茶樹，明顯可見枝條或葉片乾枯死亡，其上幾乎為黑色菌索所纏繞。"}, "1679454725.8756697": {"單位": "", "標題": "茶髮狀病防治方法", "作者": "", "發布日": 0, "摘要": "", "全文": "一、田間衛生，去除菌索與剪除附著菌索之枝條，並將其燒毀。\n二、夏威夷大學之柯文雄博士建議以火焰燒除法來清除茶叢間之菌索，火焰燒灼的時間以不傷及茶芽為主(進行第一次燒灼時，若能配合施行全園臺刈，效果更佳)，但必須每半年進行一次。"}, "1679455200.5433898": {"單位": "", "標題": "茶髮狀病敘述", "作者": "", "發布日": 0, "摘要": "", "全文": "由Mann氏在印度茶樹上首先發現。在台灣。1984於茶樹上首先發現本病，茶農習慣稱茶樹上之鬍鬚，當時僅發生於臺灣東部少數茶園，危害情形並不嚴重；1984年起，臺灣茶園，北自坪林，南至林內，都可以發現茶髮狀病。過去認為茶髮狀病菌對茶樹無害，但田間觀察發現其會耗弱茶樹的生機，使茶菁產量有逐年遞減的現象。"}, "1679455225.6168022": {"單位": "", "標題": "茶髮狀病分布", "作者": "", "發布日": 0, "摘要": "", "全文": "據報告指出，此病害多發生於印度、錫蘭（今之斯里蘭卡）、爪哇及澳洲，大部分亞洲熱帶地區都會發生，尤其是多霧潮濕叢林中。"}, "1679455238.0183642": {"單位": "", "標題": "茶髮狀病寄主範圍", "作者": "", "發布日": 0, "摘要": "", "全文": "寄主除茶樹外，還包括荳蔻、橡樹及可可。"}, "1679586395.2886844": {"單位": "", "標題": "水稻細菌性條斑病發生與防治", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病(Bacterial leaf strek)由Xanthomonas oryzae pv. oryzicola引起，與水稻白葉枯病病原同種的新病原型(pathovar)，民國96年首次在臺灣南投縣草屯鎮及雲林縣二崙鄉發現疑似病徵，經證實於台中市、雲林縣、嘉義縣及台南市等地區陸續發現。本文旨在介紹本病發生生態、病徵及防治方法，提供農民進一步認識此一病害。\n水稻細菌性條斑病主要發生於菲律賓、中國南方地區、印度、印尼、泰國、西非部份國家及澳洲等地區。據報導，本病害可造成5-30%的產量失，在中國大陸嚴重時損失可達60%。寄主方面，秈稻品種普遍較稉稻品種感病，除危害水稻外，亦感染部份禾本科雜草或作物。\n本病病原主要存在於種子及葉片殘體中，土壤中僅能存活數週。種子及田間水稻殘體為本病初次感染源，爾後病原細菌由水稻氣孔或傷口進入葉片，經由作物間的機械接觸、雨水、灌溉水等途徑傳播，發病適溫25-30℃，高溫、高濕及高氮肥的環境下病害發展迅速且嚴重，目前主要發現於二期稻作。\n本病為葉部病害，在水稻各生長時期皆可感染。病原菌進入葉片後，於葉片的薄壁細胞中增殖。初期病徵在葉脈間呈水浸狀透明條紋，病斑隨病勢進展延長且顏色漸深。透明條斑為本病與水稻白葉枯病區分的明顯病徵。嚴重時可見病斑外產生黄色不透明分泌物，此即菌泥。病斑在後期可能癒合而呈現橘黃色塊斑，最終轉為灰白色，葉片桔萎、捲曲死亡，此時病徵不易與白葉枯病區別。\n本病害防治方法：1.種植健康秧苗，避免由罹病田中採種。2.稻種可利用52℃溫湯浸種30分鐘，降低病原菌數量。3.將田間帶病稻樁、稻草清除或翻埋入土中並淹水降低田間病原菌。4.避免施用過量氮肥。5.目前無推薦藥劑，可參考水稻白葉枯病防治藥劑如10%克枯爛可濕性粉劑或10%鏈四環黴素水溶性粉劑稀釋1000倍，於發病初期進行防治。\n"}, "1679586465.984217": {"單位": "", "標題": "水稻細菌性條斑病(Bacterial leaf streak)發生情形", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病(Bacterial leaf streak)早在 1918 年時即在菲律賓有文獻報導此\n病害的病徵，但當時尚未鑑定病原菌，直到 1957年大陸學者將此病害正式命名為細菌性條斑病，命名病原菌為Xanthomonas oryzicola。條斑病主要發生於菲律賓、中國南方地區、泰國、馬來西亞、印度、越南、印尼、西非部分國家等地區。Naik等人曾報導易感染細菌性條斑病的水稻品種千粒重損失28.6-32.3%，中國大陸報告細菌性條斑病造成減產 10-30%左右，嚴重者甚至可達60%以上。\n在台灣，2007年第二期作期間(8月中、下旬)，分別於南投縣草屯鎮早熟糯稻田區和雲林縣二崙鄉台南11號田區首次發現疑似病徵，經過16S rDNA定序比對結果與Xanthomonas oryzae pv. oryzae 相似度高達97%以上，另以人工接種完成柯霍氏法則，由病徵及生理生化測試確定為細菌性條斑病，隨後陸續在台中、彰化、雲林、嘉義、台南等地區亦發現相同的病。筆者自2007年調查台中至台南等中南部地區細菌病條斑病發生情形，至今發現條斑病主要發生在第二期稻作，第一期稻作則尚未發現條斑病。\n"}, "1679586481.9062471": {"單位": "", "標題": "水稻細菌性條斑病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻全生育期皆可發病，分蘗期至孕穗期發病較重。初期在葉片上形成暗綠色水浸狀半透明病斑，與白葉枯病菌的危害情形有所不同，條斑病形成之病斑受到葉脈限制呈條斑狀延展，在部分感病品種上病斑四周會産生黄暈 (yellow halo)。當溼度高時，病菌會於病斑表面滲出細小球狀的黄色菌泥。病斑漸漸變淡褐色，部分病斑會互相融合呈橘黄色不規則斑，最後整葉枯死內捲，葉片呈灰白色，最後的病徵很難與白葉枯病的病徵區分。Shekhawat & Sreivastava指出病原菌感染水稻劍葉或小花時，造成子房、雄蕊、胚乳呈褐色或黑色壞死，穎片褐變，進而影響水稻產量。"}, "1679586498.2605543": {"單位": "", "標題": "水稻細菌性條斑病發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "細菌性條斑病菌由自然開口(尤其是氣孔)或傷口侵入，在薄壁組織細胞間增殖造成為害。其發病條件類似白葉枯病，於高溫多濕、高氮肥的環境下易發生，26-30.5℃適合發病，溫度若低於22℃病斑停止擴大，低於16℃則無病斑産生。病原菌可藉由雨水、灌漑水、昆蟲、農事操作、葉子互相接觸和帶病之野生稻作近距離的傳播，以帶病種子作遠距離傳播。病原菌靠病株殘體與帶病種子在田間存活，其可存在於穀粒的種殼、種皮與種胚内，胚乳内則無病原菌存在，1972年Shekawat & Sreivastava報告指出條斑病菌存活在成熟的種子穎殼下，只有在開花期接種時才會感染子房、胚乳等部位，之後的時間接種只會感染穎殼，待種子發芽後感染真葉造成為害，為初次感染源。已知細菌性條斑病菌在稻種內可存活9個月，乾燥病葉可長達12個月，在土壤中則只有7週，在灌水中存活的時間則依溫度不同而有差異，可存活10-90天不等。病斑産生之菌泥為二次感染源，在劍葉上形成之菌泥是引起稻種感染的主因，在有露水或雨水狀態下經風吹會造成葉與葉之間感染，若菌泥掉入灌漑水中，則造成田與田之間感染。"}, "1679586515.6274183": {"單位": "", "標題": "水稻細菌性條斑病抗病育種篩選", "作者": "", "發布日": 0, "摘要": "", "全文": "1965年，Goto測試102個水稻品種發現稉稻較秈稻抗病，然歐等人於1970年時測試了1000個以上的水稻品種，發現不論稉稻或秈稻皆無抗性。大陸學者發現屬於小葉型、葉片窄而直立、葉片氣孔密度較低、氣孔開張度較小的水稻則抗性較強。李等指出抗細菌性條斑病菌的資源多來自東南亞地區的印度、孟加拉與菲律賓，大多為老品種，其農藝性狀不佳。郭等人報導發現一IRBB5(xa-5)對白葉枯病和細菌性條斑病兩種病害均有很高的抗性另有報導IR20、Krishna和Jagannath此三種水稻品種對條斑病具有抗性。"}, "1679586554.8116698": {"單位": "", "標題": "水稻細菌性條斑病防治對策", "作者": "", "發布日": 0, "摘要": "", "全文": "防治細菌性條斑病的方法與防治白葉枯病的方法相近，可分為以下幾個方向：(1)栽培抗病品種：台灣水稻目前尚未針對細菌性條斑病進行抗性檢定，未來可考慮以R20、Krishna和Jagannath三種水稻品種作親本來進行抗病育種。(2)稻種消毒：林等人研究種子消毒和秧苗期施藥防治細菌性條斑病較有利。1965年，Faan與Wu曾使用有機汞藥劑處理帶菌種子可有效防治條斑病發生。稻種浸於0.025% Streptomycine 溶液中，或利用52 ℃溫湯處理30分鐘，可以降低病菌在種子上的數量。(3)將田間帶病稻樁、稻草燒毁，或翻埋入土中並淹水以降低病原菌數量。(4)勿施用過多氮肥。(5)已發病田區灌漑水勿採用淹灌或串灌的方式，促使病原菌株到株或田到田傳播。(6)清除雜草減少昆蟲息地，以減少昆蟲取食時造成之傷口。(7)拮抗菌防治：Rao等人，發現一些葉表微生物如Pseudomonas、Ewinia、 Aspergillus可作為拮抗菌。大陸學者研發之Recor製劑(Cladosporium)與B－HCH製劑(Bacillus)對田間水稻的保護作用較防治效果較強。(8)田間藥劑防治：施用 Vitavax(0.15-3.0%)可有效防治本病；大陸學者使用 5%辛氨乙甘酸(菌毒清)水劑與50%Chlorine Dioxide水溶劑(殺菌王)防治效果不錯。筆者測定細菌性條斑病菌對不同藥劑之感受性，發現10種農用藥劑對細菌性條斑病菌之生長均有抑制效果，但以80%鋅錳乃浦可濕性粉劑1000X溶液的效果最佳，可供後續溫室與田間藥劑防治試驗挑選藥劑時作參考。"}, "1679586579.0200047": {"單位": "", "標題": "Xanthomonas oryzae pv. oryzicola 引起的水稻細菌性條班病", "作者": "", "發布日": 0, "摘要": "", "全文": "2007年在南投縣草屯及雲林縣二崙鄉田區水稻陸續出現暗綠色至黄褐色斑的病徵，條斑上有時可見细小的黃色菌泥，後來陸續在苗栗、台中、彰化、嘉義、台南、花蓮和台東等地發現相同的病徵，從條斑處可分離出黄色細菌，菌落型態類似白葉枯病菌，經柯霍氏法確定此黃色細菌為病原，經過16S rDNA定序比對，結果顯示此病原細菌與水稻白葉枯病菌Xanthomonas oryzae pv. oryzae (Xoo)相似度高達97%，與Xanthomonas oryzae pv. oryzicola (Xoc)相似度達100%，此病原細菌接種至供試水稻品種上皆造成條斑狀病徵，不同於白葉枯病菌造成的典型葉枯型病徵，且生理生化試驗測定結果得知該細菌可利用L-Alanine，但無法生長在含有Cu(NO3)2的培養基中，確認該病原細菌為X. oryzae pv. oryzicola，可引起水稻細菌性條斑病。又於溫室接種不同水稻品種測試其抗感病性程度，結果顯示16個台灣常見品種均可感病，但3個供試菌株造成的發病程度不一，XOCH-1菌株(平均罹病等級為1.8)致病力明顯較XOCI-1c(2.3)及XOCK-1b(3.1)弱。「台稉2號」、「台稉8號」、「台稉11號」、「台稉16號」和「台南11號」發病率均達100%，「台南11號」和「台稉16號」平均罹病等級最高(3.6和33)；發病率最低者分別為「高雄145號」(41.7%)、「台東30號」(41.7%)和「台稉糯1號」(78.3%)。測試10種殺菌劑在不同濃度下對該病菌的生長抑制效果，以81.3%嘉賜銅可濕性粉劑400X、80%鋅錳乃浦可濕性粉劑1000X，以及白葉枯病防治藥劑10%鏈四環黴素可濕性粉劑1000X、10%克枯爛可濕性粉劑1000X的效果最佳，將其稀釋液於溫室內進行防治試驗，結果顯示4種藥劑均能降低發病率，且接種前施用較接種後施用防治效果佳，其中以接種前3天施用鋅錳乃浦、接種前7天及前1天施用嘉賜銅的防治效果最佳。"}, "1679586618.3044472": {"單位": "", "標題": "水稻細菌性條班病在台灣之發生", "作者": "", "發布日": 0, "摘要": "", "全文": "由於台灣屬高溫多濕的海島型亞熱帶氣候，病蟲害繁多，每年水稻因為病害造成的損失約6%。根據《台灣植物病害名彙》(Taiwan Phytopathological Society 2002)所述，台灣目前已記載有80種病原，主要病害為稻熱病(rice blast)、白葉枯病 (bacterial blight; BB)和紋枯病(sheath blight; ShB)等。 \n2007年第2期作期間(8月中、下旬)，分別於南投縣草屯鎮早熟糯稻田區和雲林縣二崙鄉「台南11號」稉稻田區，首次發現葉片上許多暗綠色或黃褐色之條斑，溼度高時條斑上可見細小的黃色菌泥(ooze)，與台灣常見之細菌性病害白葉枯病(病原菌Xanthomonas oryzae pv. oryzae, Xoo)病徵略有不同，其在葉片邊緣形成波浪狀病斑，並隨著葉脈往下蔓延，在葉脈兩側形成黃化病斑之典型葉枯病徵，但與國外記載由不同病原型Xanthomonas oryzae pv. oryzicola (Xoc)引起的細菌性條斑病(bacterial leaf streak; BLS)受葉脈侷限形成之條斑病徵相似，隨後陸續於台中、彰化、嘉義和台南等地發現相同的病徵。\n"}, "1679586653.2059312": {"單位": "", "標題": "水稻細菌性條班病田間病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "2007年首先於南投縣草屯鎮早熟糯稻田區和雲林縣二崙鄉「台南11號」稉稻田區發現葉片上可見許多暗綠色或黃褐之條班， 濕度高時條斑上可見細小的黃色菌泥，在「台南11號」上可見病斑周圍產生黃暈(yellow halo)，較嚴重者病斑融合呈橘黃色不規則斑。6個供試品種皆於接種3-4天後葉面開始出現墨綠色水浸狀小點，隨後受葉脈限制往上下蔓延，呈暗綠色或黃褐色條斑，在強光照射下病班呈半透明狀，濕度高時病斑上常附著許多細小球狀之黃色菌泥； ‘TK2’和‘TN11’水稻品種上可見病斑周圍有黃暈產生。隨後病班漸漸變淡褐色，部分病斑會互相融合呈橘黃色不規則斑，最後整葉枯死內捲，葉片呈灰白色，與田間病徵相同。"}, "1679586673.0488183": {"單位": "", "標題": "水稻細菌性條班病病原菌生理生化特性", "作者": "", "發布日": 0, "摘要": "", "全文": "供試之病原菌在生理生化特性方面與Xoc相近，為革蘭氏陰性，短桿狀，具單一極生鞭毛，為好氣性菌，在YDC培養基上可產生黃色色素，於30℃培養時產生黏稠狀(mucoid)菌落，在KB培養基上不產生螢光色素，不具有氧化酶(oxidase)、過氧化氫酶(catalase)、 尿素酶(urease)及硝酸還原活性，可利用L-Alanine，但無法生長在含有Cu(NO3)2的培養基中。"}, "1679586689.2783105": {"單位": "", "標題": "台灣水稻品種對細菌性條斑病的抗感性試驗", "作者": "", "發布日": 0, "摘要": "", "全文": "16個供試水稻品種分別接種3株供試菌株的結果，不同地區採集的菌株在不同品種上的發病程度不一，但可見從草屯採集的XOCH-1菌株致病力明顯較從雲林和台南採集的XOCI-1c及XOCK-1b菌株弱。以稉稻而言，‘TK2’、‘TK8’、 ‘TK11’、‘TK16’和‘TN11’品種發病率均達100%，並以‘TN11’、 ‘TK16’和‘TK11’品種接種3個供試菌株後的平均罹病等級最高，分別為3.6、3.3及3.2，‘TK16’接種XOCK-1b後罹病等級甚至達5.7；其次為‘TK5’、 ‘TK14’和‘TNG71’品種，發病率均達90%以上；‘KH145’和‘TT3’兩品種發病率41.7%明顯較其他12種低，甚至在接種XOCH-1後不發病。2個秈稻和2個糯稻品種均可被供試菌株感染致病，且接種XOCK-1b後的罹病等級較其他菌株高，甚至在秈稻品種皆達4.0以上，但明顯可見‘TKG1’品種的發病率78.3%較其他3個品種低。"}, "1679586716.1388566": {"單位": "", "標題": "台灣水稻細菌性條斑病之藥劑感受性", "作者": "", "發布日": 0, "摘要": "", "全文": "測試結果顯示，10種殺菌劑在不同稀釋倍數下，除3%嘉賜黴素溶液200X與400X稀釋液對供試之6個Xoc菌株、3%嘉賜黴素溶液100X稀釋液對XOCF-9b、XOCH-1、XOCI-3b 及XOCK-1a 以及歐索林酸處理組對XOCF-8b的生長均無抑制效果外，其餘處理對供試Xoc之生長皆有抑制效果，抑制圈直徑最高可達3.29cm(80%鋅錳乃浦可性粉劑1000X稀釋液)，平均抑制效果前5大分別為81.3%嘉賜銅可濕性粉劑500X(2.51cm)、80%鋅錳乃浦可濕性粉劑1000X (2.46cm)、80%鋅錳乃浦可濕性粉劑1500X (2.36cm)、 80%鋅錳乃浦可濕性粉劑2000X (2.32cm)和81.3%嘉賜銅可濕性粉劑1000X (2.05cm)，效果最差者為3%嘉賜黴素溶液處理組，其次為27.12%三元硫酸銅水懸劑處理組。對Xoo而言，含銅類藥劑之鹼性氯氧化銅、氫氧化銅與三元硫酸銅無抑制效果，3%嘉賜黴素溶液處理組亦僅100x稀釋液XM42菌株外無抑制效果，平均抑制效果前5大分別為80%鋅錳乃浦可濕性粉劑1000X (3.18cm)、80%鋅錳乃浦可濕性粉劑2000X(2.94cm)、80% 錳乃浦可濕性粉劑1500X(2.84cm)、12.5% 鏈黴素溶液100X與200X稀釋液(2.73cm和 2.53 cm)。"}, "1679586741.1636302": {"單位": "", "標題": "水稻細菌性條斑病溫室藥劑防治試驗", "作者": "", "發布日": 0, "摘要": "", "全文": "當於溫室使用4種藥劑進行防治試驗，結果每個處理組的發病率均比對照組(80%上)低，其中接種前3天施用鋅錳乃浦、接種前7天及前1天施用嘉賜銅的防治效果最佳，完全不發病。除接種前3天施用嘉賜銅的處理組發病率達37.5%外，接種前施用鋅錳乃浦和嘉賜銅明顯比接種後施用的處理組發病率低，發病率為18.8%以下，而克枯爛要於接種前3天以上才能達到相同的防治效果；鏈四環黴素於接種當天施用效果最佳，發病率為12.5%，接種前7天施用之理處理組次之。"}, "1679586821.9132519": {"單位": "", "標題": "水稻細菌性條斑病發現至鑑定之過程簡述", "作者": "", "發布日": 0, "摘要": "", "全文": "筆者2007年於南投草屯、雲林二崙陸續發現水稻上出現暗綠色至黃褐色之條斑狀病徵，病斑上有時可見細小的黃色菌泥，從病斑處可分離出類似Xoo之黃色細菌，經過16S rDNA定序比對，結果顯示此病原細菌與Xoo相似度高達97%以上。然此病原細菌接種至供試水稻品種上皆造成條斑狀病徵，明顯與Xoo引起的典型葉枯型病徵不同，而與國外報導由不同病原型Xanthomonas oryzae pv. oryzicola引起之BLS的病徵相似，惜鑑定時資料庫未有Xoc的序列資料可供比對。之後，再以XOCH-1及 XOCK-1b 2個菌株重新進行定序鑑定，結果顯示2個菌株與Xoc相似度達100%。Swings et al. (1990) 曾表示可使用下列方式來區分Xoc與Xoo：(1)在水稻上的病徵；(2)部分生理生化特徵差異；(3)蛋白質指紋圖譜(fingerprint)；(4) 脂肪酸組成(fatty acid proflile)；以及(5)病原型專一單元抗體(monoclonal antibodies)。本試驗的生理生化試驗結果，除不能使明膠液化且無法水解澱粉外皆與Xoc相近，而與Xoo不同，且其中該細菌可利用L-Alanine，但無法生長在含有Cu(NO3)2的培養基中，皆為文獻中記載Xoc和Xoo不同之處。明膠液化與澱粉水解能力結果與文獻不同，其原因可能是供試菌株跟國外菌株之間存有差異，也可能受試驗方法或紀錄結果之日數不一所影響。綜合上述病徵表型、16S rDNA定序比對及生理生化測定結果，顯示引起台灣水稻早熟糯稻和「台南11號」條斑狀病徵的病原細菌為X. oryzae pv. oryzicola。筆者目前已在苗栗、台中、彰化、雲林、嘉義、台南、花蓮和台東發現本病害發生，田間已發現的罹病品種有早熟糯稻、「台中秈17號」(‘TCS17’)、「台東31號」(‘TT31’)、‘SA169’、 ‘TCS10’、 ‘TK2’、 ‘TK16’、 ‘TN11’、 ‘TNG67’、 ‘TNG70’、 ‘TNG71’和‘TNGS22’，多屬稉稻。\n由Xoc所引起之BLS，早在1918年即有文獻報導，當時尚未確認病原菌，直至1957年大陸學者Fang et al. (1957)將此病害正式命名為細菌性條斑病，病原菌為Xanthomonas oryzicola，直至1990年才由 Swings et al. (1990)重新命名為 X. oryzae pv. oryzicola。本病害主要分佈於菲律賓、中國南方地區、泰國、馬來西亞、印度、越南、印尼、西非部分國家等地區。Xoc可危害水稻全生育期，感染水稻劍葉或小花時，造成子房、雄蕊、胚乳呈褐色或黑色壞死，穎片褐變，進而影響水稻產量。據報導BLS可造成減產10-30%左右，嚴重者甚至可達60%以上。在台灣，BLS主要發生在第2期作，直至2012年才在花東地區發現第1期作為害，於水稻田區呈不均勻分佈，且多與白葉枯病(BB)共同為害。本病害的發病條件類似BB，於高溫多濕、高氮肥的環境下易發生，26-30.5℃適合發病，且Xoc可藉由帶菌種子傳播，BLS在台灣有可能造成重危害。\n"}, "1679586847.3294961": {"單位": "", "標題": "水稻細菌性條斑病品種感病性統整", "作者": "", "發布日": 0, "摘要": "", "全文": "筆者於溫室測試16個台灣水稻品種對Xoc之感病性，來研判將來BLS在台灣可能危害程度，結果發現秈稻、稉稻與糯稻皆感病，但不同地區採集的菌株在不同品種上的發病程度不一。稉稻中‘TK2’、 ‘TK8’、 ‘TK11’、 ‘TK16’和‘TN11’品種病率均達100%，其次為‘TK5’、 ‘TK14’和‘TNG71’ 水稻品種，平均發病率分別為97.6、91.6及95.3%。‘KH145’和‘TT30’兩品種病率41.7%明顯較其他12種低，甚至接種XOCH-1時不發病；2個秈稻和2個糯稻品種均可被供試菌株感染致病，‘TKG1’品種的發病率78.3%明顯較低，但4個品種接種XOCK-1b後的罹病等級較另兩個菌株高。其中‘TK2’、 ‘TN11’和‘TK8’同時為良質米推薦品種與2007-2012年種植面積前10大之品種(TRIS)，使BLS在台嚴重發生具有潛力。Goto (1965)曾表明水稻品種間的抗感病性差異明顯，認為稉稻較和秈稻和糯稻抗病，而Ou et al. (1970)認為秈、稉稻皆無抗性，本試驗的結果較似後者。然亦有報導指出，同一品種和不同類型與來源的稻種對BLS的抗感性在不同地區表現有很大的差異，這些差異可能與檢測方式(如供試水稻株齡)及供試菌株不同有關。本試驗結果亦發現使用不同菌株結果呈現不同的抗感性，未來如要進行其他品種的抗感性測試時，必須注意供試菌株的選擇。"}, "1679586893.947377": {"單位": "", "標題": "水稻細菌性條斑病防治藥劑測試結果簡述及建議之防治策略", "作者": "", "發布日": 0, "摘要": "", "全文": "有關BLS的藥劑防治研究較少，多建議議使用BB的防治藥劑即可，國外曾報導施用Vitavax (0.15-3.0%) 可有效防治本病， 大陸學者Xing & He (2007)也曾於室内測定新殺細菌劑噻森銅(Saisentong)對Xoo和Xoc的抑制能力，結果與田間已用來防治BB及BLS的藥劑噻枯唑 (bismerthlazol)差異不顯著。為提供農民可使用之防治藥劑，筆者從可抑制Xoc生長的10種不同濃度之殺菌劑中選取抑制效果最佳的藥劑嘉賜銅和鋅錳乃浦，與已推薦使用在防治白葉枯病的藥劑鏈四環黴素和克枯爛於溫室進行防治試驗。結果顯示，4種藥劑均能降低發病率，且接種前施用較接種後施用防治效果佳，其中以接種前施用較接後施用防冶效果佳，其中以接前3天施用鋅錳乃浦、接種前7天及前1天施用嘉賜銅的防治效果最佳，完全不發病。目前除嘉賜銅未推薦使用在水稻上，田間仍可以使用鏈四環黴素與克枯爛來同時防治本病害及BB，80%鋅錳乃浦可濕性粉劑亦已被用來防治水稻稻熱病，使用濃度(稀釋倍數500X)比溫室試驗(1000X)所使用的更高，可以用於田間防治BLS。除此之外，亦配合清除雜草、病組織翻埋入土中並淹水、勿施用過多氮肥等農事操作，並應注意稻種消毒工作，以降低BLS在田間發生之機率。"}, "1679591391.7399712": {"單位": "", "標題": "稻麴病發生生態與防治概述", "作者": "", "發布日": 0, "摘要": "", "全文": "民國七十二年第二期作田間調查的結果，水稻稻麴病罹病叢率達14.8%，罹病穗率10.0%，一稻穗中稻麴數1~8個，其中以1個(64.7%)及2個(20.6%)最多。稻麴的分布，主要集中在中段(52.7%)及下段(34.4%)，罹病穗之穗重顯著減輕。民國七十七年第二期作調查結果，罹病穗率最高爲12.5%，最低為2.3%，每穗稻麴數均最高爲2.7個，最低為0.3個，病原菌厚膜抱子在無菌水及水瓊脂之發芽均以25℃為最佳，其次為30℃，再次為20℃。在水瓊脂之發芽率高達95%，在無菌水中之發芽率亦高達93%。厚膜胞子發芽之酸鹼度為4~9，最適在5~8之間。黃色稻麴厚膜胞子之發芽率高於黑色厚膜胞子，黄色者發芽率高達93%；黑色者僅6%，有時黑色厚膜胞子甚至不發芽。厚膜胞子發芽能力在室溫25~30℃下最低保持26天，最高保持60天，一般在40~60天，其發芽率隨著保存時間之增加而減少，通常在一個月內發芽率佳，但往後發芽率就顯著下降。病原菌在馬鈴薯葡萄糖洋菜培養基上菌落生長緩慢，生長速度最快者約需5週的時間才能長滿9公分的培養皿。厚膜胞子發芽產生分生胞子，分生胞子在水瓊脂之發芽率可達10.6%，其發芽之酸鹼度以6~7最適。在田間行藥劑篩選，以75%四氮異苯腈及58%鋅錳滅達樂混合可濕性粉劑效果最佳。"}, "1679591414.522516": {"單位": "", "標題": "水稻稻麴病發生紀錄描述", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻稻麴病(Ustilaginoidea virens)，於1878年由Cooke首先報告，1887年以後陸續有本病之報告。在中國古代亦有此病之記載，由於此病發生在最適宜的氣候件下，特别是高濕多雨，與水稻生長的氣候相似，被故認為在「好年冬」時才會發生本病，一般農民稱「稻麴」 為「榖母」。\n日本早在1950年代就已經開始本病的研究，尤其是在岐阜大學的池上氏發表的報告最多。有關本病田間發生生態，菌絲生長對營養的需求，接種試驗及傳播途徑在國外已有報告，但本省尚未有有關稻麴病的研究報告。因為本病在過去僅零星發生，而且發病輕微，故不受重視。但是近年來在本省水稻田曾普遍發生，影響產量及品質。有鑑於此，乃對本病之生態及防治加以探討，並將所得結果寫成報告，藉供研究及防治之參考。\n"}, "1679591449.7811015": {"單位": "", "標題": "水稻稻麴病田間發病調査", "作者": "", "發布日": 0, "摘要": "", "全文": "民國七十二年第二期作田間調查結果，罹病叢率平均最高為19.3%，最低為11.3%，平均為14.8%。罹病穗率平均最高為14.9%，最低為7.6%，平均為10.0%。稻麴在病穗中以中段(52.7%)最多，其次為下段(34.6%)，上段最少(12.7%)。\n在每病穗中稻麴之數目以1個最多(64.7%)，其次為2個(20.6%)。稻麴之數目對穗重之影響，由於稻麴鄰近之不稔實粒的增加，所以對穗重有顯著的影響。\n民國七十七年第二期作田間調查罹病穗率最高為12.5%，最低為2.3%，平均為5.1%。每穗稻麴數最高為2.7個，最低為0.3個，平均為1.4個。\n"}, "1679591482.0148091": {"單位": "", "標題": "水稻稻麴病接種試驗", "作者": "", "發布日": 0, "摘要": "", "全文": "在所接種的60稻穗，三週後有8穗產生灰白色的稻麴，罹病穗率13.3%，每穗之稻麴數有1~2個。稻麴的色澤隨着稻穗的成熟終成黃褐色。"}, "1679591504.1066859": {"單位": "", "標題": "水稻稻麴病厚膜胞子在水瓊脂及無菌水中於不同溫度下之發芽率", "作者": "", "發布日": 0, "摘要": "", "全文": "稻麴病菌不同菌株厚膜胞子在水瓊脂之發芽率差異甚大，菌株 TP-2及 TP-30 發芽率不高，菌株 Tp-3及 TP-8發芽情形較好。一般發芽溫度範圍在15，20，25及 30℃，尤其在20，25及30℃爲佳，在10及 35°C發芽不佳。\n厚膜胞子在無菌水中之發芽率差異亦甚大，一般其發芽率比在水瓊脂中之發芽率為低，在無菌水中之發芽率仍以TP-8為最佳。"}, "1679591530.2665272": {"單位": "", "標題": "水稻稻麴病厚膜胞子在不同酸鹼度之水瓊脂發芽率", "作者": "", "發布日": 0, "摘要": "", "全文": "厚膜胞子發芽之適宜酸鹼度在5-8之間，三個菌株之發芽率仍TP-8為最高。"}, "1679591550.232157": {"單位": "", "標題": "水稻稻麴病稻麴黃色與黑色部份厚膜胞子在水瓊脂之發芽率", "作者": "", "發布日": 0, "摘要": "", "全文": "同一稻麴黄色部份厚膜胞子發芽率優於黑色部份厚膜胞子之發芽率。取自白河之稻麴黄色部份厚膜胞子之發芽率達93.3%，但黑色部份厚膜胞子之發芽率僅6.5%。由民雄取回之稻麴黄色厚膜胞子之發芽率為30.6%，而黑色部份之厚膜胞子則不發芽。"}, "1679591574.5327601": {"單位": "", "標題": "水稻稻麴病厚膜胞子在室溫下之存活", "作者": "", "發布日": 0, "摘要": "", "全文": "由田間採回12個稻麴在室溫 25~30℃下厚膜胞子發芽能力最低保持26天，最高保持60天，一般在40~60天。其發芽率隨著保持時間之增加而減少。通常在一個月内發芽率佳，但此後發芽率就顯著下降。"}, "1679591596.799704": {"單位": "", "標題": "水稻稻麴病菌落生長速度", "作者": "", "發布日": 0, "摘要": "", "全文": "稻麴病菌在 PDA培養基上生速度緩慢，生長速度最快者約5週的時間才能長滿9公分的培養皿，有的菌株生長速度緩慢，5週後菌落之大小僅6.0 x 6.1公分。"}, "1679591627.8134968": {"單位": "", "標題": "水稻稻麴病分生胞子之發芽率", "作者": "", "發布日": 0, "摘要": "", "全文": "厚膜胞子發芽後產生分生胞子，分生胞子之發芽率不高，菌株 TP-3，TP-8及TP-30發芽率各為4.2，6.7及5.3%。\n分生胞子在不同酸鹼度之發芽率以6及7發芽最佳，但發芽率不高，發芽率最高者僅10.6%。"}, "1679591657.125877": {"單位": "", "標題": "水稻稻麴病田間藥劑篩選試驗", "作者": "", "發布日": 0, "摘要": "", "全文": "民國七十二年第二期作篩選結果，以75%四氯異苯腈可濕性粉劑，80%四氯丹可濕性粉劑，58%鋅錳滅達樂可濕性粉劑及33%鋅錳乃浦可濕性粉劑等四種藥劑之藥效最佳。\n民國七十七年第二期作篩選結果，以75%四氯異苯腈可濕性粉劑及58%鋅錳滅達樂可濕性粉劑防治效果最佳，其罹病叢率僅為0.2及0.3%。"}, "1679591672.450567": {"單位": "", "標題": "水稻稻麴病綜合討論", "作者": "", "發布日": 0, "摘要": "", "全文": "稻麴病近年來在本省各地區普遍發生，影響稻米的生產。民國七十二年第二期作罹病穗率最高達10%，民國七十七年第二期作罹病穗率達12.5%，罹病穗之穗重顯著減輕，故可知稻麴病可影響米質及產量。稻麴病菌厚膜胞子在水瓊脂或無菌水中之發芽，菌株間之差異很大，本試驗中以菌株TP-8發芽率最高。發芽溫度以 25℃ 最適，酸鹼度以5-7最適，黄色稻麴厚膜胞子之發芽率優於黑色稻麴之厚膜胞子，本報告所提到的黑色厚膜胞子可能和日本所提到之綠色厚膜胞子相似。厚膜胞能芽發子力最低保存26天，最高保存60天，日本報告在低溫下可保存十個月。在日本報告有5-10%之稻麴會帶有菌核，而由菌核產生子囊胞子做為第一次感染源，厚膜胞子做為第二次感染源，或在秧苗期就以厚膜胞子接種，在抽穗期亦會產生稻麴。但目前從田間採回之稻麴尚未看到菌核，所以在台灣以何種型態之病原為感染源尚不清楚。不過依據病原菌生長的速度甚爲緩慢，以及稻麴在接種後三週才開始形成，若由稻麴上之厚膜胞子再做為第二次感染源似乎不太可能。在藥劑篩選，由兩年之結果顯示75%四氯異苯腈可濕性粉劑及58%鋅錳滅達樂可濕性粉劑防治效果最佳。"}, "1679913088.9452977": {"單位": "", "標題": "植物保護圖鑑系列 8-水稻黃葉病", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌學名：Rice transitory yellowing virus\n(ICTV正式承認種名Rice yellow stunl virus)\n英名：Rice transitory yellowing\n簡稱： RTYV\n一、前言\n1960年稻作屏東地區第二期稻發生原因不明之病害，起初土壤學者認為是一種由土壤引起之生理性障礙，並稱為窒息病（suffocating disease）。1962年此一新發生之不明病害經邱人璋博士證實係經由黑尾葉蟬媒介傳播之一種新病毒病害。1960年屏東地區第二期稻發生面積達15,273公頃，1961年包括屏東地區以外之彰化、雲林、高雄等新發病地區，總計發病面積為15,548 公頃，1962 年發病面積累計為25,635公頃，由於其發生面積均與「窒息病」併計，故其中黃葉病發生面積究竟佔多少難予確知。此後發病程度逐年減輕，其中僅1970、1972及1975年在中、南部發生較為嚴重，第二期稻發生面積均超過6,000公頃。本病主要發生於第二期稻，第一期稻作則僅見部份地區零星發生。1980年以後本病發生更趨輕微僅零星存在高屏少數地點，至1990年代臺灣水稻栽培區幾無黃葉病發生之蹤跡。\n二、病癥\n黃葉病之主要徵狀為病株之葉片黃化與分 減少。罹病植株下方及中部葉片自葉尖開始轉變為黃銹色，葉脈間組織呈色較淡，隱然有斑駁，位於下方之葉片變色最早，常全葉枯黃，葉面散生銹褐色斑點，靠近葉尖部分撚捲乾枯。此外，發病稻株分 數減少，根群發育較差，生育後期偶有復健之現象，以致罹病植株抽穗明顯延遲。\n三、病原菌概述\n（一）分類地位\n Rhabdovidae\n  Nucleorhabdovirus\n（二）分布\n本病在1960年代主要分布於臺灣中、南部及東部之水稻栽培區，主要發生地域包括中部地區（臺中縣石岡、東勢；南投縣魚池；彰化縣溪州）、屏東地區（屏東縣美濃、枋寮）、臺東地區（臺東市、新港、東河）及花蓮地區（瑞穗、富源）。1980年代以後發生範圍明顯縮小，僅在高雄縣旗山、六龜、美濃一帶仍有零星發生； 1990 年代以後本病幾乎在島內消失。本病亦發生於中國大陸華南地區。\n（三）寄主\n黃葉病病毒除感染水稻外，野生李氏禾及大黍亦可見受其感染。Chiu et al.以機械接種方法成功將病毒接種到非禾本科之菸草。此外，黑尾葉蟬亦為黃葉病病毒之寄主。\n（四）形態\n黃葉病由Rhabdovirus病毒所引起。陳、四方二氏利用罹病葉片粗汁液以陰染法在電顯下可觀察到呈鎗彈型（bulletshaped），寬度為96 nm，長度約為20~140nm，中心具有寬約 45 nm之軸溝（axialcanal），粒子表面佈滿高約7 nm之小突起。純化之病毒樣品，利用PTA陰染在電顯下觀察多數含被膜之病毒粒子，寬度約93nm，長度為124 nm (67~130 nm），被膜表面可見28突起，其高度為5.2 nm，寬約5nm。病葉行超薄切片於韌皮部細胞內亦可觀察到大小約94×180~210 nm，具有三層被膜構造之鎗彈型病毒粒子。另於吸毒後經25日及30日之媒介昆蟲的唾腺亦可觀察到類似前述之病毒粒子。\n（五）媒介昆蟲與傳播\n黃葉病可經由三種黑尾葉蟬（偽黑尾葉蟬Nephotettix cincticeps，黑條黑偽葉蟬 N.nigropictus及臺灣黑偽葉蟬N. virescens）以持續性方式傳播。病毒在黑條黑偽葉蟬蟲體內之潛伏期為3~29日，在偽黑尾葉蟬為21~34日，在臺灣黑偽葉蟬為4~20日。黑條黑偽葉蟬最短獲毒時間為5分鐘，傳病蟲接種最短時間為5~10分鐘。有關三種媒介昆蟲傳播黃葉病的能力，邱氏測試黑條黑偽葉蟬三個蟲群之傳病率分別為62％、41％及65％，而偽黑尾葉蟬在二次試驗所得傳病率分別為25％及35％，臺灣黑尾葉蟬之傳病率為33％。溫度對偽黑尾葉蟬及黑條黑偽葉蟬之獲毒及傳病有明顯之影響，在25及30℃獲毒率較低溫時為高，潛伏期較短。17℃為媒介昆蟲獲毒後完成潛伏期之臨界溫度。偽黑尾葉蟬若蟲獲毒傳病能力較成蟲高，雄蟲較雌蟲為高；但黑條黑偽葉蟬性別間並無差異。此外黃葉病病毒對偽黑尾葉蟬生育有明顯之不良影響。\n（六）診斷技術\n本病毒由於形態特殊，可陰染罹病組織粗汁液或超薄切片罹病組織再以電子顯微鏡觀察病毒，或以機械接種方法將病毒接種到指示植物N. rustica上，或利用血清學技術如酵素連結免疫分析法（ELISA）均可鑑定帶毒媒介昆蟲及罹病植物。\n四、發生生態\n黃葉病之發生以第二期稻為主。謝氏曾於1966~1968年間每月2次在臺中地區檢定田間黑尾葉蟬帶毒蟲個體，發現年中出現二個帶毒蟲高峰期，第一個高峰期出現於六月，帶毒蟲率6~7.7％，第二個高峰期出現於十月，帶毒蟲率約14.5~22.7％。陳氏於1976~1978年間，在中部地區之東勢、大里每月3次採集黑尾葉蟬測定帶黃葉病病毒個體，發現二至四月或五月帶毒蟲個體所佔百分率極低。第一期稻初期媒介昆蟲帶毒蟲率偏低的現象可能受前年第二期稻收割後冬季期間黃葉病罹病株再生能力低以及帶毒蟲壽命較短之影響；第二期稻的情況則相反五至七月田間帶毒個體百分率增高，同一期間黑尾葉蟬的自然族群亦達到第一個高峰期，病毒傳播潛力大。此外，第二期稻期間高溫（26~28℃）有利於病徵的表現及縮短病毒在媒介昆蟲體內之潛伏期，以上諸現象可能說明第二期稻黃葉病發生較嚴重的原因。\n五、防治方法\n從生態學的觀點黃葉病與黃萎病的發生情況極相類似，媒介昆蟲種類又相同，在防治上可採取相同的對策而達到同時防治二種病害的目的。由於第二期水稻黃葉病有70％的罹病株係於秧苗期被感染，因此播種前及秧苗期以殺蟲劑大面積防治田間媒介昆蟲或延遲秧田播種時期，以逃避黑尾葉蟬族群之高峰期的傳毒。此外，育苗中心集中育苗等措施均證實有減少黃葉病發生之功效。在抗病品種方面，高雄農改場曾檢定國內外水稻品種（系）2,758個，發現IR 3260-91-100及4596-PN-132-8-3-15-4等抗病性極強之品種。\n"}, "1679972702.2473757": {"單位": "", "標題": "水稻徒長病 病原菌學名：有性世代 Gibberella fujikuroi (Sawada.) Ito 無性世代 Fusarium moniliforme J. Sheld. 英名：Bakanae disease", "作者": "", "發布日": 0, "摘要": "", "全文": "一.\t前言\n臺灣水稻徒長病最早由澤田氏於1912年記載報告。本病在苗期發生時病徵明顯，一般人常稱之為「稻苗徒長病」，農民則稱之為「稻公」，日本稱之為「馬鹿苗病」，本病不但是苗期重要病害，也是本田期重要病害之一。\n早期採用水秧田育苗，第一期作稻苗徒長病之發生率比第二期作為高，尤其遇旱災無法按時插秧時，老秧苗罹患徒長病之百分率特別高，政府在1960~1980年間，推行稻種消毒補助，本病發生已有顯著減少，但田間尚常可見其發生。張氏報告，稻種經有機汞劑消毒之秧田發病率有0~4.4％之，未經稻種消毒之秧田，其發病率為0.15~22.3％。近年來農友雖有做稻種消毒，田間還是普遍發生，本田期發病率與秧苗期相似，田與田間差異甚大，成熟期水稻有0~20％因徒長病而枯死。本病引起稻產量之損失，國外已有報告，但各地之損失量不一。臺灣尚未見評估報告。\n\n二.\t病徵\n秧苗期徒長病，罹病苗常比健康苗高出1/3~1/2以上，病苗纖細黃綠色，葉幅變小，葉片與葉鞘之著生角加大。徒長苗在移植後大部分枯死，移植後未死之病株病徵常會消失，至分蘗盛期又陸續再表現病徵。\n水稻分蘗盛期，除秧苗期被害之病苗再顯現病徵外，亦有新病株陸續出現病徵，插秧時原有病株再顯現病徵者一般無分蘗，新病株則常有少數分蘗。本田期徒長病之病徵與秧苗期之病徵相似，病株纖細黃綠色，葉幅狹小，葉片著生角加大，病株比健株高，當陽光照射及微風吹動時，極易識別徒長病株。徒長病株之莖節處生有不定根，稻稈維管束褐變，病菌在葉鞘內側及莖節上產生菌絲及小型分生孢子。當病株的維管束褐變蔓\n延到整株時，基部開始腐爛，故又名腳腐病（Foot rot）。隨之全株萎凋枯死，並產生白粉紅色的菌絲層，菌絲層上密生分生孢子，偶爾可見橙色之分生孢子堆，菌絲層最後轉變為淡灰色。當稻株間之濕度大時，常可見淡灰色的菌絲層上散生有籃黑色的小點，此即病菌之子囊殼。有些病株上並無濃密之菌絲層，亦直接由病組織長出子囊殼，子囊殼單生或叢生。徒長病株大部份在水稻開花前死亡，無法抽穗；後期感染病株至抽穗期無論有無明顯病徵常能抽穗，但抽穗後病株相繼死亡，稻穗上皆為空粒或有少數榖粒但皆不飽滿。\n\n三.\t病原菌概述\n(一)\t地位分類\nAscomycetes 子囊菌綱\n   Hypocreales 肉座菌目\n      Nectriaceace 赤殼菌科\n         Gibberella 赤黴菌屬\n(二)\t分布\n本病廣泛分布於全世界稻栽培區。\n\n(三)\t寄主\n雖然有報告指出，本病菌人工接種甘蔗、玉米等禾本科植物，可產生徒長病徵。有人曾將分生孢子與培養過濾液分別接種禾本科植物，結果顯示過濾液可致各種植物表現徒長，分生孢子則只有水稻會顯現徒長病徵。比較不同作物上的Fusarium moniliforme ，也發現水稻的菌株與旱作分離的菌株不同。\n\n(四)\t型態\n有性世代形成子囊殼，子囊殼藍黑色，球形或卵形，外表粗糙著生於寄主表面，大小為214.0-348.0 ×156.0-312.0µm。子囊著生於子囊殼內之子實層，子囊透明圓筒型，大小為60.0-120.0 ×7.5-13.5µm，子囊中8個子囊孢子，成單列或雙列並排。子囊孢子透明，單隔膜，偶有2-3隔膜者，大小為12.0-24.0 ×6.0-12.0µm。\n無性世代主要有大小兩種分生孢子，病株上以小型分生孢子為主。大型分生孢子無色細長，兩端狹窄呈鐮刀形，頂端細胞略呈彎曲，基部細胞明顯，大多為4~6個細胞，極少數為1~3或7~8個細胞。田間病株上大型分生孢子不多，人工培養之大型分生孢子，菌株間差異甚大，張氏報告，同一子囊內單孢分離所得之菌株，一菌株之大孢子大小平均為54.9 ×6.7µm，另一菌株則為76.7 ×6.3µm。小型分生孢子一端狹窄一端平圓、紡綞形、卵形、或保齡球形、無色、一孢偶有二孢，病株上之孢子大小為6-20 ×3-4.5µm，培養基上為9.0-15.0×4.5-7.5µm。小型分生孢子呈念珠狀著生於分生孢子梗，鏈生現象為F. moniliforme之主要特徵，亦為分類根據之一，亦可呈假頭狀累積，即小孢子由孢子梗連續產生，初生孢子將先產生之孢子擠到一側，許多小孢子形成水珠球狀。本菌之野生型菌株在馬鈴薯煎汁瓊酯培養基上，光照適溫培養時，菌絲棉狀、白色至淡粉紅色，會產生淡橙黃色偶爾間雜紫色之色素於培養基中，菌絲上散生橙色之分生孢子堆（Sporodochia）。本菌無厚膜孢子，但老化菌株常有細胞壁加厚之大孢子或菌絲細胞以及藍黑色菌核，以抵抗不良環境。 \n(五)\t診斷技術\n病株比健株高為本病特徵。葉片黃綠色、著生角加大，稻節增生大量鬚根，稻分蘗後期病株開始枯萎死亡，並產生白粉紅色之菌絲層。稻品種混雜造成植株高矮不一，或生理遺傳引起之徒長，葉片呈銳角著生，也不會提早枯死。\n\n(六)\t生活史\n本病原菌在自然界中，有性與無性世代會同時存在，以無性世代之菌絲及孢子就可連續繁殖，不一定要經過有性世代。田間高濕環境下，病菌比較容易形成子囊殼，而產生有性世代。本菌有性世代為異絲生殖，必須兩個親和性菌株同時存在，方能形成子囊殼。高濕環境下，病株上之子囊孢子成熟後可自子囊殼陸續噴出。但濕度太低時，子囊孢子即不能射出而自子囊殼之孔口泌出（Ooze）。\n\n四.\t發生生態\n稻苗徒長病之最適發病溫度，各學者專家所報導結果並不一致，瀨戶氏報告為土壤溫度35℃最適發病；高橋氏報告土溫30 ℃最適發病；西門氏報告 31 ℃最適發病；但義大利及錫蘭兩地之報告則稱低溫徒長病多而高溫35℃時發病少。臺灣以往第一期稻作苗徒長病的發生機率比第二期稻作為高，顯示低溫似乎比較適合徒長病之發生。綜觀各方面報告及田間發病情形，可推論凡是適合水稻生長之溫度即適合徒長病發生。 大氣中相對濕度對徒長病之影響不大，土壤濕度影響則很大，湛水狀況下不適合鐮孢病菌之生長，徒長病發生較少，土壤維持一般旱作田含水量或略乾狀況下，較適合徒長病發生。育苗時適合徒長病菌生長之期間長短，對徒長病發生百分率影響最大，水稻秧田育苗之初期大部分時間為湛水狀態，後期土壤較乾，因此老秧苗徒長病率甚高。箱育秧苗因播種量多土壤淺又非湛水狀態，因此徒長病比較多，但因箱育秧苗期間短，有時病株不易顯現。\n稻種帶菌是徒長病的主要傳播途徑，土壤傳播之機率比較小。早期人們認為水稻開花時被徒長病菌之分生孢子感染，乳熟後成為病穀，為下期稻作徒長病最主要之初次感染源。筆者及日本學者研究，均發現水稻開花時被病菌感染的機率很小。\n稻種傳播徒長病的方式，可分為徒長病株上的秕粒及健穀被污染二種方式。病株上的秕粒內外含大量之病菌，浸種催芽時病秕長出菌絲及孢子感染鄰接之稻種；健穀只有稻殼會受污染，除收穫時會被染外，本田期也是關鍵時期。本田期稻穀受子囊孢子或分生孢子污染的田間環境不同，稻田常維持灌水狀態，稻株基部濕度高，病株基部容易腐敗而快速枯死，病菌在高濕下容易形成有性世代，病菌利用子囊孢子污染稻穀。在比較乾之環境，稻田徒長病株枯死速率較慢，病菌雖然不容易形成有性世代，但是病株高度超過健株，健株抽穗時，病株上的分生孢子很容易污染健穀。\n有關被污染的榖粒播種後發病率之研究，根據張氏報告，每顆穀粒平均帶有4.2個菌體之稻榖，播種後可得8.25％之徒長苗，證明污染於稻殼外之病菌亦可致病。宇氏報告，土壤接種徒長病菌之分生孢子，當每公克土壤含645個菌體時，即可引起稻苗徒長病。張氏報告，稻田中 F.moniliforme之分布不均，稻徒長病株附近的土壤含較高濃度的病菌，病組織中之病菌被埋入土中可為感染源，但因病菌族群密度不高，所以稻苗徒長病雖可經由土壤傳播，但機會比稻種傳播為小。\n五.\t防治方法\n子囊孢子成熟後可自子囊殼陸續噴出。但濕度太低時，子囊孢子即不能射出而自子囊殼之孔口泌出（Ooze）。\n"}, "1679973019.4692245": {"單位": "", "標題": "水稻徒長病 (Bakanae disease of rice; Elongation disease of rice plant)", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌：Gibberella fujikuroi (Sawada) Ito (有性世代)\nFusarium moniliforme J. Sheld (無性世代)\n\n病原生態：\n本病菌在自然界中，有性與無性世代會同時存在，以無性世代之菌絲及孢子就可連續繁殖，不一定要經過有性世代。田間高濕環境下，病菌比較容易形成子囊殼，而產生有性世代。本菌有性世代為異絲生殖，必須兩個親和性菌株同時存在，方能形成子囊殼。高濕環境下，病株上之子囊孢子成熟後可自子囊殼陸續噴出。但溫度太低時，子囊孢子即不能射出而自子囊殼之孔口泌出(Ooze)。\n\n病徵：\n秧苗期徒長病，罹病苗常比建康苗高出1/3～1/2以上，病苗纖細黃綠色，葉幅變小，葉片與葉鞘之著生角加大。徒長病苗在移植後大部分枯死，移植後未死之病株病徵常會消失，至分蘗期又陸續再表現病徵。\n水稻分蘗盛期，除秧苗期被害之病苗再顯現病徵外，亦有新病株陸續出現病徵，插秧時原有病株再顯現病徵者一般無分蘗，新病株則常有少數分蘗。本田期徒長病之病徵與秧苗期之病徵相似，病株纖細黃綠色，葉幅狹小，葉片著生角加大，病株比健株高，當陽光照射及微風吹動時，極易識別徒長病株。徒長病株之莖節處生有不定根，稻桿維管束褐變，病菌在葉鞘內側及莖節上產生菌絲及小型分生孢子。當病株的維管束褐變蔓延到整株時，基部開始腐爛，故又名腳腐病(Foot rot)。隨之全株萎凋枯死，並產生白粉紅色的菌絲層，菌絲層上密生分生孢子，偶爾可見橙色之分生孢子堆，菌絲層最後轉變為淡灰色。當稻株間之溼度大時，常可見淡灰色的菌絲層上散生有藍黑色的小點，此即病菌之子囊殼，子囊殼單生或叢生。徒長病株大部分在水稻開花前死亡，無法抽穗；後期感染病株至抽穗期無論有無明顯病徵常能抽穗，但抽穗後病株相繼死亡，稻穗上皆為空粒或有少數穀粒但皆不飽滿。\n\n傳播途徑：\n稻種帶菌是徒長病的主要傳播途徑，土壤傳播之機率比較小。早期人們認為水稻開花時被徒長病菌之分生孢子感染，乳熟後成為病穀，為下期稻作徒長病最主要之初次感染源。\n稻種傳播徒長病的方式，可分為徒長病菌上的秕粒及健穀被污染兩種方式。病株上的秕粒內外含大量之病菌，浸種催芽時病秕長出菌絲及孢子感染鄰接之稻種；健穀只有稻穀會受污染，除收穫時會被污染外，本田期也是關鍵時期。本田期稻榖受子囊孢子或分生孢子污染的田間環境不同，稻田常維持灌水狀態，稻株基部容易腐敗而快速枯死，病菌在高濕下容易形成有性世代，病菌利用子囊孢子污染稻穀。在比較乾之環境，稻田徒長病株枯死速率較慢，病菌雖然不容易形成有性世代，但是病株高度超過健株，健株抽穗時，病株上的分生孢子很容易污染健穀。\n\n防治方法：\n拔除病株：秧田發現罹病秧苗，須隨時拔除，不可移植於本田。本田發現病株，亦隨時拔除，減少傳染病原。\n"}, "1679974329.4322278": {"單位": "", "標題": "水稻徒長病之發生及因應對策", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻徒長病由病原真菌 (Gibberella fujikuroi，無性世代為鐮胞菌 Fusarium moniliforme)所引起，近幾年來在臺灣各地水稻產區為害時有所聞，98 年第一期作在臺東、花蓮地區普遍發生，本場調查本田罹病率，水稻品種高雄 139 號及臺稉 2 號於 98 年超過 10%，99 年更高達 5~50%。經本場積極進行防治試驗，改進稻種消毒方法，並針對農民及育苗業者實施教育宣導，提供完整防治策略，100 年度第一期作，罹病率已大多降至1% 以下，大幅改善水稻徒長病在臺東地區發生的情形。未來應持續進行相關預防措施，以免再度發生病害。茲將水稻徒長病發生生態及因應對策介紹如下。\n\n病徵與發生生態\n稻種帶菌是徒長病的主要感染源及傳播途徑，土壤傳播機率較小。在苗期時病徵明顯，病苗通常在插秧前後即死亡。徒長病苗在移植後大部分枯死，未死之病株至分蘗期又再出現病徵。本田期之病徵與秧苗期病徵相似，全株纖細呈淡黃綠色，葉片狹長，葉片與葉鞘之著生角度加大，病菌自根部侵入維管束，經導管向上蔓延，同時分泌激勃素促使稻株徒長，病株比健株高，基部莖節處長出不定根，病株不能結穗或抽穗後空粒及不飽滿穀粒，也容易發生提早死亡之現象。病株枯死後所產生之分生孢子污染榖粒，即為隔年之傳染源。病株倒伏於地上，病原菌落於土中，如兩期稻作相隔時間不長，土中的病原菌仍可感染插秧後的稻苗。育苗土中混拌添加的稻殼，如未先經高溫消毒處理，也有極高的帶菌率。徒長病病原菌在水田中可存活 4 個月，凡適合水稻生長之溫度皆適合徒長病菌滋生，第一期稻作苗徒長病的發生率較第二期稻作為高。\n\n預防發生之因應對策\nㄧ、選用健康稻種：稻種帶菌是本病主要傳播途徑，當稻種帶菌率極高時，藥劑處理的消毒效果也不理想，導致徒長發生嚴重。育苗業者須在無發病的健康稻田採種，以減少稻種帶菌；建議將徒長病的帶菌率納入稻種檢查的項目之一，從原原種、原種、採種至育苗的稻種，均應檢測稻種徒長病菌的帶菌率，層層嚴格把關，確保健康稻種的生產，以減少後續防治的成本及病害損失。\n二、選種罹病率低的品種：依據本場3年來調查本田罹病結果顯示，不同栽培品種間水稻徒長病罹病率差異很大，如高雄139號罹病最嚴重，其次為臺稉2號、臺稉糯5號及花蓮20號等。而臺東30號、臺稉 9 號、臺農 71 號、高雄 145 號及越光等品種，其罹病率較低。\n三、稻種藥劑消毒：稻種消毒是防治徒長病的最重要措施，本場比較現行稻種消毒方法的預防效果，並進一步評估開發有效的稻種消毒藥劑，結果以 25.9%得克利水基乳劑 2,000 倍、25% 撲克拉乳劑 1,000 倍及 20% 披扶座可濕性粉劑 200倍浸種 24 小時後催芽，或 40% 免賴地可濕性粉劑 1000 倍、20% 披扶座可濕性粉劑 1000 倍及 80% 多得淨混合可濕性粉劑800 倍催芽後浸藥 12 小時，對徒長病的抑制效果最佳。\n四、拔除病株：徒長病菌在水田中能存活 4 個月，第一、二期稻作間相隔時間短，土中的病株殘體帶菌，仍可感染插秧後的稻苗，導致本田期徒長病普遍發生，而病株上的病原菌孢子又污染稻種，如此惡性循環，使得徒長病的發生日趨嚴重。如欲有效遏止本病的繼續惡化，不論稻苗期或本田期發現病株，都必須隨時拔除，發病嚴重的稻田則應休耕或輪作綠肥作物至少一期，以減少土壤中之病菌。\n五、非農藥資材應用：\n（一）溫湯浸種：稻種之物理殺菌可先以 54℃溫水浸泡5分鐘，再以56~57℃處理15分鐘，然後立即放入20℃以下之冷水中5分鐘；或以60℃浸泡10分鐘或62℃浸泡6分鐘，可有效除滅病菌。\n（二）植物油：催芽後浸泡肉桂油 1,500 倍與展著劑 3000 倍稀釋混合液 4 小時，可將帶菌率降至 10% 以下。\n（三）微生物農藥：稻種催芽後以枯草桿菌 WG6-14 液劑 30 倍稀釋液浸泡 8 小時；稻苗綠化期以 200 倍稀釋液均勻噴灑於稻苗箱，每隔7天噴施1次，連續3次。\n（四）採用抑病育苗土：以抑病育苗土同時使用1% 蚵殼粉及蓖麻粕兩種添加物具協力效果。\n（五）噴施亞磷酸酸（亞磷酸：氫氧化鉀 =1:1）1,500 倍稀釋液於播種後之育苗土上，預防稻苗徒長病效果穩定。有機水稻栽培農戶可參酌採行以上非農藥預防措施。\n\n結語\n為掌握田間水稻徒長病發生生態演變及快速且妥適的因應，未來應朝向病菌偵測技術之研發、健康稻種生產體系之建構、病菌抗藥性問題之探討、稻種消毒新技術之開發、田間病害發生生態探討、管理策略之擬訂及優良抗病品種選育等各方向努力，期能提供多元面向的預防管理及防治策略，有助於徹底防範水稻徒長病之發生。\n"}, "1680054051.0430586": {"單位": "", "標題": "水稻縞葉枯病 病原菌學名：Rice stripe virus英名：Rice strips", "作者": "", "發布日": 0, "摘要": "", "全文": "一.\t前言\n水稻縞葉枯病於1969年首次在臺灣有發病紀錄。隨後15年均僅見零星發生於中部及屏東水稻栽培區，並未對稻作生產構成威脅，至1984年第一期稻作臺灣發病面積驟增，其發生範圍並迅速擴及全臺。1984、1985、1986及1987年臺灣第一、二期稻累計發病面積分別為7,662、11,590、5,917及4,165公頃。近年來發生程度減輕，但仍為稻作較常見之病毒病害。\n\n二.\t病徵\n水稻於苗期感染縞葉枯病，病徵潛伏期（夏季）約2週。病徵最初出現於心葉，常捲縮不能展開且呈不正常的徒長、下垂或扭轉，並有黃白色長條帶狀斑紋和葉脈平行，此帶狀斑紋之長度常自葉基至葉尖，發病後葉片自葉尖向基部枯萎。分蘗期至孕穗期感染之植株，常於上方葉片出現許多由小黃綠色斑點形成之條紋或黃綠色大形條紋和葉脈平行，或上方心葉均呈黃色狀。被害稻株呈矮化現象，分蘗減少常不能抽穗或穗受到抑制而呈畸型，如偶而抽穗，其穗短小多不稔實。一般分 盛期以前發病之稻株均有提早枯萎死亡之現象。\n\n三.\t病原概述\n(一)\t分類地位\nGeaus : Tenuivirus\n(二)\t分布\n本病在臺灣自1969年被報告以來發生均極輕微，發生地點亦僅局限於中部地區之臺中、彰化縣市及高屏地區之萬巒、麟洛、內埔、竹田、潮州等鄉鎮。1984~1986年間本病突然大流行，發生範圍迅速擴及臺灣各稻作區。1987年以後發生減少，發病範圍又回復到輕微發生時的地區。本病在臺灣發生外分布地區尚包括日本、韓國、中國大陸等。\n(三)\t寄主\n本病毒僅感染多種禾本科作物或雜草。在臺灣除水稻以外，小麥、大麥、燕麥、高粱、玉米、小米及看麥娘等以帶毒斑飛蝨接種均證實可被感染。\n(四)\t型態\n純化水稻縞葉枯病毒樣品經醋酸鈾（urayl acetate）染色在電子顯微鏡下觀察到病毒呈螺旋狀構造（helix structure），幅寬約10 nm，呈不規則彎曲線狀，有時可見分枝，長度100~600 nm不等。\n(五)\t媒介昆蟲與傳播\n斑飛蝨（Laodelphax striatellus）為本病毒之主要媒介昆蟲，在日本Unkanodes sapporonus Mats.及Ribautodelphax albifascia Mats.亦經試驗證實可以傳播病毒。斑飛蝨若蟲及雄蟲均可獲毒傳病，病毒在蟲體內潛伏期為5~26日（多數9~12日）。媒介昆蟲最短獲毒及接種取食時間分別為5及10分鐘。傳毒蟲在具傳病能力之最初二週傳毒能力最強，老齡若蟲傳毒能力明顯減退。病毒可以經卵傳播至子代，若蟲於孵化後第8日開始具有傳毒能力。病毒不能機械傳播，亦不經由種子或其他種類昆蟲媒\n介傳播。\n(六)\t診斷技術\n本病可藉由病徵判別、媒介昆蟲接種或血清學技術如酵素連結免疫分析法（ELISA）均可鑑定帶毒媒介昆蟲或罹病植物，其他血清學方法如Double diffission，Western blot，tissue blot等亦均可供為診斷、偵測之應用。\n四.\t發生生態\n在臺灣中部地區斑飛蝨可於再生稻、小麥或其他禾本科雜草等植物越冬，越冬期間能繁殖2個世代，帶毒越冬蟲可成為翌年第一期稻感病蟲源，病毒亦可藉發病寄主植物越冬而成為翌年第一期稻病毒源。在田間斑飛蝨棲群於六月上旬（第一期稻）及十月（第二期稻）各出現一個高峰期。彰化縣大村鄉第一、二期稻水稻斑飛蝨帶毒蟲率高峰期分別於五月上旬至六月下旬及九月下旬出現，此一結果與同年次調查田間自然感染株於四至六月份出現高峰期極相吻合。根據田間水稻生育情形推測四及五月份田間帶毒蟲多寡直接影響該年度第一期稻之發病程度。此外，根據田間病徵出現時期及病徵潛伏期推測第一期稻有二個主要感染期，第一次感染發生在秧苗期及本田初期（插秧後20日），罹病率佔全期作總罹病率之1~19％，以越冬媒介昆蟲為主要傳病蟲源。第二次感染發生在插秧後40~60日間，主要感染蟲源為越冬蟲遷入本田後所繁殖之第一世代成蟲或第二代若蟲，其感染率佔全期作總罹病率之80％以上。第二期稻發病均較輕微。在高屏地區斑飛蝨族群於四月下旬（第一期稻）及十月上旬（第二期稻）分別出現高峰期。第一、二期稻斑飛蝨帶毒蟲之高峰期則分別於五月上旬及八月下旬出現。\n五.\t防治方法\n(1)\t藥劑防媒介昆蟲\n發病嚴重地區於水稻育苗期噴灑殺蟲劑能有效減少苗期及本田初期之媒介昆蟲感染。另外中部地區水稻縞葉枯病以第一期稻發生較為嚴重，根據田間水稻縞葉枯病主要發病時期及不同稻齡水稻感染發病所需潛伏期，推算水稻係於插秧後40~50日間，第一世代斑飛蝨若蟲至成蟲期為其主要感染時期，因此建議罹病地區於此期間實施大面積噴佈殺蟲劑防治斑飛蝨，能有效減少縞葉枯病的發生。此項推論經1990年高雄區農業改良場在該轄區內三個地點以空中施藥方法，於插秧後40日左右噴佈殺蟲劑證實對縞葉枯病有良好防除效果。\n(2)\t抗病品種之利用\n一般秈稻均較粳稻耐病。高雄區農業改良場曾檢定700餘品種（系）對水稻縞葉枯病之抵抗性，發現臺粳育1420等11個抗病性較強品系。\n(3)\t調整種植時期\n插秧期早晚對縞葉枯病罹病度有明顯的影響。臺中區農業改良場於1986年第一期稻稻在該場農場（臺中市舊址）試驗發現早植稻、中植稻及晚植稻之罹病率分別為4.2％、3.4％及1.2％。因此發病嚴重地區延遲第一期稻之插秧期確能有效減少病害的發生。\n\n"}, "1680055232.4835036": {"單位": "", "標題": "油茶根腐病(White root rot)", "作者": "", "發布日": 0, "摘要": "", "全文": "油茶根腐病主要發生於 4~5 月和 9~10 月份為發病高峰期，病原菌適宜生長 於 pH 4 左右的土中，特別是對黏質土壤、排水不良的苗圃。根腐病主要危害油茶一年生苗木，病菌在苗木根周圍形成大量白色的絲狀膜層，因此又稱為白紋羽病、白絹病或霉根病。"}, "1680056039.2404528": {"單位": "", "標題": "植物保護圖鑑系列8-水稻黃萎病", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌學名：Phytoplasma\n英名：Rice yellow dwarf\n簡稱： RYD\n\n一、前言\n臺灣水稻黃萎病於1925年由日人黑澤氏發現，光復以前本病僅局部分布於宜北、新竹地區。1961年前後臺中、彰化兩縣主要稻作栽培區均有發生，1966年桃園縣第二期稻發生面積約28,000 餘公頃，其中嚴重受害面積3,000公頃，產量損失達 90 ％。以後發生範圍逐漸擴及全臺，1966~1972年間年累計發生面積均超過20,000公頃，此為本病發生之高峰期，1983年以後發生面積劇減，全臺每年發生面積均未超過2,000公頃。1993年以後本病之發生更趨輕微，甚至在第一期稻收割後之再生稻都難得再見到病株，未再對稻作生產構成任何威脅。\n\n二、病癥\n水稻感染黃萎病之主要徵狀為植株矮化、分 增多、植株生長勢衰弱、葉片呈淡黃色。病徵的表現主要受感染或發病於水稻生育時期之影響。第二期稻秧苗期感染之稻株於分 盛期前後表現典型之病徵，罹病株極度矮化，平均株高僅健全株之1/4~1/3，分 數比健全者增加2~3倍。罹病葉呈淡黃綠色，細長狀，柔弱；罹病莖多不抽穗，少數抽穗，穗型亦很小且多不稔實，此類病株往往見於生育後期發病後逐漸枯死。第一期稻秧苗期或第二期稻分 初期感病之水稻，於孕穗後期或抽穗初期出現病徵，病徵於較晚抽出之分 上方幼葉顯現，發病之稻莖亦略矮化，新葉淡黃綠色，罹病之稻莖亦能抽穗，但多為畸型穗、穗長較短、稔實率差。罹病株未出現病徵之部分稻莖，稍後在稻基部或莖節上產生小型黃化分 。第一期稻分 期或第二期稻分 盛期及孕穗初期感染之水稻，於抽穗後期至齊穗期間出現病徵，其病徵特性是自稻莖之下方莖節側方長出許多黃化分 ，主莖可以正常抽穗但稔實率較差，黃化分 亦能抽穗但穗型很小，均不稔實，往往一主莖可發現5~6穗，此種現象多發生於第一期稻作。第一期稻孕穗期及第二期稻抽穗期感染黃萎病之稻株，於水稻成熟期自稻基部莖節側方長出許多小黃化分 ，部分罹病稻於水稻收割前未顯現任何徵狀，但收割後則自再生稻表現黃化病徵。\n\n三、病原概述\n（一）名稱\n菌質體 phytoplasma。\n\n（二）分布\n在日據時代黃萎病主要分布於宜蘭、臺北、新竹地區。1961年左右中部地區包括臺中、彰化等縣市發生相當嚴重，1967年雲林、花蓮及1968年嘉義、臺南、臺東均有發生之報告，到1969、1970年高雄、屏東亦有發生，自此本病分布遍及臺灣各地稻作栽培區，1983年以後發生面積劇減。本病在國外分布地區包括日本、中國大陸（海南島）、菲律賓、泰國、馬來西亞、印度及鍚蘭等，但在熱帶國家發病程度輕微。\n\n（三）寄主\n在田間，水稻為黃萎病原之主要自然寄主植物。室內以吸食病株後之黑尾葉蟬（Nephotettix cincticeps）接種，證實千金子、白茅、李氏禾、棒頭草、矮穎馬唐、兩耳草、佛歐里指草、看麥娘等 8 種禾本科雜草亦可感染黃萎病。此外，黑尾葉蟬亦為黃萎病原之寄主。\n\n（四）形態\n黃萎病的病原最早係由日人奈須氏等以電子顯微鏡於罹病水稻韌皮部篩管細胞內及取食發病水稻後30日之黑尾葉蟬的中腸與唾腺檢出形狀與大小不一直徑約500nm類似Mycoplasma之形體。在臺灣，陳、劉二氏超薄切片罹染黃萎病之水稻組織，於電子顯微鏡下觀察罹病水稻葉片之韌皮部及篩管內含有120~1200nm（直徑或長度）之多態型擬菌質，在傳病之黑尾葉蟬的中腸、唾腺、脂肪體、馬氏管及懷菌細胞堆（mycetome）等均可觀察到多形性擬 菌 質 體 （Mycoplasm-like organism, MLO），大小約40~1200 nm（直徑或長度）。\n\n（五）媒介昆蟲與傳播\n黃萎病藉由三種黑尾葉蟬（偽黑尾葉蟬Nephotettix cincticeps，黑條黑尾葉蟬 N. nigropictus，臺灣黑尾葉蟬N. virescens）媒介傳播。邱氏於1966年提出N. cincticeps及 N. apicalis（＝N. nigropictus）傳播黃萎病的報告指出健康的黑尾葉蟬於病稻飼育 3日，再歷4~5星期之潛伏期即能傳病。供試偽黑尾葉蟬之傳病率為32.1％；黑條黑尾葉蟬之傳病率為25~30.5％。另外陳氏比較三種黑尾葉蟬之傳病能力指出偽黑尾葉蟬傳病率為 70.8％、黑條黑尾葉蟬為51.9％及臺灣黑尾葉蟬為 77.4％。偽黑尾葉蟬最短獲取病原及接種時間分別為10及3分鐘，病原不能經卵傳播。溫度對黑尾葉蟬傳播黃萎病有顯著之影響，陳氏指出偽黑尾葉蟬在10~20˚C取食病株之傳病率為7~49％；25~30˚C 時傳病率為60~61％。溫度對病原在媒介昆蟲體內之潛伏期亦有明顯之影響，當媒介昆蟲在15˚C取食病株後歷102日未見表現傳病能力；17˚C 時，在21隻供試蟲中有1隻經68日開始表現傳病能力；20˚C時潛伏期在 45 日以上， 25˚C 時潛伏期為22~37日；30˚C時潛伏期為18~27日。黑尾葉蟬成蟲及若蟲對黃萎病罹病稻株具有棲息偏好性。此外，具有傳病能力之黑尾葉蟬成蟲壽命較不傳病之健全成蟲為長，此種現象在田間有助長媒介昆蟲傳播病害。\n\n(六)診斷技術\n本病可以媒介昆蟲接種，藉由病徵加以診斷；也可利用DNA核酸探針及聚合酶\n連鎖反應（PCR）加以偵測。\n\n四、發生生態\n陳氏調查全臺灣46 個水稻栽培地點三種黑尾葉蟬之分布，結果偽黑尾葉蟬佔89.2％；黑條黑尾葉蟬佔10.63％；臺灣黑尾葉蟬佔0.25％。其中以偽黑尾葉蟬分布範圍最廣，所佔比例最高，黑條黑尾葉蟬在臺中以南地區相對增加，臺灣黑尾葉蟬主要分布在臺東濱海地帶，由於臺灣黑尾葉蟬密度極低，因此在田間實際傳播病害時其所扮演角色並不重要。病原在第二期稻作及翌年第一期稻作期間之越冬主要有三種可能方式：1.經由媒介昆蟲越冬。2.經由再生稻 越 冬 。 3 . 經 由 雜 草 越 冬 。 陳 氏 等 於1974~1976年一及二月採集臺中縣東勢、大里等發病地之黑尾葉蟬成蟲2004隻，傳病蟲佔13.4％，其中以1976年2月份傳病蟲率最高為21~28％。根據黑尾葉蟬之生活史及病原在蟲體內所需潛伏期推測，上述傳病蟲係於11月前後黑尾葉蟬若蟲在田間吸食罹患黃萎病稻株而獲得取病原。冬季水稻田殘留黃萎病再生稻亦為病原越冬重要途徑之一。雖然陳氏報告於室內以媒介昆蟲接種方式證明有八種禾本科雜草可以感染黃萎病，但在田間絕少發現雜草出現類似黃萎病之病徵，推測野外雜草成為黃萎病病原中間寄主之可能性較小。在臺灣，黃萎病之發生以第二期稻為主，第一期稻發生相對輕微，產量蒙受損失亦較小。陳氏等於1973~1976年在黃萎病常發生台中縣東勢鎮、大里市地區調查黑尾葉蟬傳播黃萎病之生態指出黑尾葉蟬在田間一年出現二個傳病害率高峰期，第一個高峰期於二月至三月上旬出現，傳播病蟲率為29~64％不等，這些蟲源為第一期稻水稻感染黃萎病主要之來源，但此時適值全年間黑尾葉蟬自然族群密度最低季節，傳病之蟲數相對減少，水稻感染黃萎病之機率相對降低，加以第一期水稻生育初期自然氣溫低，感病之水稻受低溫之影響，病徵往往延至生育後期方始出現，對產量影響甚少。第二個高峰期於七月至八月上旬出現，傳病蟲率為10~36％。此時正值全年間黑尾葉蟬自然族群密度第一個高峰期之後期，田間族群密度尚高，故第二期稻秧苗期及本田初期之水稻感病機率遠較第一期稻大。第二期稻初期高溫，罹病稻株於插秧後50~60日大量出現病徵，嚴重影響水稻產量。\n\ṇ五、防治方法\n（一）藥劑防治媒介昆蟲\n根據田間水稻黃萎病發病時期及水稻感染至發病所需潛伏期，推測第二期稻水稻黃萎病之罹病株主要於秧苗期被感染，因此發病地區於秧苗期使用殺蟲劑或於本田初期大面積實施共同防治或空中施藥防治黑尾葉蟬，即能有效減少病害的發生。\n\n（二）逃避感染期\n簡、朱二氏指出第二期水稻早植稻黃萎病罹病率比晚植稻高。過去水稻均採水秧田方式個別育苗，由於個別農戶秧田面積小且多分散，秧田附近或田埂雜草均為媒介昆蟲主要棲息場所，一旦秧苗出現後媒介昆蟲隨即遷入並傳播病害。目前約有九成五以上水稻秧苗改於育苗中心集體育苗，秧苗集中結果，相對被昆蟲傳播感染病害的機率降低，部分育苗中心育苗時配合殺蟲劑處理，更能有效遏阻病害的傳播。臺灣近 10 年來蟲媒病害發生密度銳減，育苗中心集體育苗的貢獻不可忽視。此外，發病地區延遲第二期稻水稻秧苗期，逃避第四世代黑尾葉蟬的傳播高峰期，亦可能是黃萎病發生減少的另一原因。\n\n（三）抗病、抗蟲品種之利用\n陳、柯氏等於1970~1975年間蒐集國內外水稻3000餘個品種（系），利用幼苗接種方法及田間自然發病檢定方法篩選品種（系）對黃萎病之抵抗性，結果發現Firooz-1等17個抗病性極強之品種（系），抗黃萎病育種工作曾在臺灣農業試驗所進行，後因故中斷。在媒介昆蟲方面，嘉義農試分所於1970~1973年檢定國內外1813個水稻品種對黑尾葉蟬之抵抗性，發現61種屬抗病品種，這些品種多數為原產於錫蘭、印度之稻種。臺灣直接利用抗病品種來減少飛蝨、浮塵子類蟲媒病害的發生，實質上並未獲得具體成效。值得一提的是近 1970-1990 年代，臺灣除有抗褐飛蝨品種育成推廣外，水稻育種由於追求高產目標，曾不斷引進矮性高產水稻種原，其中不乏抗病、抗蟲基因被導入推廣品種中，無形提升臺灣現有推廣水稻品種之抗病、抗蟲素質，可能是造成長期以來臺灣水稻飛蝨、葉蟬類昆蟲以及其媒介之病害發生趨向輕微的另一項原因。\n\n（四）其他方法\n黃萎病發病地區於水稻收穫後應即翻犁稻田，將殘株深埋土中，以免再生稻成為傳染源。此外，於收穫後應即清除田邊雜草，以防止媒介昆蟲黑尾葉蟬之棲息潛伏，亦為減少感染之有效措施。\n"}, "1680056337.6023276": {"單位": "", "標題": "植物保護手冊 水稻篇 十一、稻黃葉病與黃萎病 ", "作者": "", "發布日": 0, "摘要": "", "全文": "稻黃葉病 \n病原：Virus \n英名：Transitory yellowing \n病徵： \n罹病株之葉片黃化，分蘗減少，下方葉片散生銹褐色斑點，靠近葉尖部分捲縮乾枯。 \n傳播途徑：本病病原係由黑尾葉蟬(浮塵子)、偽黑尾葉蟬及原黑尾葉蟬等媒介傳播。 \n\n稻黃萎病 \n病原：Mycoplasma-like organism \n英名：Yellow dwarf \n病徵： \n罹病稻株矮化，分蘗增多，葉片呈淡黃色。在分蘗後期被感染之水稻，病徵不明顯，僅表現於少數分蘗莖上，且該分蘗莖比正常者為短。病株往往不能抽穗，即使能抽穗，稔實亦欠佳。生育後期感染之稻株，到收穫期雖無明顯病徵出現，但收割後之再生稻有典型之黃化現象。 \n傳播途徑：本病病原(菌質)係由黑尾葉蟬、偽黑尾葉蟬及原黑尾葉蟬等媒介傳播。 \n(一)稻黃葉病與黃萎病防治方法 \n1.發病地區於水稻收穫後，應即翻犁稻田，將殘株深埋土中，以免再生稻成為傳染源。 \n2.水稻收穫後應即清除田邊雜草，以防範傳播病原媒介昆蟲黑尾葉蟬之潛伏。 \n3.第二期作應徹底防除黑尾葉蟬。 \na.秧田期以前：本病發生地區在秧田整地時，必須事先施藥，以徹底防除潛伏於附\n近雜草中之媒介昆蟲(適用藥劑，參照秧田期以前黑尾葉蟬防除法)。 \nb.秧田期：稻葉開始展開時(播種後五天左右)，及插秧前三天，各施藥一次，以防除媒\n介昆蟲。秧田附近之雜草亦必須同時施藥(適用藥劑，參照秧田期黑尾葉蟬防除法)。 \nc.本田期：插秧前本田附近之雜草應施藥一次；插秧後如發現黑尾葉蟬，應再施藥\n防除，直至幼穗形成期為止(適用藥劑，參照本田期黑尾葉蟬防除法)。 \nd.插秧後隨時注意田間情形，發現病株時應即拔除，以減少傳染源。\n"}, "1680058272.9359863": {"單位": "", "標題": "褐根病簡介", "作者": "", "發布日": 0, "摘要": "", "全文": "褐根病是亞洲、歐洲與非洲熱帶及亞熱帶地區林木、多年生果樹及特用作物正要根部病害，尤其近年來更受到重視，已危害多種果樹及樹木植株萎凋死亡。根據林務局林木診斷服務案件中統計每年約30-50%的案件與褐根病有關，可想而知褐根病對果樹及林木的健康有相當之影響。且近年來苗栗地區(大湖、三灣及卓蘭)梨樹陸續發現此病危害，已嚴重影響農民生計。\n褐根病(Brown root rot)稱林木殺手或樹癌，為木本植物真菌性根部病害，病原菌為有害木層孔菌(Phellinus noxius) 或俗稱褐根病菌，引起木本植物的根部及莖基部木材腐朽、樹皮腐敗導致莖基部環狀壞死，因而輸導功能遭受破壞，而引起植株萎凋死亡。文獻記載在東南亞及印度主要為害之經濟木本或多年生植物如橡膠樹、茶樹、油椰子、椰子及相思樹等。\nPhellinus noxius 在自然界威不易發現子實體，但有很特別的病徵，仔細觀察不難診斷。其診斷鑑定法\n(1)\t樹木出現急性或慢性立枯症狀時，觀察樹冠基部與裸露之根系，如有長出深褐色的菌絲包圍其表面，即可斷定為罹患褐根病。若無菌絲體需進行步驟(2)。\n(2)\t挖開土壤，如果樹根上長有褐色菌絲，剝去樹皮後，組織上有網紋狀菌絲束，即可斷定罹患褐根病，若無上述病徵需進行步驟(3)。\n(3)\t將罹病根切(鋸)下一段，對半劈開，密封於塑膠袋內，於室溫(25-30℃)保持高濕1-2天，如為褐根病病根，組織表面會出現褐色菌體，即可斷定罹患褐根病。\n(4)\t進行並組織分離工作\n\n此外，農試所已研發成功利用核酸探針來偵測果樹多種根部病害技術，可直接測定。"}, "1680059784.239706": {"單位": "", "標題": "水稻品種抵抗黃萎病之研究 III.水稻品種抵抗黃萎病之類型", "作者": "", "發布日": 0, "摘要": "", "全文": "一、前 言 \n水稻品種間對黃萎病抵抗性有顯明之差異。於室內及田間檢定水稻品種對黃萎病之抵抗性，約累計檢定三千品種(系)(包括稉稻、秈稻及野生稻)。全部之粳稻及大多數秈稻及野生稻均屬感病性品種，部份秈稻如Firooz-1 Kabara, C4-63A等三十餘品種(系)有相當程度之抗病性，其中Firooz-1經室內2.3次及田間6次檢定從未表現病徵，其抗病性近似免疫。\n由於抗黃萎病品種檢定工作係於不同年次、季節進行，所得資料實難予相互比較分析。本試驗蒐集部份過去已獲得抵抗黃萎病品種(系)，於相同試驗條件下，針對抗病品種間罹病株之病徵潛伏期以及品種抗黃萎病與抗媒介昆蟲(偏好性)之關係做一初步探討，於此僅將所得結果提出報告。 \n\n二、試驗材料與方法 \n1.材料：抗黃萎病品種－Firooz-1, C4-63A, Kabara, Bella pantna, Upland-7, IR1487-194-5-3-2, IR994-102-2-3-2, B581A6-545, 153IR-22(SI) 4bs-6-1, Meher-1宜蘭菊仔A，宜蘭菊仔B及低腳菊仔等。 \n抗黑尾浮塵子品種－H105，MTU 1, Gangla, Muranga 137, 高秈育12號及Te-tep等。 \n感病品種－馬霸粘1號，崎玉糯10號，凍米占，台南5號，台中在來一號及IR 26等。 \n\n2.方法 \n一、水稻品種抗黃萎病與抗媒介昆蟲(偏好性)之關係： \n(一)室內試驗－供試品種15個經室內催芽後播種於育苗箱(40×40×5 cm)上。排列採逢機區集設計，4重覆。小區內每一品種種植一行計10株佔距9公分，行距3公分。小區間距離1公分。苗齡達2~3葉期時，將育苗箱放入大型罩箱內(42×42×50 cm)，箱上方為玻璃，四面為80Mesh尼龍網。罩四面之上方各置一箋10W之植物栽培燈。經室內飼養之帶病媒介昆蟲640隻(每株一蟲)釋放於箱內。於釋放後1、6、12、24及48小時等5次分別記錄各品種上之棲息蟲數。由於涉及黃萎病接種問題，偏好性觀察僅止於接種後48小時。接種後，各品種分別移植到溫室栽盆內，記錄各品種之罹病率並分析媒介昆蟲對品種間之偏好性與品種間黃萎病罹病程度之關係。本試驗於63年3月及8月重覆2次。 \n(二)田間試驗－供試水稻於室內育苗，15天後移植於本田。田間排列採完全逢機區集設計，重覆3次。小區面積4 m×5 m，種植320株，小區之間隔一行，試驗田周圍並設置保護行區1公尺(台南5號)。水稻移植後第70、80、90、100及110天各調查黑尾浮塵子密度一次。調查時以捕蟲網(36公分口徑)掃捕40回，計算媒介昆蟲數。於移植後100天調查黃萎病罹病株率並於水稻收割後20天調查再生稻罹病率。 \n二、品種間病徵潛伏期之差異： \n(一)室內試驗－方法同玻筒接種法於移植後20日起每隔2日記錄一次罹病株(即潛伏期)。本試驗於64年7~11月間重覆3次。 \n(二)田間試驗－育苗箱(40×40×5 cm)縱分二半，每半截播種11品種即每盆22品種，每品種種植2行共35株，品種間行距2公分。3盆代表3次重覆。於二葉期時將育苗箱移置蟲箱(45×45×60 cm)內，每箱釋放帶病媒介昆蟲1000隻，接種48小時。接種後將稻苗移植於本田。田間試驗方法與抗病品種田間檢定者同(6)。移植後40日起每隔5日記錄一次罹病株數(潛伏期)。 \n三、Firooz-1之罹病性測定： \n據檢定資料(6)Firooz-1先後經室內檢定23次及田間檢定6次均未出現病徵。本試驗藉媒介昆蟲接種方法以測定其是否罹病。 \n方法：Firooz-1及台中在來一號於室內育苗，二葉期時以帶毒蟲接種(每苗接種8隻，接種12小時)。於接種後80天(台中在來1號病徵已出現)。每組一株以室內飼養之健全黑尾浮塵子1-2齡若蟲100隻吸食24小時。將供試蟲飼養於健全稻苗上(台南五號)，自40日起自蟲群隨機取樣50隻個別接種到健苗上，迄蟲體死亡為止。測定Firooz-1是否感染黃萎病。試驗時每株供試稻為一組，每品種計五株代表五個重覆，另外並設置三組以吸食健苗代替吸食病株者供為對照。試驗64年6月~10月。 \n\n三、結 果 \n一、水稻品種抗黃萎病與抗黑尾浮塵子(偏好性)之關係： \n黑尾浮塵子(Nephotettix cincticeps Uhler)成蟲對供試品種間之偏好性有顯著的差異。在室內條件下，苗期測定黑尾浮塵子對抗黃萎病品種(以下簡稱抗病品種)之偏好性。結果若與抗蟲品種H105 、MTUI 及感蟲品種台中在來一號比較，黑尾浮塵子對抗病品種Firooz-1、C4-63A、Kabara、Bella pantna具有非偏好性。宜蘭菊仔A、低腳菊仔、Upland-7及Gangala則屬於中度至感受性品種。抗黑尾浮塵子之品種MTUI，於強白接種的情況下，罹病率較輕為7.5~10% ；H105 則表現極感病，罹病率為37~69% ，抗蟲程度中等之Te-tep 、Muranga137、高秈12號則屬於極感病品種，室內試驗水稻品種抗黃萎病與抗媒介昆蟲(偏好性)\n間並無顯著之相關性(r=0.3787)。 田間水稻株期，黑尾浮塵子對Firooz-1具非偏好棲息性。媒介昆蟲對宜蘭菊仔A, C4-63A, Muranga 137之棲息偏好性與台南五號差異不顯著，但與台中在來一號則差異呈極顯著。抗蟲品種H105，MTUI在田間未感染黃萎病，Te-tep罹病率達33.6%。在田間自然環境下，水稻品種抗黃萎病與抗媒介昆蟲(偏好性)間並無顯著之相關性(r=0.2161)。 \n二、品種間病徵潛伏期之差異： \n多數抗病品種，罹病率低，發病株潛伏期極長。15個抗黃萎病品種經室內人工接種後，於水稻生育期平均罹病株率為2.4%而4個對照品種平均罹病率為50.14%。水稻收割後再生稻供試抗病品種平均罹病率為4.7%，其餘為無徵者(Symptomless)；對照品種平均罹病率為53.82%。水稻生育期抗病品種中Belle-Patna (中抗品種)罹病率最高為12%，Firooz-1，Kabara，C4-63A，Upland-7，宜蘭菊仔A等五品種則始終未有病徵出現。供試抗病品種中少數罹病株之病徵均於生育後期仍至再生稻始予出現。供試品種中，馬霸粘一號於生育期出現病徵僅7.4%，但再生稻為36.7%。由於罹病株很少，且網室內密植情況下，無法做產量比較。田間試驗同樣於苗期接種，所得結果與室內者相似，也因為罹病株很少，未行產量調查，但就64年第二期作觀察結果供試抗病品種罹病株平均潛伏期約在80天以上。即病徵出現適值抽穗期以後，病徵於罹病株中之部份分蘗之歛葉出現。部份罹病株病徵發現於齊穗期以後始自根際部長出黃化葉。此類潛伏期極長之品種，即使發病，對產量之影響也很少，田間試驗時發現Kabara，C4-63A，宜蘭菊仔A等品種至黃熟期均不出現病徵。遂採取上方老化葉片供媒介昆蟲吸食後再行接種到水稻上。結果顯示可以傳病，但傳病蟲率比吸食發病之台中在來一號者低，證明此類未出現病徵之植株實質上亦感染黃萎病。 \n三、Firooz-1對黃萎病之感染性測定 \n過去黃萎病抗病品種檢定發現Firooz-1最為抗病，從未有病徵出現者(6)。本實驗使用Firooz-1與台中在來一號比較即供試稻二葉期經人工接種後80天(TN1已出現病徵)以黑尾浮塵子若蟲吸食供試品種，經潛伏期，再予引接到水稻上發現取食Firooz-1五組蟲群中，四組可以傳病，平均傳病蟲率為3.6%；對照台中在來一號五組蟲群均可傳病，傳病蟲率為66.5% 。結果證明Firooz-1雖未表現病徵但仍然可以感染黃萎病，故其抵抗性絕非免疫所引起。 \n\n四、結 論 \n部份水稻品種抵抗黃萎病之現象相當明顯。品種抵抗昆蟲傳播之毒素病(或類似病害)時，其主要原因不外於(一)該品種對媒介昆蟲與(二)該品種對毒素(病原)，所產生之各種影響致該品種不得病。根據結果，水稻品種抵抗黃萎病之現象，可能與品種之抵抗媒介昆蟲及耐病性有關。 \n抗病品種Firooz-1，C4-63A，Kabara，Bell pantna亦兼具有某程度之媒介昆蟲非偏好之抗蟲作用。upland-7宜蘭菊仔A，低腳菊仔(中度抗病)則屬於中度感蟲性品種。抗媒介昆蟲品種MTUI，H105經人工接種後，平均罹病率各為8及52%。在田間抗蟲品種MTUI及H105均顯示抵抗黃萎病。引起此種現象之原因，可能是在田間媒介昆蟲對品種間有偏好性的差異。抗蟲品種由於媒介昆蟲之非偏好性而引起逃避感染而產生「田間抵抗性」。此類品種在實際栽培上亦有應用的價值但這種現象並非發生於全部之抗蟲品種上，如Te-tep為中度抗蟲品種，不論室內或田間對黃萎病之反應均屬於極感病品種。林指出IR8經測定係Tungro病之感病性品種，但在泰國田間測定結果為抗病品種，其原因係IR 8抵抗Nephotettix impicticeps。林報告謂在田間水稻品種抵抗Tungro病，可能由於媒介昆蟲對品種之非偏好性所引起。此種現象使媒介昆蟲不喜好移向非偏好性品種。Thomas在研究蕃茄捲葉毒素病時發現抗病品種C5，CVF4媒介昆蟲對之具有非偏好性，抗蟲現象可能是抗病之重要因素，但部份抗病品種顯然與媒介昆蟲之非偏好性無關或少有關係並結論謂抗病性不能歸因於媒介昆蟲之偏好性。林亦下結論，謂水稻品種抗Tungro病與抗N. impicticeps並不絕對關係並將抗蟲與抗病之關係歸納成四種狀況：(一)既抗病又抗蟲品種(二)不抗病但抗蟲品種(三)既不抗病又不抗蟲品種(四)抗病不抗蟲品種。 \nCrill et al在蓿苜品種抵抗及容忍蓿苜嵌紋病(Alfalfa Mosaic Virus)報告中，給耐病\n(Tolerance)的定義是植株感染病原後，其產量仍然正常或幾近正常者”。本試驗根據過去抗黃萎病檢定結果共採用十五個抗病性中等以上品種(系)為試驗材料。試驗結果除顯示供試品種間罹病率很低外，少數罹病株之病徵潛伏期間很長，均於齊穗期或收割後再生稻始予出現病徵，第一期作由於低溫影響，潛伏期較長且傳病蟲率較低。由於罹病株很少，未行產量調查，但就實際觀察及據陳、柯二氏報告證明水稻齊穗期以後出現病徵之植株對產量顯然少有影響或無影響，此種因潛伏期極長而不影響水稻產量之現象可能為品種抵抗黃萎病之重要原因，供試品種中馬霸粘1號，凍米占等品種雖不抗病，但多數病徵於水稻收割後始予出現，這些品種亦屬於耐病型。同一試驗中之Kabara，C4-63A，宜蘭菊仔A於水稻黃熟期採集不呈現病徵之老化且呈黃褐色葉片，經媒介昆蟲取食後可以傳病，但傳病蟲數較對照台中在來一號病株要低得多，此種現象是否顯示這些抗病株本身含有某些化學成份而是予阻止或抑制病原之繁殖則有待進一步證明。 \nFirooz-1在陳、柯二氏過去許多次抗黃萎病檢定中，均未出現病徵其抗病性幾近於免疫。經高密度種後80天，以健全媒介昆蟲若蟲由接種株收回傳至水稻上，傳病蟲率僅3.6%，證明Firooz-1確能感染黃萎病，引起此種現象之原因尚未明瞭，Ling 於研究抗Tungro病Pankhari 203品種時，認為其抗病原因與媒介昆蟲之取食行為植物組織等無關，並推論其抗病性品種(罹病率很低)是由於毒素於植體內不活化或由於植體內含有某些物質可以抑制毒素之繁殖所致。 \n\n五、摘 要 \n測定水稻黑尾浮塵子(Nephotettix cincticeps Uhler)(以下簡稱媒介昆蟲)對15個黃萎病抵抗性品種(簡稱抗病品種)及5個抵抗媒介昆蟲品種對黃萎病之反應，結果1)媒介昆蟲對抗病品種Firooz-1，Kabara，C4-63A等具非偏好性；但對宜蘭菊仔A，低腳菊仔則具偏好性2)抗媒介昆蟲品種Te-tep，高秈育12號對黃萎病顯示感受性。H105及MTUI在室內表現輕及中度感病性，在田間自然環境下則呈抗病性。品種抵抗黃萎病與抵抗黑尾浮塵子間並無顯著之相關性。溫室人工接種15個抗病性品種，結果水稻生育期罹病範圍在0~12% (2.4)，水稻收割後再生稻罹病率為0~15% (5.4)5個感受性品種於水稻生育期之罹病範圍為32~60% (50.1)，再生稻為33.3~63.3% (59.8)。1975年第二期作田間試驗抗病性品種中之少數於水稻生育期出現之罹病株平均潛伏期為83天，病徵於抽穗期以後至成熟期間出現，多數之罹病株病徵則於再生稻上始予出現，此類罹病現象對產量少有影響。兩個罹病率高之品種馬霸粘1號及凍米占之情形亦極類似。其餘供試感病性品種，台中在來1號，台南5號，IR 26等之病徵潛伏期為47~65天(53)。 在我們過去抗病性品種檢定中發現Firooz-1均未表現病徵，健全媒介昆蟲若蟲取食接種後80天之Firooz-1及台中在來一號(已出現病徵)植株，結果取食Firooz-1之蟲群傳病率極低。\n"}, "1680060280.579376": {"單位": "", "標題": "褐根病菌介紹及防治", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌\n褐根病菌 (有害木層孔菌) (Phellinus noxius (Corner) Cunningham) 的分類地位為擔子菌門 (Basidiomycota)，層菌綱 (Hymenomycetes)，無褶菌目(Aphyllophorales)，刺革菌科 (Hymenochaetaceae)，木層孔菌屬 (Phellinus)。在早期文獻記錄中發現，本病原菌曾有下列同物異名：Hymenochaete noxiaBerk. ex Cke., Poria setulosocrocea Clel. et Rodw., Poria cacao Pat., Fomescacao Pat., Fomes lamaoensis (Murr.) Sacc. et Trott 和 Fomes noxius Corner 等。直到 1965 年本病原菌才正式使用目前的學名。刺革菌科的主要特徵為子實體褐色且滴上 3-5% KOH 將變成黑色，菌絲不具扣子體，具或不具剛毛，不具小囊狀體，本科共有10個菌屬。木層孔菌屬是刺革菌科最大的菌屬，木層孔菌內的菌種全部均為木材白色腐朽菌，多數營腐生或具有弱病原性，少數菌種具有較強的病原性，尤其以 P. noxius 的病原性最強。Phellinus noxius 在自然界感染的植物鮮少形成完整的子實體，在 96 種寄主中，僅在 9 種寄主植物發現子實體，分別是木麻黃、樟樹、榕樹、印度橡皮樹、山刈葉、龍眼、荔枝、番荔枝、鳳凰木。在鋸木屑太空包培養可形成子實體。在植物上的子實體從平伏至反轉，但在木屑培養基上則為平伏。雖在植物上及木屑培養基形成之子實體外觀上有些差異，但其微細構造則相似。於子實體表面滴上 3-5% KOH 永久變成黑色。菌孔表面灰褐色至淡褐色。菌絲為二次元系統，含有不具扣子體的生長菌絲 (generative hyphae) 及骨骼菌絲 (skeletal hyphae)，生長菌絲直徑為2-4 μm, 無色至黃色，骨骼菌絲黃褐色至深褐色，直徑為 3-6 μm。菌體基質剛毛菌絲深黑褐色，直徑達 13 μm，長達 450 μm。擔孢子平滑無色，寬卵形至次球形，大小 3-4×4-6 μm。\nPhellinus noxius 很容易分離培養，其在 PDA (potato dextrose agar) 和MEA (malt-extract agar) 培養基生長良好。依據Stalpers的方法研究其純培養特徵為：在 25℃14 天菌絲生長直徑大於 70 mm, 菌落前緣菌絲氣生至平伏，菌落初期白色至草黃色，後變成琥珀褐色至黑褐色，氣生菌絲棉生至被粉粒生，形成段生孢子和毛狀菌絲 (trichocysts)。生長菌絲不具扣子體。P.noxius 產生 laccase 和 peroxidase 之細胞外氧化酵素，但不產生 tyrosinase。依據 Stalpers 設定的代碼，P. noxius 之培養特徵代碼為 1, 3, 5, 12, 13, (14),(18), (19), 21, 22, (25), 28, 30, (31), 34, 35, 38, 46, 48, 52, 53, (54), 61, 67, 84, 89,90。台灣分離之 P. noxius 純培養特徵與 Stalpers 的報導大致符合，唯 Stalpers並未觀察到 P. noxius 的節生孢子。台灣分離到的菌株及自荷蘭菌種中心購買之菌株 (CBS 170.32) 均具有節生孢子。筆者於 1997 年初前往印尼分離之 P.noxius 也具有節生孢子。在木層孔菌屬中，目前僅知 P. noxius 菌可在人工培養基中形成毛狀菌絲和節生孢子，因此可做為純培養時的鑑定依據。在病組織上可發現毛狀菌絲，但在病組織上未發現或鮮見節生孢子。在台灣自 15種寄主分離之菌株，對生長溫度的反應相似；最適生長溫度近 30℃，最高溫達 36℃，最低溫 10-12 ℃，但其生長速度有差異，直線生長介於 3.4 公分/天至 0.8 公分/天。菌絲生長 pH 值介於 3.5 至 7.0，高於 7.5 則不能生長。\n\n病徵與寄主範圍\nPhellinus noxius 在自然界雖不易發現子實體，但有很特別的病徵，仔細觀察不難診斷。在接近地際部主莖及根部的發病樹木往往有黃色至深褐色的菌絲面 (mycelial mat) 包圍其表面，在根部之菌絲面常與泥沙結合而不明顯，上述病徵是現場鑑定本病害的主要依據。其引起植物地上部全株初期黃化萎凋，最後枯死。從黃化到枯死只需一個月至三個月，屬於快速萎凋病。本病之所以造成快速萎凋的主要原因是 P. noxius 直接為害樹皮的輸導組織，導致水份及養份之輸送遭受阻礙而死亡。本病原菌除為害樹皮外，也可造成木材白色腐朽。受感染之內側木材組織具不規則黃褐網紋。在腐朽木材與健康木材間常有黑褐色帶隔離。腐朽末期木材變輕、乾和海棉狀。\nPhellinus noxius 為害的寄生範圍廣泛，早期澤田氏已記錄 18 種寄主。近年來在台灣中低海發現很多木本植物為 P. noxius 的寄主，目前有 96 種寄主被發現，且陸續在發現新寄主中。其寄主木本植物包括多種珍貴老樹、公園行道樹、海岸防風林和果樹，如樟樹、榕樹、楓香、桉樹類、相思樹、鳳凰木、木麻黃、南洋杉類、桃花心木、龍眼、荔枝等。P. noxius 除為害木本多年生植物外，也發現四種草本一年生植物受其為害，如茵陳蒿、馬鞍藤和山萵苣。在田間與林地的觀察，筆者發現 P. noxius 似乎沒有特定寄主，一旦與病原接觸均可受其為害。筆者報導分離自 12 種寄主之P. noxius，將每一菌株都接種到 12 種寄主，發現每一菌株都可引起 12 種寄主植物發病，但有兩種植物（相思樹和柳樹）具有較低的發病率，此結果顯示P. noxius不具病原生理小種，但不同寄主間存在不同程度之感病性。Ann et al.檢定台灣 101 品種(含 92 種)園藝作物對褐根病菌之抗感病性。結果顯示，極為感病之植物共有 13 種，包括果樹 5 種：枇杷、軟枝番荔枝、可可、百香果、破布子。極感病觀賞植物 8 種：茉莉花、黃槐、黃花夾竹桃、金露花、西洋杜鵑、聖誕紅、櫻花、黃金風鈴木，於接種六個月內全數死亡。抗(耐)病者有蘋果、蓮霧、圓滑番荔枝、扁櫻桃等 7 種：而柑橘(酸橘、柳橙、苦柚)、愛文檬果(砧木為在來種)、及黑板樹則對褐根病極為抗(耐)病，於接種一年內均無發現死亡情形。 \n生理、生態與分佈\n在北美洲西北地區針葉樹最重要病害之一薄層根腐病 ( laminated root rot ) 的病原菌 P. weirii，已知因缺乏分泌硝酸還原酵素 ( nitrate reductase ) 的能力而無法利用硝酸鹽中的氮源。在該地區有一種赤楊 ( Alnus rubraBong. )，因其與共生根瘤菌可以固定空氣的氮，使其森林土壤含有較多的硝酸鹽。此種赤楊林地相當不利 P. weirii 的發病。其原因可能是土壤中高濃度的硝酸鹽存在的效果。因此在發病嚴重地區利用赤楊輪作，應可以降低病害的發生。P. noxius 經測定，同樣具有選擇性氮源同化作用，即 P. noxius 缺乏分泌硝酸還原酵素的能力。吾人或許可以考慮此生理特性加以利用，結合於病害綜合防治策略。如發病地區施用硝酸鹽氮肥或種植豆科一年生植物以增加土壤硝酸鹽濃度，但仍需經由田間試驗以評估其效果。\n在褐根病發病的林地，常發現病害自一發病中心逐漸向四周擴散，此現象顯示褐根病的傳播主要經由根部接觸由病根傳給健根。雖然有報導証明擔孢子可以成功感染植物，但因 P. noxius 在自然界不易形成子實體，因此經由擔孢子做長距離傳播的機會較少。由於本病主要經由殘留在土壤的病根傳播病害，因此殘留土壤病根的生態與病害的發生有息息相關。筆者發現 P.noxius 存在殘根的活性可一直到病根完全腐爛為止。經調查田間三種寄主植物（瓊崖海棠、木麻黃與樟樹）之殘留病根發現，自死亡後一年至十年的病根均可以分離到 P. noxius，死亡年代愈短病原存活的比率愈高，但在死亡十年後的木麻黃病根仍有 50％ 以上的存活率，可見 P. noxius的殘根可以在土壤內做長期的存活，在土壤內存活期間如遇到寄主植物的健根則有機會感染為害。但對病根周圍的土壤利用選擇性培養基進行分離則無法檢測到 P. noxius 的存在，可見本病原在土壤的存活主要以殘根為主。在溫室中，將感染 P. noxius 的木材、節生孢子、擔孢子與菌絲放入不同含水率的土壤中。節生孢子和擔孢子在五個月後於各種含水率的處理中，則無法檢測到 P. noxius 的存在，菌絲則在十二個星期後，於各種含水率的處理中無法檢測到 P. noxius 的存在，然而感染 P. noxius 的木材除浸水的處理外，經過兩年仍有高達 80％ 以上的存活率。但浸水處理之木材一個月則無法檢測到 P. noxius 的存活。上述結果也顯示 P. noxius 以殘根做為主要存活的處所，此結果與田間的試驗相符合，然而在浸水的情況下則可加速 P. noxius 的死亡。此結果或許可以應用在防治的策略上，如果感染林地或果園在環境許可下，可進行一個月以上的浸水，以達到降低或殺死感染源的效果。 \n褐根病是亞洲、非洲與紐澳熱帶地區的病害，美洲及歐洲均未發現報導。以亞洲、非洲與紐澳赤道附近的陸地及島嶼為主，南自南半球紐澳，北至日本琉球群島，太平洋上的島嶼也常有發現。在台灣，每個縣市均有發現，以西部台中以南和東部和平以南較常發現。從發病次數的記錄，發現本病較常發生於海邊沙質土壤，其它地區的黏質土壤偶而發生。此現象可能與土壤含水力有關。P. noxius 在浸水狀態的殘根存活能力較差，在含水較少的狀態殘根存活能力較好。沙質土壤含水力及含水持久性不及黏質土壤，因此較易保持土壤於相對乾燥的狀態，因而有利於 P. noxius 的存活。而黏質土壤處於高濕度的狀態較長久，因而不利於 P. noxius 的存活。經檢測罹患褐根病寄主植物根圈土壤之酸鹼值，結果顯示土壤 pH 值介於 4-9 均可發現褐根病，其中以pH5-8 的比例較多。\n\n病害防治\n本病害的防治方法到目前為止，仍沒有任何正式剎菌劑被推荐於病害防治上。然而在實驗室對病原菌之測定及林地初步試驗之結果顯示，三得芬、三泰芬、護矽得、硫酸銅、快得寧、銅快得寧、撲克拉、滅普寧、4-4 式波爾多液及尿素等劑對本病有某些程度的抑制及治療效果，但因未經完整的試驗結果評估，及合法行政程序登記，仍不適合做為推荐防治藥劑。同時，本病菌主要為害根部，藥劑的施用不易達到預期治療效果，因此施與藥劑之成效，常受樹種與環境影響。事實上，褐根病的防治工作，應以預防為主，因本病原菌為害植物初期地上部沒有任何病徵，一旦地上部出現黃化萎凋時，根部已有 80% 以上受害，在此情況下如欲進行治療處理，為時已晚。本病原菌主要傳染的來源是病殘根，其傳播途徑主要靠病根與健康根的接觸傳染。因此在預防的考慮下，只要可以阻止病根與健康根的接觸，及殺死或除去土壤中的感染病殘根，就可以達到防治效果。以下的防治方法則依據上述的原則。\n1. 掘溝阻斷法：在健康樹與病樹間溝深約 1 公尺，並以強力塑膠布阻隔後回填土壤，以阻止病根與健康根的接觸傳染。\n2. 將受害植株的主根掘起並燒燬，無法完全掘出之受害細根，可施用尿素並最好覆蓋塑膠布 2 星期以上，尿素的用量約為每公頃700-1000 公斤。如該土壤偏酸性可配合施用石灰調整土壤偏中性及鹼性。此方法可以殺死土壤中細根的病原菌，尤其在鹼性土壤更有效。另外可以考慮使用燻蒸劑邁隆每公頃 300-600 公斤拌入土中加水後覆蓋塑膠布 2 星期以上，進行燻蒸。\n3. 發病地區如不便將主根掘起且該地區具有灌溉系統，可進行 1 個月的浸水，以殺死存活於殘根的病原菌。\n4. 發病初期以外樹木外科手術法切除感染部位後以三得芬及銅快得寧稀釋 500 倍淋洗傷口及灌注周邊土壤。\n5. 藥劑防治發病周圍的健康樹或發病初期的林木可用 a. 藥劑混土覆蓋法和 b. 藥劑稀釋灌注法，兩方法任選一種處理：\na. 藥劑混土覆蓋法：將下列藥劑：3 公斤 (升) 的三得芬 (克利生)或三泰芬或新星 (護矽得)，3 公斤 (升) 的銅快得寧或快得寧或撲克拉，15 公斤的尿素和 3 公斤石灰 (如為中、鹼性土壤不用加) 與 1 立方公尺 (公噸) 土壤混合，將混和藥劑的土壤覆蓋在樹幹基及周圍之土表，厚度約 3-5 公分，範圍則依樹冠大小而定盡可能函蓋樹冠，覆土完畢後將土表淋濕，處理後最好再覆蓋塑膠布一個月，如處理地點易浸水，可先將表土刮出 3-5 公分，但不要刮傷樹根。半年後再處理一次。\nb. 藥劑稀釋灌注法：將以下藥劑加水稀釋，500 倍的三得芬或三泰芬或新星，500 倍的銅快得寧或快得寧或撲克拉，100 倍的尿素和 200 倍的石疢 (如為中、鹼性土壤不用加)，將上述稀釋藥劑最好加壓灌注土壤，或淋灌於表土，施用藥量以每平方公尺用20-30 公升的藥劑，施用範圍則依樹冠大小而定，盡可能涵蓋樹冠以下之土壤，處理後最好覆蓋塑膠布一個月，間隔三個月再處理，共處理三次。如處理之林木生長於貧瘠地可適量施用有機肥，以增加樹木抵抗力。\n6. 發病地區於再植前利用燻蒸劑處理病土。\n\n生物防治是當今植物病蟲害防治的趨勢，因為生物防治較沒有化學防治造成的環境問題。但生物防治有很多限制因子，目前田間成功的例子並不多。Kothandaraman et al.發現土壤根圈中的放線菌 (actinomycetes) 可以抑制 P.noxius, 但未有進一步的防治應用試驗。這是目前對 P. noxius 僅有之生物防治報告。"}, "1680060483.40413": {"單位": "", "標題": "茶樹根腐病(White root rot)", "作者": "", "發布日": 0, "摘要": "", "全文": "白紋羽病 (White root rot)\n\n病原菌：Rosellinia necatrix Prillieux（有性世代）\n　　　　Dematophra necatrix Hartig（無性世代）\n\n病原生態：\n　　在台灣白紋羽病多發生在中北部高冷地區，喜冷涼、潮濕的環境，台灣平地茶園極少發生，只在少數高山茶園被發現。其傳播的方式是藉由病根與健根的接觸；田間病害發生的模式是以罹病株為中心，向外作輻射狀的擴散，在無寄主的狀態下，病原菌可附著在有機物上存活很久。\n\n病徵：\n　　本病主要危害茶樹的根部及基部，若發生在茶苗，數周內即死亡。發生在成長多年之成木茶樹，受害植株根表面有白色棉絮狀的菌絲覆蓋在病組織表面，將罹病根表皮剝離，表皮下可發現放射羽毛狀的菌絲，最後可以遍及整個根部，發病多年的老根表面被覆一層灰色的菌絲片，仔細觀察其中有許多粗、細不等的灰黑色菌絲束，被害寄主植物會造成根部腐敗，樹皮很容易脫落，由於根部腐敗導致罹病植株的葉片黃化、褐變、枯萎、繼而落葉，最後全株萎凋死亡。\n\n防治方法：\n\n一、高山茶區新開墾的茶園，應將前作的根系完全清除，避免殘根成為病原。\n二、發病輕微的茶園，可利用掘溝阻斷法防止本病的擴散；並應徹底的清除殘留在地上或土中的殘根。"}, "1680060946.2380629": {"單位": "", "標題": "植物保護圖鑑系列8-水稻胡麻葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "一、前言\n稻胡麻葉枯病為臺灣稻作主要風土病之一。水稻各生育期均可能受稻胡麻葉枯病菌危害，土壤貧瘠或乾旱地區容易發生本病，其它病蟲害引起稻株生育不良後，本病亦常伴隨發生。稻種採收前被本病菌感染或污染，種子萌芽時容易被危害引起苗枯，低溫秧苗生長緩慢時更容易發生。由本病菌引起之枯死苗在育苗箱中零散分布，至今尚未曾嚴重發生過。長出本葉後之秧苗或本田期稻株則以形成葉斑為主，苗期葉斑主要發生於老秧苗，近年來利用箱育秧苗，育苗期間短，秧苗期較少胡麻葉枯病。本病危害本田期稻株之部位以葉片為主，亦可危害葉舌、穗梗及穀粒等部位，但較少危害稻節及葉鞘。本病嚴重發生將造成重大損失，孟加拉曾因本病大發生而造成該國之飢荒。依據前臺灣省政府農林廳報告，臺灣第二期作本病之發生大多比第一期作嚴重。1967年至今，第一期作發生面積超過一萬公頃之年份，有1969、71~76、80、82及84~86等年份，其中1971年發生31,055公頃最廣，而1995年發生面積1,578公頃最少；第二期作大多超過一萬公頃，其中1970 年44,766 公頃最廣，而1973 年發生1,730公頃最少。\n一般地區，本病發生於水稻生育後期，對產量影響不大。但在土壤貧瘠地區，水稻生育不良，易發生本病，本病發生程度不同會造成不同之減產，國外報告，輕度發生時減產不顯著，中度發病會造成12％減產，嚴重時造成30-43％甚至50-90％之減產。本病除造成減產外，亦會降低稻米品質。\n\n二、病癥\n稻種萌芽時受害會引起苗枯病，稻芽初呈黃褐色水浸狀病變，子葉上呈短黑色線狀斑點，嚴重時繼而枯萎死亡，病苗上有墨綠色菌絲及分生孢子，病苗之子葉褐色至深褐色，並向本葉之葉鞘蔓延，葉鞘受害後亦呈褐色病變，組織脆而易折斷，葉片生長受阻不易伸長，致葉片直立黃化，嚴重則與葉鞘一起枯萎死亡。老秧苗葉片病斑與本田期葉片病斑相似，初呈墨綠色水浸狀小斑點，隨後轉為褐色小斑點，再漸次擴大成為紡錘形或橢圓形，一般病斑如胡麻種子之大小，整個病斑呈褐色至深褐色，周圍明顯有黃暈，有些病斑上具有同心輪紋。稻植株缺氮、鉀或矽而顯現感病性時，病斑會繼續擴大，大型病斑沿葉脈呈長橢圓形，兩端較圓寬，黃暈明顯但較窄，常易被誤認為稻熱病斑，但稻熱病之病斑兩端較尖黃暈不明顯，兩者間有頗大差異。稻孕穗期嚴重發生胡麻葉枯病，植株呈現矮化，葉片常無法正常伸展，葉片縐縮，葉片組織略變厚，抽穗緩慢，稻穗短小結實不佳。本病甚少危害稻葉鞘，但會危害葉節及葉舌，即葉片與葉鞘交接處及其葉舌，初呈墨綠水浸狀小斑，而後轉為褐色，並擴大病斑，如發生在孕穗期劍葉之葉舌，嚴重時會造成抽穗不良。本病會感染稻穗，致病力比稻熱病弱。穗頸或枝梗被害後，形成墨綠色轉黑褐色病斑，被害部位以上之稻穗不會立即枯死。穀粒亦常被感染，初呈褐色至黑褐色小斑點，病斑擴大後成為胡麻種子大小之茶褐、暗褐色病斑，嚴重時病斑會擴展至大部份外穎，環境適宜並有孢子柄及分生孢子產生。稻穗被害後，空秕粒增加，其糙米病變為銹米、死米或青米等，對稻米品質影響甚鉅。\n\n三、病原菌概述\n（一）分類地位\nAscomycetes  子囊菌綱\nPleosporales  格孢腔菌目\nPleosporaceae  格孢腔菌科\nCochliobolus  旋孢腔菌屬\n（二）分布\n稻胡麻葉枯病分布全世界，包括亞洲、美洲及非洲所有種植稻的國家，無論是水稻或陸稻，均有發生本病之報告。\n（三）寄主\n許多報告指出Bipolaris oryzae會感染狗牙根、馬唐、粟、李氏禾、茭白及野稻。筆者曾採集稻田附近之禾本科植物的葉片病斑，包括茭白、李氏禾、馬唐、莎草、雙穗雀稗、牛筋草、狗牙根、狼尾草及竹葉等，均可分離到B. oryzae，回接水稻葉片上出現典型的病斑。田間觀察發現，稻胡麻葉枯病田附近之茭白筍、李氏禾及竹葉最常見有病斑，其中茭白筍與水稻二者之胡麻葉枯病會互相傳播，加速病害蔓延。\n（四）形態\n本病原菌有性世代為子囊孢子，自然界尚未發現其存在，目前多以人工培養產生，子囊殼呈球形或扁球形、有嘴口、深黃 褐 色 至 黑 色 、 大 小 560-950 × 368-777µm。子囊無色長圓筒形至長紡綞形，大小142-235 ×21-36µ m，內有8 個子囊孢子。子囊孢子呈絲狀，無色至灰橄欖綠，有6~16個隔膜，大小為250-469 ×6-9µm，呈螺旋狀並互相捲曲。\n田間病斑上會形成無性世代之分生孢子，孢子量不多。分生孢子呈紡錘形、6~11 個隔膜，大多孢子稍彎曲呈新月型、中間略下方處較膨大，頂端半圓形寬度約為孢子中間部位之一半，基部細孢有明顯孢子著生痕跡，大小35-170 ×11-17µm，分生孢子在潮濕環境下，未脫離孢子梗前即會發芽，但發芽管常因無足夠養分及濕度而枯萎。分生孢子梗自氣孔或表皮長出，單生或簇生，稍微彎曲，大小150-600 ×4-8µm，7-15個隔膜，基部暗褐色，往上漸呈淡色。\n（五）診斷技術\n稻胡麻葉枯病之病斑如胡麻種子之大小，整個病斑呈褐色至深褐色，周圍明顯有黃暈，是診斷重點。貧瘠土地之稻植株，會出現極感病之大型病斑，大型病斑沿葉脈呈長橢圓形擴展，常易被誤認為稻熱病斑。本病之大型病斑黃暈雖然比小型\n斑窄，但黃暈仍然明顯，本病之病斑兩端較圓寬、病斑中間維持褐色至深褐色，稻熱病之病斑兩端較尖、病斑中間灰白色或淡褐色、黃暈不明顯，兩者間有頗大差異。\n（六）生活史\n本病之病原菌腐生力強，可以在枯死的病斑組織中繼續生長。如此以菌絲與孢子反覆傳播與繁殖，存活於田間。\n\n四、發生生態\n本病菌之殘存，係靠其菌絲或分生孢子。分生孢子在乾燥環境下可存活3~6 個月，但在高濕度下則存活約1個月而已。不過有報告指出，感染稻種之分生孢子平均可存活兩年。病組織中之菌絲，平均可存活3~4年。本病初次感染源，分別來自帶菌稻種及田間病稻草。\n稻種上帶有本病菌，經浸種催芽及播種後，其初生芽及根可能被感染，除了在育苗箱中高密度秧苗及低溫環境下，會引起秧苗枯萎外，正常狀況下，秧苗會迅速長出葉片，病菌並未感染葉片產生病斑。病菌在稻種穀粒及子葉上增殖，所產生之分生孢子，為感染秧苗後期葉片之第二次感染源。\n本病菌之分生孢子無休眠性，只要濕度夠，雖未脫離分生孢子梗，亦會發芽。脫離分生孢子梗之孢子，一般從基部及頂端細胞長出發芽管，發芽管常覆有黏稠液有助於附著在固體表面，發芽的先端會形成附著器，形成在寄主表面之附著器，會產生侵入釘直接貫穿表皮細胞，發芽管亦可不產生附著器直接經由氣孔侵入組織內。溫度20-28℃之高濕環境下，分生孢子在稻葉表面，經4~8小時即可完成侵入過程。\n肥料養分對本病之影響，與其它病害略有不同，稻株缺乏氮肥易發生本病，足量氮肥可抑制本病發生，恰與稻熱病、紋枯病及白葉枯病等病害相反。鉀肥及矽酸肥之影響，則與其它病害相同，均可增強抗病。砂質土壤、泥炭地土壤或土壤表層淺之稻田，因土壤貧瘠及保肥力差易發生本病。\n其他病蟲害發生後，造成水稻生育不良，亦會併發本病，其中以黃萎病及病毒病害最明顯，除山區環境外，稻熱病與胡麻葉枯病同時發生之情況較少。化學肥料施用過度，未施用有機肥，土壤中有機質減少，本病將漸次增多。酸性土壤易引起有效鐵及錳等缺乏，較容易發生本病。各種土壤因子對水稻產生不良影響，均會併發本病，如植物殘株等有機物在排水不良之土壤中，異常醱酵產生有害物質，造成水稻生育不良，而誘發本病。土壤過於乾早時，或地下水過高排水不良，或利用冷泉水灌溉之田地，均易因稻生理障害而發生本病。\ṇ\n五、防治方法\n本病會經由稻種傳播，稻種消毒可防止稻種傳播，降低感染源。本病屬於風土病，各地區發病情況差異很大。每年發病嚴重之地區，分 後期本病初發生時，要即時施藥防治。有關耕種栽培管理部分，請參考紋枯病之防治方法。\n"}, "1680060968.5226882": {"單位": "", "標題": "白紋羽病(white root rot)", "作者": "", "發布日": 0, "摘要": "", "全文": "(一)\t病徵與發生病徵：本病最早於1923年由Petch報導在茶樹發生，但臺灣一般平地茶園甚少發生，高山茶區開墾後逐漸發生、蔓延。白紋羽病為土壤傳播之根腐性病原菌，寄主範圍相當廣泛，臺灣地區已知有梨、葡萄、枇杷、桃樹、梅樹及蘋果樹等多種果害樹及數種林木受到白紋羽病為害之紀錄；而茶白紋羽病也並非臺灣地區茶樹之新病害，早於民國五十四年之農業要覽中已有茶樹白紋羽病之記載。\n茶白紋羽病於田間之傳播方式主要藉由罹病茶樹根部與健康茶樹根部之接觸而傳染，故田間發病型態常見以發病之茶樹為中心沿著茶行逐漸擴散之現象。罹病植株最初於受感染根系之地上部出現茶芽新梢抽出變少，葉色褪綠、葉片易黃化、提早落葉之現象，以後茶欉逐漸出現枝葉稀疏、樹勢衰弱之慢性萎凋病徵，若此期間遇到環境逆境衝擊，則茶欉迅速出現青枯狀之急性病徵。溼度高時，常可發現罹病組織上覆蓋一層白色羽毛狀菌絲，並蔓延至主根上或附近土壤中，挖開罹病茶樹之根部，常可見根皮有腐爛現象，病情嚴重時茶欉地際部亦可見到白色棉狀菌絲附著，而溼度降低時白色棉狀菌絲常轉變為灰白色；被害根部之表皮與木質部之間變得鬆散且極易剝離，其內常可見本病病原菌之典型白色扇骨狀菌絲存在。\n隨著病勢繼續擴展至根際部時，茶樹因根際部皮層受害，造成環剝效應而導致茶欉全株萎凋枯死，罹病植株枯死一段時間後，地際部份會產生黑色剛毛狀、頭部有白色膨大構造之無性世代構造，可作為茶白紋羽病診斷之依據之一。\n(二)\t病原菌：本病病原菌為褐座堅殼菌，學名為 Rosellinia necatrix Prill，無性世代之菌絲細而無色，寬度為5-8µm，在罹病組織上生長而形成白色菌絲層，後期細胞壁加厚，菌絲變為褐色至深褐色，部份菌絲在隔膜處膨大成洋梨形。厚膜孢子圓形，菌核黑色，大小為1mm，較大者可至5mm。罹病植株之根部於黑暗潮濕情況下，經三週可產生大量之孢子束；孢子束黑色，叢生，有分枝，狀似樹枝，頂端著生分生孢子。分生孢子無色單胞，卵圓形或橢圓形，大小為3.8-5.6×2.8-3.8µm，易脫落。\n(三)\t管理策略及防治方法：\n(1)\t墾植茶園之前，應注意前期作物是否曾罹患白紋羽病，若有，可考慮放棄種植茶樹，或全園經徹底之土壤消毒後再行種植。\n(2)\t徹底清除罹病植株：徹底清除罹病植株，尤以根部需完全清除，並立即加以燒燬，如欲補植，需以燻蒸劑處理罹病株種植處及周圍的土壤後，再行補植。\n(3)\t加強肥培管理：補植前可適量施用有機肥料，發病輕微之病株及其附近之健株，亦可加強肥培管理，以增強植株之生長勢而增加抗病力。\n(4)\t開溝阻隔：可採用挖溝的方法以減少病原菌擴散，即以病株為中心，與鄰近健株間挖溝，溝寬約30公分，溝深約1公尺，切斷根部之接觸。挖溝後可配合施用有機肥、藥劑及隔絕物質舖設而增加阻隔作用。然需徹底清除病株殘根，方可發揮隔絕作用。\n(5)\t藥劑防治：尚無正式推薦藥劑，可參考梨白紋羽病之方法。"}, "1680061123.3651807": {"單位": "", "標題": "花蓮區農業推廣簡訊 5(2):8-9 水稻胡痳葉枯病的發生環境與防治法", "作者": "", "發布日": 0, "摘要": "", "全文": "胡麻葉枯病為本區一種極為普遍的真菌性病害，估計在宜蘭縣及花蓮縣容易罹患稻胡麻葉枯病的面積約四千公頃，此種病害的發生與土壤條件、營養條件及氣候條件有密切的關係，近年來由於本場大力示範推廣土壤改良及藥劑防治的結果，使稻胡麻葉枯病之發生顯著減少，但仍有部分農友，特別是宜蘭縣的農民，對稻胡麻葉枯病的認識仍不夠，為此特將此種病害的症狀、發生環境及防治法介紹給農友，以減少損失。\n \n病徵及傳播途徑 \n 稻胡麻葉枯病的發生一般在水稻孕穗期開始，以後逐漸增多至生育末期將屆成熟收穫時最為嚴重。葉片被害時，最初顯現褐色的小斑點，然後逐漸擴大成胡麻粒狀或橢圓形的病斑，由於其病斑類似胡麻，因此取名為胡麻葉枯病，在病斑的中央呈灰白色，周緣暗褐色，具有淡黃色暈環，葉鞘受害時則呈現不規則之淡褐色大病斑。節部、穗及枝梗亦會被為害，受害時呈現暗褐色或淡褐色。此病菌是由種子或空氣傳播。 \n\n對稻株生育及產量的影響 \n 將罹患嚴重稻胡麻葉枯病的種子做稻種播種後，約有 15∼18％的秧苗會致死，使秧苗及初期稻株生育衰弱，減少葉片光合作用能，降低穀粒重 4.6∼29.1％，稔實率 1∼9％，產量可減少 50∼90％，品質亦變劣。 \n\n土壤與營養條件 \n 一般而言，稻胡麻葉枯病在土壤肥力愈貧瘠的稻田愈易發生，排水不良的稻田亦容易發生且嚴重，在本區東岸母岩沖積土、黑色土及黃土之稻田較不易發生，但在片岩沖積土則易發生，特別是在具有鐵錳積聚層的水田和排水不良的水田。經農試所及本場多年試驗結果，發現稻胡麻葉枯病的發生與土壤中有效性矽、鉀及錳之含量有極顯著之負相關關係，即土壤中有效性矽、鉀及錳的含量愈低愈易發生此種病害。日本的文獻亦指出胡麻葉枯病的發生與氯化鉀的不足有密切的關係，氯化鉀欠缺時病斑數增加，特別在水稻營養生長期，停止供應氯化鉀時發病特別顯著。氯化鉀缺少時不但病斑數增多且大型病斑增加。稻胡麻葉枯病的發生與氮肥亦有密切關係，氮肥施用過多時小型病斑率高，氮肥施用不足時大型病斑率高，於水稻生育初期氮供應過多，生育中期以後急速缺氮時易引起營養凋落而發生胡麻葉枯病。另有文獻指出磷的含量與胡麻葉枯病的感受性呈正相關關係，即磷的含量愈低水稻愈不會得到胡麻葉枯病。因此欲減輕此病的為害，必須注意水稻的營養管理及土壤改良。 \n\n氣候條件 \n 稻胡麻葉枯病適宜發生的溫度為 25∼30℃，而二期作水稻的生育期適逢高溫，因此二期作較易發病且較嚴重，一期作的生育期恰低溫，因此一期作較不易發生且輕微，在花蓮地區罹病指數平均一期作為 31，二期作為 42。一般適當的水溫為 30∼32℃，如果水溫較此範圍高時或低時，將造成營養吸收之選擇性的抑制而使水稻容易感受胡麻葉枯病。在夜晚高溫和在仲夏光度強的情況下，容易發生胡麻葉枯病。空氣高濕和土壤水分低時，不僅抑制矽和鉀的吸收並且減低葉子矽酸及氧化鉀的含量而增加水稻對胡麻葉枯病的感受性。\n \n防治方法 \n要減輕稻胡麻葉枯病的發生，必須注意下列幾種措施才能奏效： \n(一)稻種消毒：稻胡麻葉枯病的病菌係藉種子傳播，因此應避免將罹患病株的稻穀當作稻種，應選無病者供作稻種。為減輕在苗床和本田發病機會，稻種經選種後，應選擇適當的藥劑消毒以消滅附著在稻種上的胡麻葉枯病的病原菌。 \n(二)增施有機物：多施堆肥、綠肥等有機質肥料並行深耕以增進土壤肥力及改善土壤物理性。 \n(三)適當的氮肥：氮肥施用不要過多或過少，宜根據稻株反應作靈活調節氮肥施用量及施用時期。 \n(四)矽、鉀、錳肥的施用：在胡麻葉枯病容易發生的稻田，每公頃增施矽酸爐渣四噸＋氧化鉀 60 公斤＋硫酸錳 100 公斤，在一期作罹病指數由 31 減至 16，即病害減輕 48％；二期作由 42 減至 28，病害減輕 34％。產量一期作由 4,265 公斤／公頃增加至 4,929 公斤／公頃，增產率 16％，二期作由 2,644 公斤／公頃增加至 3,217 公斤／公頃，增產率 21％。 \n(五)藥劑防治：目前防治稻胡麻葉枯病的藥劑仍以 33％鋅錳乃浦水懸粉劑較為有效。為配合胡麻葉枯病的發生時期，噴藥防治第一次宜在水稻分藥盛期時施藥，經 14 天再施藥一次，第三次則在齊穗期施藥，經 14 天再施藥一次。如此可以提高稔實率、千粒重及增加稻穀收量 7∼13％。 ̱\n"}, "1680062248.655912": {"單位": "", "標題": "苗栗區農業專訊佔第二十九期 水稻胡麻葉枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻為臺灣地區最主要的農作物，也是國內栽培面積最廣及農戶數最多的產業，除具糧食安全丶農村經濟發展外，更具社會安全丶生態保育及文化傳承等多功能特性。由於臺灣氣候屬高溫多濕的環境，很適合各種作物病原之繁殖及為害，每年因病害的損失估計約6-10%。近年來稻熱病丶白葉枯病、紋枯病為水稻主要流行病，然而胡麻葉枯病在近年來為本轄內二期稻作之重要風土病，為預防該病發生，特專文報告，以滅少損失。\n胡麻葉枯病是水稻普遍發生的真菌性病害，此病菌可由種子或空氣傳播。在苗栗地區每期作發生面積約3.500公頃以上。水稻在各生育期均可受害，尤其以水稻抽穗開花至黃熟期病癥最為顯著，胡麻葉枯病的危害主要以葉片及穀粒為主，葉片被害時，初呈墨綠色水浸狀小班點，隨後轉為褐色小斑點，再次擴大成為紡錘形或橢圓形，然後逐漸擴大成胡麻粒狀的病班，由於病斑類似胡麻，因此取名為胡麻葉枯病。在病斑的中央是灰白色，周緣暗褐色，具有明顯淡黃色暈圈，穀粒危害時亦呈現暗褐色或淡褐色小斑點，病斑擴大後亦呈胡麻種子大小之病斑，致稻穀空粒增加，糙米變為銹米、死米或青米等，一旦發生則影響稻米產量與品質甚鉅·\n胡麻葉枯病的發生與土壤質地，施肥管理及氣候條件有密切的關條，一般發生在砂質土壤，因土壤貧脊，缺乏有機質肥料、土壤淺且保肥力差，鐵錳積聚層和排水不良的酸性土壤水田。此外，酸性土壤中有效性矽、鉀及錳的含量愈低，易發生此種病害；或水稻生育初期氮肥供應過多，生育中後期急速缺氮引起營養不均。另外在二期作水稻的生育初期適逢高溫丶強風丶豪雨，開花抽穗期又逢東北季風，乾季提早來臨，致灌排水管理不當，使得胡麻葉枯病甚為明顯發病。\n在防治方法方面，水稻胡麻葉枯病主要由稻種傳播，因此應選擇適當的藥劑將稻種消毒，以消滅附著在稻種上的病原菌，並避免將罹患病株的稻榖供作稻種，可滅輕發病機會、此外，在土壤改善方面應勵行深耕，打破犁底層，增加有機質肥料及種植綠肥植物，並靈活調節氮肥施用量。施用土壤改良劑，在整地前應施用苦土石灰或矽酸爐渣調整酸鹼度。藥劑防治方面，在水稻發病初期施用33%鋅錳乃浦水懸劑400倍丶37%錳乃浦水懸劑600倍丶25%普克利乳劑1,300倍，經14天再施用1次，連續4次，效果最佳。經由以上的措施，皆可達到防治的效果，增加產量改進米質。\n"}, "1680075194.6098702": {"單位": "", "標題": "稻小粒菌核病台灣發生情形及危害概述", "作者": "", "發布日": 0, "摘要": "", "全文": "稻小粒菌核病包括小球菌核病及小黑菌核病，二者之形態及生態均有差異，一般認為小黑菌為小球菌之變種。小粒菌核病為臺灣水稻之風土病，每年發生情形變化很大。根據前臺灣省政府農林廳統計 1964-1996年期間，第一期作稻小粒菌核病的發生面積，以1971發生面積3,639公頃最廣，第二期作之發生面積，以 1973 年達 24,416公頃為最廣；1976年以後，第二期作稻小粒菌核病發生面積均低於五千公頃。由上述資料顯示，臺灣第二期稻作小粒菌核病的發生面積比第一期作廣，臺灣水稻小粒菌核病之分佈並無明顯的地理性差異。1962年第一期作平均 發病率及損失率分別為71.31％及25.23％，第二期作則為64.64％及37.00％，因此第二期作水稻受害程度比第一期作嚴重。小粒菌核病菌感染稻株，如僅以細小病斑出現於葉鞘或莖稈上，一般對稻株生育之影響甚小，而不被認為是病害；如果稻稈周圍被害達20-30％ 以上，小粒菌核病菌侵入稻組織後，分解組織使其軟化腐朽，莖稈地基部組織軟化後，常引起稻株倒伏並提早死亡，則可導致50％以上之減產，故其破壞性很大。"}, "1680075318.3171825": {"單位": "", "標題": "稻小粒菌核病病徵", "作者": "", "發布日": 0, "摘要": "", "全文": "本病主要危害稻葉鞘及莖稈。初發生期及感染部位，均與紋枯病相似，在水稻分孽盛期，稻叢近水面之葉鞘表面形成小型黑漆色的病斑或黑色細長的縱條斑，漸次擴大至葉鞘內部。水稻分期至抽穗期，小粒菌核病之病勢進展，一般僅止於葉鞘甚少進入莖稈。水稻乳熟期，葉鞘病斑上之病原菌會開始侵入稻稈組織，產生縱條狀黑色病斑，病斑散生。嚴重時，多數病斑合併圍繞整枝稻稈，稻稈組織由內向外漸次被病原菌分解，病稈組織軟化後隨之腐朽，稻株倒伏枯死。人為接種小球菌核病菌到葉鞘或莖稈，病斑呈線狀或斑紋狀；接種小黑菌核病菌病斑呈縱走線狀，此可作為診斷二種菌核病菌之特徵。但是依筆者過去經驗，在田間並不易利用病徵分辨小球菌核病或小黑菌核病。稻小粒菌核病感染葉鞘或莖稈後，會在病組織中及莖稈內壁形成多數菌核。小球菌的菌核呈規則之圓球形，表面黑色具光澤，大小0.2~0.3公釐左右。小黑菌之菌核為不規則球形，表面黑色無光澤，菌核數目較多但較小形，大小為0.1~0.2公釐。 被小粒菌核病危害之稻稈形成菌核後，雖然外觀病徵不易分辨何種小粒菌核病菌所引起，但因小黑菌之菌核小而多、小球菌核大而少，所以剝開病稈，由菌核量及大小可約略診斷。小球菌之菌核在病組織上之著生方式，為表生或半埋生於病稈內壁表面組織，菌核圓球形而表面光滑，當剝開病稈後輕輕震動，即可見許多菌核掉落。相對的，小黑菌之菌核著生方式為埋生，菌核表面較粗糙，剝開病稈時除了切口上之菌核掉落外，輕輕震動並不易使菌核掉落。調查田間病株上之菌核，常發現一叢水稻中同一病稈小球菌及小黑菌分別或同時存在，得知兩菌共同危害之情形很高。小粒菌核病菌常自葉鞘外部感染，逐漸進展使葉鞘與稻稈形成病斑，病菌進入稻稈內部組織後，再往上下兩方向擴展病勢，所以先被感染之節間內所產生之菌核量最多。但部分小粒菌核病，係由稻稈基部感染，再往上蔓延，這種感染方式，在葉鞘及莖稈上並無明顯病斑，但病稈基部組織常變黑色而有灰色菌絲，菌核量以基部往上第一或第二伸長節間最多。"}, "1680075384.7239091": {"單位": "", "標題": "稻小粒菌核病病原菌概述", "作者": "", "發布日": 0, "摘要": "", "全文": "稻小粒菌核病病原菌學名：有性世代 Magnaporthe salvinii (Catt.)R.A. Krause & R.K. Webster，無性世代 Nakataea sigmoidea (Cavara) Hara var. sigmoidea、Nakataea sigmoidea (Cavara)Hara var. irregulare(Cralley & Tullis)。分類地位 Ascomycetes 子囊菌綱，近似 Phyllachorales 黑痣菌目，Magnaporthaceae 科 Magnaporthe屬。分布：本病廣布於世界各稻產區，包括亞洲、美洲、非洲及歐洲均有記載。寄主：本菌為腐生性強之兼性寄生菌，在自然界大多以弱寄生為主。利用人工接種測試，寄主植物廣，但以百合科、莎草科、禾本科及燈心草科等為主要寄主植物。田間禾本科植物如茭白筍等也有小粒菌核病，各種植物與水稻上之小粒菌核病菌是否相同，尚未獲得明確的答案。形態：本病之病原菌僅有小球菌會形成有性世代，小黑菌只有無性世代。小球菌有性世代為異絲生殖，形成子囊孢子及子囊殼。子囊殼黑色球形、埋生於葉鞘外側組織，直徑平均381µm（202-481µm），殼鼻短僅30-70µm，寬度為子囊殼直徑的一半、不突出葉鞘外表皮、肉眼可見。子囊弧形、大小約為90-128 ×12-14µm，子囊 壁幾乎看不見並於孢子成熟時溶化有柄。子囊內一般有8個子囊孢子偶爾僅有4個、雙列排列。孢子成熟時具3個隔膜，隔膜略縊縮褐色呈稍彎曲之紡綞形兩端細胞較淡大小為38-53 × 7-8µm。菌絲白色、灰白至橄欖色，在病組織或培養基上大多表生，菌核黑色、表面光滑、大小180-280µm。分生孢子紡綞形彎曲，一般具3個隔膜中間隔膜處常有縊縮，兩端細胞顏色較淡，大小約為29-49×9.9-14.2µm。小黑菌之菌絲白色、灰白至橄欖色，氣生菌絲較少，埋生菌絲黑色。菌核在病 組織或培養基上大多埋生，菌核量較多而 小，約為268-342 ×90-119µm，菌核黑色、不規則、表面粗糙。分生孢子紡綞形，一般具3隔膜，兩端細胞較淡，大小約為41-58 ×9-12µm、常附有孢子長度2-3倍長之附絲即發芽管。病原菌在自然界以無性世代為主，利用菌絲行營養生長，以菌核為主要繁殖體，具殘存及傳播功能，菌絲在土壤中之殘存力不強，但病組織中之菌絲殘存期間較長。根據報告，本菌在寄主組織內會形成有性世代之子囊殼及子囊孢子。"}, "1680075426.0741239": {"單位": "", "標題": "稻小粒菌核病診斷技術", "作者": "", "發布日": 0, "摘要": "", "全文": "在葉鞘病斑為黑漆色或黑色細長的縱條斑，與其他病害之褐色斑有差異；稻稈上產生縱條狀黑色病斑，病斑散生，嚴重時，多數病斑合併圍繞整枝稻稈，稻稈組織由內向外漸次被病菌分解，病稈組織軟化後隨之腐朽，稻株倒伏枯死。 小粒菌核病會使稻株倒伏提早枯死，與飛蝨類所引起之「蝨燒」相似，人們常不易分辨而互相混淆。單純病害或蟲害時，只要由枯死稻株上有無蟲蛻皮所留之殼，或組織中有無菌核，即可診斷。但因兩者常共同危害，所以何者為主兇？就需要經驗判斷，蟲殼愈多則蟲所佔角色愈重要，菌核愈早出現則病害所佔角色愈重要，即稻株剛枯萎時稻稈內就有菌核形成，小粒菌核病的可能性甚大。另外，觀察田間倒伏株時，可將稻莖分成上下二半，上半部莖幹先枯萎組織鬆軟者大多因「蝨燒」所致，下半部莖幹先枯萎組織鬆軟者大多因小粒菌核病所致。"}, "1680075485.2918577": {"單位": "", "標題": "稻小粒菌核病發生生態", "作者": "", "發布日": 0, "摘要": "", "全文": "小粒菌核病的病組織枯死後，病菌在組織中形成大量菌核，並可延續至稻收穫後。病菌在稻樁上繼續產生菌核，與零落殘留於土中的菌核，成為下期作之初次感染源。各方研究結果，顯示小粒菌核病菌在田間，至少可存活4個月以上，比臺灣各期作間隔為長。本病菌之菌核在稻田中之消長，據筆者進行稻紋枯病生態研究時所做比較觀察，發現本病菌與紋枯病菌相似，整地至插秧時田水中菌核量最多。每公頃小粒菌核病菌之菌核量估計約在100億至1000億，插秧後每叢水稻外表上常附有數十至數千個菌核，本菌之腐生性較強，稻株上之菌核會發芽並於植物殘體等有機物質上生長，若缺乏可供生長有機物或環境不適合時菌核發芽後隨即死亡，受稻株本身抗性及拮抗微生物之影響，只有少數菌核發芽後會感染水稻葉鞘。本病之病斑上會形成分生孢子，野中氏報告，分生孢子之感染較菌核之感染機率少，故經由分生孢子造成之第二次傳染，對本病不具重要性。小球菌及小黑菌接種在水稻葉片或葉鞘上，菌絲形成附著器及侵入菌絲之最適溫度為24-28℃，在36℃以上不能形成附著器，在8℃時小球菌可形成少數附著器，小黑菌則不形成附著器。謝氏報告，指出小粒菌核病菌感染之最適溫度為24℃，病斑發展之最適溫度為30℃。剝除葉鞘之稻莖上，以刺傷接種小球菌，在8℃及36℃可產生小病斑，小黑菌則無法產生病斑。對具有葉鞘之稻莖上，小球菌及小黑菌在12℃以下或36℃以上均不產生病斑。較高溫氣候下易發生小球菌核病，小黑菌則相反。本病發生與施肥之關係極為密切，研究顯示，氮肥施用量多於正常量時易發生小粒菌核病，多施鉀肥時可減少小粒菌核病的發生，磷肥影響不大，但同時多施鉀肥與磷肥之水稻對小粒菌核病之抵抗性低，比單獨多施鉀肥者較易發病，矽酸可增加稻株抗性。灌溉排水影響菌核之形成、發芽、感染及病勢之進展，其中以灌水深度及排水時期與小粒菌核病發生之關係較為密切。綜合多位學者之研究結果，稻小粒菌核病對深水區稻株之感染率比淺水區為高，可能因深水區中之漂浮菌核被帶到較高位葉鞘、菌核易流入葉鞘內側、葉鞘組織比較纖弱易感病等因素所致。但病菌侵入葉鞘組織後，病菌在病組織中之病勢進展，則洽好相反，即淺水區之病勢進展較快，其原因可能與稻組織之水份潛勢有關。降雨時期及降雨量對稻小粒菌核病之影響，與灌排水之影響頗為相似，感染期或感染期來臨前降雨量多，稻株被感染率增加。病勢進展期降雨量豐富，病勢進展速率就降低稻品種對小粒菌核病之抗感病性，多篇研究報告均指出，稻品種間之抗感病性因年而有差異，這種差異乃起因於稻生育期間之氣候所致。一般而言，早熟品種比晚熟品種較感病。水稻其他病蟲害與小粒菌核病亦有密切關係，例如有節稻熱病、紋枯病、線蟲心枯病等病害併發時，可以抑制水稻小粒菌核病之被害度。水稻受二化螟蟲及飛蝨危害後，有助於小粒菌核病之感染及病勢進展，為眾所周知之事實。稻胡麻葉枯病與稻小粒菌核病之間，常有共同危害並互相增加其危害程度之現象。"}, "1680075574.100839": {"單位": "", "標題": "水稻小粒菌核病防治藥劑初步篩選", "作者": "", "發布日": 0, "摘要": "", "全文": "本病害在中國大陸造成危害，陸續有不少相關防治報告，其中如李氏於2010年水稻小粒菌核病的防治提到選用部份稻熱病或紋枯病的防治藥劑進行防治，可施藥於始穗期連續施用兩次，間隔為7天；或者於孕穗期連續施用三次，間隔為6天，施藥於水稻欉基部。潘氏亦在2014年提到田間試驗中利用依普同、撲克拉、普克利等藥劑有防治效果等等。臺灣小粒菌核病目前田間出現枯萎症狀相當零星不常見，同一田區於下一期作也不易再觀察到相同症狀發生。104年收集田間水稻殘體，切取基部於室內分袋包裝靜置1 個月後，15個田區的水稻殘體中，有6個田區的水上殘體上長出小粒菌核，共收集得6個菌株，進一步以臺南11號水稻進行病原性測試，其中3個菌株呈陽性反應，分別來自雲林縣大埤鄉、嘉義縣太保市、臺南市柳營區。小粒菌核病目前無登記防治藥劑，以往多參考紋枯病防治方式。本研究由水稻登記使用藥劑之作用機制中選取18種藥劑 ，先進行對採集之3個病原菌株進行藥劑抑制率測試，每種作用機制藥劑選取一種藥劑作代表，其中8種藥劑抑制率達100%：40% 甲基多保淨水懸 劑 1000倍、50% 免賴得可濕性粉劑1000倍、55% 貝芬同可濕性粉劑1000倍、50% 福多寧可濕性粉劑2000倍、50% 護粒松乳劑1000倍、23% 菲克利水懸劑 4000倍、20% 芬諾尼水懸劑1500倍、80% 鋅猛乃浦可濕性粉劑500倍。將登記於水稻上之相同機制藥劑整理如下：50% 免賴得可濕性粉劑1500倍、40% 甲基多保淨水懸劑1000倍、55% 貝芬同可濕性粉劑 1000倍、7.5%依普座乳劑 1000倍、23%菲克利水懸劑 4000倍、10.7% 四克利乳劑1000倍、12% 依普座水懸劑 1500倍、24.9% 待克利乳劑 3000倍、24.9% 待克利水懸劑 3000倍、10% 菲克利乳劑 1500倍、25% 普克利乳劑 1300倍、2%賽氟滅粒劑 30公斤/公頃、21%賽氟滅水懸劑 3000倍、1.5%福拉比粒劑 20公斤/公頃、15%福多寧乳劑 1500倍、40% 滅普寧水懸劑 1200倍、20% 福多寧水懸劑 2000倍、75% 滅普寧可濕性粉劑 1000倍、50% 福多寧可濕性粉劑 3000倍、50% 護粒松乳劑 1000倍、20% 芬諾尼水懸劑 1500倍、33%鋅錳乃浦水懸劑 400倍、80%鋅猛乃浦可濕性粉劑 500倍、37%錳乃浦水懸劑 600倍。可供農友作為防治參考。防治方法：一、種植抗病品種，水稻不同品種對於病害抗病性不同，品種抗病在田間也是持續變化中，一般而言早熟品種較晚熟品種感病。二、罹病稻株之處理：水稻收穫時，應從接近地面刈割，減少菌核殘留田間。稻草不可用作肥料，必須經過醱酵後，方可施用。 三、注意肥料三要素之配合，避免缺乏鉀肥。四、於發病田區耕犁進水後，可將浮於水面之菌核或稻桿清除。五、雜草防治：本病病原菌為多犯性，必須除去畦畔之雜草，以減少傳染源。六、藥劑防治：農友可先參考登記於水稻病害之防治藥劑，如表二，施藥時期可於始穗期連續施用兩次，間隔為7天；或者於孕穗期連續施用三次，間隔為6天，施藥於水稻欉基部。七、盡量減少病蟲害等因素所造成之傷口，可降低本病害感染之機率。"}, "1680075605.8295317": {"單位": "", "標題": "稻小粒菌核病之侵染與稻齡及品種之關係及其有效防治藥劑之研究", "作者": "", "發布日": 0, "摘要": "", "全文": "臺南5號之不同稻齡與小粒菌核病感病程度，於室內或盆栽接種結果，無論小黑或小球菌核病，第一期作自插秧後第67~74天，第二期48~55天之間最適病勢之進展。但在田間生長水稻之發病盛期（20個品種平均），第一期作爲第66~73天（插秧之日起算），第二期作爲第42~49天之平均病斑爲最高峰。較此時期早或晚之接種區，其病勢進展皆呈漸次減少之傾向供。供試品種中對小黑菌核病之抗病程度較強者有高雄選1號，Tetep台中186號，臺中在來1號，新竹矮腳尖，臺中178號等；對小球菌核病者有臺中早試60號，臺中低腳烏尖，新竹171號，臺中在來1號，新竹矮腳尖，高雄選1號，臺中65號及臺中178號等。一般對小粒菌核病具抗病性品種中，屬在來稻之比率爲多。供試三種系統性殺菌劑中，以Benlate T-2加對小粒菌核病之病勢控制效果最優，其使用濃度以1,000倍爲佳。"}, "1680078073.5626657": {"單位": "", "標題": "水稻病害—細菌性條斑病", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病 (Xanthomonas oryzae pv. oryzicola) 原分布於中國 (福建、廣東、海南、湖南及浙江省)、印度、東南亞各國及澳洲等，為熱帶地區水稻栽培重要的病害。民國 96 年首度在臺灣零星發生，民國97年二期稻作在彰化縣社頭鄉、田中鎮、芳苑鄉、臺中縣龍井鄉及南投縣名間鄉等地再度發生。該病害於中國及印度等地造成水稻 5-30 %不等的產量損失。水稻嚴重罹病時，外觀上與水稻白葉枯病 (Xanthomonas oryzae pv. oryzae) 極為相似。"}, "1680078096.909248": {"單位": "", "標題": "水稻細菌性條斑病危害徵狀", "作者": "", "發布日": 0, "摘要": "", "全文": "初期病斑呈現暗綠色水浸狀半透明斑點，而後在葉脈間伸展形成半透明狀條斑，持續擴大可達寬 0.5-1.0mm、長 3-15mm 的條斑，最後轉為褐色病斑。條狀病斑會相互融合成橙黃色不規則斑塊，之後轉為灰白色，嚴重時全葉乾枯內捲。此外，病斑上常出現許多琥珀色細小露珠狀的病原菌流出物。受害葉片出現半透明狀條斑及病斑上溢出的病原菌物可作為與白葉枯病區分的依據。"}, "1680078127.8598855": {"單位": "", "標題": "水稻細菌性條斑病傳播途徑及發病條件 ", "作者": "", "發布日": 0, "摘要": "", "全文": "帶病的稻種、遺留田間的帶病稻草及帶菌的再生稻苗均可能成為細菌性條斑病的初次傳染原。在田間，病原菌主要由氣孔或稻葉傷口侵入，在溫暖潮濕的環境下，會藉由風、雨水、露水及灌溉水來傳播，尤其是颱風造成稻葉的傷口或瘤野螟幼蟲取食後的食痕均會助長此病害的蔓延。稻種在長距離傳播扮演重要的角色，病原菌可存在稻穎，甚至可侵入胚乳部位。此外，偏施氮肥及深水灌溉的稻田罹病較為嚴重。"}, "1680078237.8202004": {"單位": "", "標題": "水稻細菌性條斑病管理對策 ", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻細菌性條斑病雖然已在台灣多個鄉鎮被發現，然而呈現點狀的分布，尚無明顯擴展的跡象，如能妥善因應，或能減緩其危害及擴展的速度。由於稻種成為長距離傳播的媒介，應加強採種田的控管，避免由罹病田區採種。國內育種研究人員由菲律賓稻米研究所或東南亞各國引進育種材料應加強稻種消毒的程序，避免試驗改良場所反而成為該病害的傳染原。此外，罹病地區稻田應減施氮肥，可減輕病勢的發展。該病害為白葉枯病病原菌的變種，防治藥劑可選擇克枯爛或鏈四環黴素等。"}, "1680078264.3723261": {"單位": "", "標題": "注意細菌性條斑病的防治", "作者": "", "發布日": 0, "摘要": "", "全文": "水稻罹患白葉枯病或細菌性條斑病，避免清晨露水未乾前行走於已發病之稻株間是相當重要的，施肥或噴藥工作建議儘可能於下午進行。防治藥劑可選用下列之一進行防治： 14 ％ 嘉賜克枯爛可濕性粉劑 1500 倍、33 ％ 克枯三賽唑可濕性粉劑 1000 倍、 10 ％克枯爛可濕性粉劑 1000 倍、10 ％ 鏈四環黴素可溶性粉劑 1000 倍。"}, "1680078331.089851": {"單位": "", "標題": "Xanthomonas oryzae pv. oryzicola引起的水稻細菌性條斑病", "作者": "", "發布日": 0, "摘要": "", "全文": "2007年在南投縣草屯鎮及雲林縣二崙鄉田區水稻陸續出現暗綠色至黃褐色條斑的病徵，條斑上有時可見細小的黃色菌泥，後來陸續在苗栗、台中、彰化、嘉義、台南、花蓮和台東等地發現相同的病徵，從條斑處可分離出黃色細菌，菌落型態類似白葉枯病菌，經柯霍氏法確定此黃色細菌為病原，經過16S rDNA定序比對，結果顯示此病原細菌與水稻白葉枯病菌Xanthomonas oryzae pv. oryzae（Xoo）相似度高達97%，與Xanthomonas oryzae pv. oryzicola（Xoc）相似度達100%，此病原細菌接種至供試水稻品種上皆造成條斑狀病徵，不同於白葉枯病菌造成的典型葉枯型病徵，且生理生化試驗測定結果得知該細菌可利用L-Alanine，但無法生長在含有Cu(NO_3)_2的培養基中，確認該病原細菌為X. oryzae pv. oryzicola，可引起水稻細菌性條斑病。又於溫室接種不同水稻品種測試其抗感病性程度，結果顯示16個台灣常見品種均可感病，但3個供試菌株造成的發病程度不一，XOCH-1菌株（平均罹病等級為1.8）致病力明顯較XOCI-1c（2.3）及XOCK-1b（3.1）弱。「台稉2號」、「台稉8號」、「台稉11號」、「台稉16號」和「台南11號」發病率均達100%，「台南11號」和「台稉16號」平均罹病等級最高（3.6和3.3）；發病率最低者分別為「高雄145號」（41.7%）、「台東30號」（41.7%）和「台稉糯1號」（78.3%）。測試10種殺菌劑在不同濃度下對該病菌的生長抑制效果，以81.3%嘉賜銅可濕性粉劑400×、80%鋅錳乃浦可濕性粉劑1,000×，以及白葉枯病防治藥劑10%鏈四環黴素可濕性粉劑1,000×、10%克枯爛可濕性粉劑1,000×的效果最佳，將其稀釋液於溫室內進行防治試驗，結果顯示4種藥劑均能降低發病率，且接種前施用較接種後施用防治效果佳，其中以接種前3天施用鋅錳乃浦、接種前7天及前1天施用嘉賜銅的防治效果最佳。"}, "1680078357.0933537": {"單位": "", "標題": "茶白紋羽病及其病原菌", "作者": "", "發布日": 0, "摘要": "", "全文": "於南投 4 處高山茶園出現立枯型病徵之茶樹根腐檢體中，分離出 9 株白紋羽菌株，其特徵為菌絲隔膜處呈梨形膨大，並可於罹病組織處產生分生孢梗（synnemata）等構造。進行茶苗人工接種試驗結果顯示，所有菌株之致病性皆相當高，可使接種茶苗產生與田間罹病株相同之病徵，從死亡病株中可再度分離出白紋羽菌，而完成柯霍氏法則。選取 4 株致病力最高之白紋羽菌株進行生理試驗，結果顯示供試菌株其最適生長溫度範圍為 25 ℃，35 ℃以上則不生長， 而於 5 ℃ 1 星期後，菌落仍可生長 0.1 mm；菌絲生長最適酸鹼度約為pH 5； 6 種不同碳素源中以葡萄糖（glucose）最適合茶白紋羽菌絲直線生長，而木糖（xylose）較不適合。8種氮素源中，以有機氮源較適合菌絲之生長；而硝酸鈣或尿素作為氮源時，其菌絲生長最緩慢。"}, "1680078380.5542142": {"單位": "", "標題": "茶白紋羽病台灣紀錄概況", "作者": "", "發布日": 0, "摘要": "", "全文": "白紋羽病（White root rot）為一種土媒病害，危害寄主植物之根部及地際部，在潮濕環境下，可產生大量白至灰白色的菌絲覆蓋在病組織表面。若將罹病根皮剝離後，可發現白色羽扇狀菌絲存在，其所造成之根部腐朽種類屬於白根腐（white root rot）。 白紋羽病急性發病時可造成植株迅速萎凋，慢性發 病時植株黃化而枝葉稀疏漸漸枯死。本病可危害多種果樹如枇杷、梨、蘋果、李、杏、橄欖、柑橘及葡萄，造成許多林木和行道樹如松樹及櫻花等之根腐病，其 亦為台灣地區引起果樹以及木本觀賞植物立枯之真菌病害之一。根據台灣植物病害名彙、 日本以及中國等文獻之記載，其亦為茶樹根部重要病害之一。以往台灣茶樹病害研究對象皆集中於地上部病害方面，對於地下部茶樹病害之研究目前仍然相當缺乏，而由白紋羽病對枇杷及梨等作物之危害經驗顯示，茶白紋羽病實在不容忽視。"}, "1680078398.843154": {"單位": "", "標題": "茶白紋羽病病原生態及防治", "作者": "", "發布日": 0, "摘要": "", "全文": "在台灣白紋羽病多發生在中北部高冷地區，喜冷涼、潮濕的環境，台灣平地茶園極少發生，只在少數高山茶園被發現。其傳播的方式是藉由病根與健根的接觸；田間病害發生的模式是以罹病株為中心，向外作輻射狀的擴散，在無寄主的狀態下，病原菌可附著在有機物上存活很久。本病主要危害茶樹的根部及基部，若發生在茶苗，數周內即死亡。發生在成長多年之成木茶樹，受害植株根表面有白色棉絮狀的菌絲覆蓋在病組織表面，將罹病根表皮剝離，表皮下可發現放射羽毛狀的菌絲，最後可以遍及整個根部，發病多年的老根表面被覆一層灰色的菌絲片，仔細觀察其中有許多粗、細不等的灰黑色菌絲束，被害寄主植物會造成根部腐敗，樹皮很容易脫落，由於根部腐敗導致罹病植株的葉片黃化、褐變、枯萎、繼而落葉，最後全株萎凋死亡。防治方法：一、高山茶區新開墾的茶園，應將前作的根系完全清除，避免殘根成為病原。二、發病輕微的茶園，可利用掘溝阻斷法防止本病的擴散；並應徹底的清除殘留在地上或土中的殘根。"}, "1680078444.454133": {"單位": "", "標題": "談白紋羽病的土壤管理對策", "作者": "", "發布日": 0, "摘要": "", "全文": "白紋羽病的病原菌為Rosellinia necatrix(Hartig) Berlese(Dematophora necatrix Hartig)，子囊菌類屬絲狀菌。菌絲為該病之主要感染源，平常以病株根部為其存活場所。病害主要藉健株與病株之根系交纏而傳播，亦可藉根部帶菌之幼苗，或帶菌之土壤傳播與蔓延，所以罹病株因根部受害後，影響水分、養分吸收及輸導功能，致使植株呈現缺水萎凋狀，爾後經數月或數年而逐漸衰弱、落葉及枯萎死亡。該病害在發病初期，其地上部的症狀，如延遲發芽、新梢生長不良、花芽增加、異常著果、葉片褪色及早期落葉等症狀的表現。地下部的症狀，是從根的表面 可見到有白色～灰白色的菌絲束及菌絲，罹病根之橫切面有變色腐敗之特徵。病源菌在罹病根內可存活8年以上，罹病組織為自然界之主要感染源。可危害的寄主範圍相當廣泛，梨樹、蘋果樹、桃樹、李樹、梅樹、葡萄等果樹類，其他桑樹、茶樹等木本類，還有蘆筍等宿根性作物，有時大豆和玉米等也會有發生危害。若罹病株死後，如果土壤未經消毒，其病源菌可長期存在土壤內而成為傳染源。本菌於12～28 ℃皆可生長，20～28 ℃生長最好，臺灣地區雨量充沛，濕度高，適於本病的發生。防治病蟲害的對策，首推「診斷」為最重要的工作。特別在土壤病害，不僅地上部的症狀很容易與潮濕 的障害混淆，而導致誤診及造成錯誤的防治對策。有報告指出該病在排水不良的梨果園發生白紋羽病機率較多，相反的，在排水良好且乾燥的果園也有發生的實例報告。實際上，在潮濕及乾燥的環境下，導致根圈容易受害，亦為誘發致病的因素之一。此外，在粘質土壤屬於慢性型發生，砂質土壤屬於易發生的急性型，所以土質對根系活性及病原菌的增殖所造成的影響有相關性。在果園實地調查，常可發現使用未腐熟且粗糙之有機物的果園，其土壤狀況對白紋羽病發生的頻率有增加的趨勢。在防治上可從三方面著手，首先對發病果樹的處理，如果確認為白紋羽病及發病程度，與有無腐敗病根及菌絲的附著，則將地際部的土壤除去。樹勢差，腐敗根又多，健全根較少時，屬於重症至枯死之間，枯死的可能性較高，又枯死至樹勢回復需要長時間，則以伐採、改植等方法較佳。在樹勢稍差，但受害程度輕，健全根的比例較高時，屬中症至輕症之間，可以推薦藥劑如40%甲基多保淨水懸劑、25%撲克拉乳劑或50%撲克拉錳可濕性粉劑等藥劑防治。\n在發病裸地改種方面，枯死的裸地，改植後有慢慢再度發病的現象。另土壤消毒後再改植，三～四年後再發病的情況也不少。苗木種植後再以藥劑注入處理，再感染 機會則會下降。此外，對發病周邊樹預防處理，可以阻絕白紋羽病發生範圍蔓延。使用藥劑而導致靜菌及殘效，可能使土壤中的白紋羽病菌再活躍，因此定期追蹤及 處理是必要的。\n"}, "1680084053.2794747": {"單位": "", "標題": "植物保護圖鑑系列4-茶樹枝枯病", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌學名：無性世代Macrophoma theicola Petch\n英名：Die-back disease\n一、前言\n在臺灣·茶枝枯病為各茶區最普遍且嚴重的病害，1966年調查發現發病的茶樹死亡率達42.6%，栽培品種中以青心鳥龍最感病，臺灣重要茶鄉鹿谷茶區栽培面積最廣的品種為青心鳥龍，因而造成嚴重損失，甚至有些茶園因此而廢耕。1959年起臺灣丶日本有許多植物病理學者從事本病之研究，從病斑上分離到許多真菌，包括Colletochrichum sp.、Pestalotia sp.、Nectria sp.、Phomopsis sp.、Macrophoma sp，及Botryodiplodia sp.等，但都無法接種成功。自臺灣茶園中分離到Macrophoma theicola （由荷蘭Centralbureau voor Schimmelcultures的Dr. R. A. Samson所鑑定），接種於青心鳥龍及台茶12號等茶樹品種上，可產生與田間相同的病徵，再分離皆可得與原接種原相同的病原菌，完成柯霍氏法則，證實茶枝枯病的病原菌為Macrophoma theicola。2003年在田間發現本菌的柄子器，更可確定Macrophoma theicola為茶樹枝枯病之病原菌。\n\n二、病徵\n枝枯病主要危害茶樹的枝條，發病初期茶叢中受害枝條葉面失去光澤，逐漸轉為淡綠色，嫩梢下垂，嚴重失水，最後全枝葉片褐化乾枯，此時枯葉仍然留在枝條上，其他未受害的茶樹枝條仍然十分健旺。在田間的景象為整排翠綠茶行中有一撮撮枯死的枝葉，嚴重者病兆深入地基部，有一半以上枝葉枯死，甚至全株死\n亡。得病多年的老枝幹其感染部位的皮層部分死亡，其他健全的組織向感染處增生癒合組織·而形成中間凹陷或凹凸不平的潰瘍病癥。\n\n三、病原菌概述\n(一）分類地位\nMitosporic fungi\n(二）分佈\n日本·印度丶斯星蘭卡·越南·中國及臺灣等地。\n(三）寄主\n茶樹\n(四）形態\n菌絲生長在馬鈴薯葡萄糖培養基（PDA) 中，菌落初期為白色稀疏菌絲，生長緩慢，漸漸變成灰色，2星期後轉為黑色，4~6星期後，可在培養基表面形成瓶狀之柄子器，寬約0.1~1.2公釐，高約0.2~3.1公釐，僅有非常少的柄子器·可產生極少量的分生孢子。\n（五）診斷技術\n依病癥診斷，剖開病枝可發現罹病部位，皮層及木質部呈深褐色，健全部位則為青綠色（皮層）與灰白色（木質部），罹病枝條上有黑色柄子器，溼度高時，會泌出大量的分生孢子。\n（六）生活史\n病原菌寄生在茶樹枝條上，夏季產生柄子器，分生孢子為主要的傳染源·可能利用分生孢子或菌絲越冬。夏季極度乾旱會使得茶園發病嚴重。\n\n四、發生生態\n茶枝枯病菌絲最適生長溫度為28~34℃，最適生長水分潛勢32℃時為-1bar，24℃\n時為-9bar。在夏季7~8月時病勢進展最嚴重，秋季以後本病漸趨緩和，北部在10月以後，新罹病枝條不再出現，直到次年春天，氣溫上升，茶樹長出新梢，才漸漸發生新枝枯的現象，如此周而復始，造成茶樹的生長勢一年不如一年，因而縮短其經濟壽命；在乾旱的年份，因茶樹之抗病能力降低，使發病較一般年份更為嚴重，各品種對枝枯病之抵抗能力差異很大，田間觀察發現小葉種發生枝枯病的比率較大葉種為高。2003年臺灣全島夏季遭受長期大乾旱，發病比較嚴重的品種有臺茶一號、臺茶十號、臺茶十二號、小葉鐵觀音、桃仁鳥龍及青心鳥龍等品種，完全無發病的品種有台茶八號、赤芽山茶及皋盧等品種。\n\n五、防治方法\n(一)發病輕微的茶園應徹底的剪除罹病枝條，剪枝後應同時噴藥，以防止病菌再入侵。\n(二)發病嚴重的茶樹可進行臺刈，並逐一清除老枝條基部之病灶；枯死的茶樹應徹底挖除，並進行全面施藥·此時防治效果恐已事倍功半。剪除或挖除之枯死枝、葉曬乾後應立即燒毀。\n(三)發病嚴重的地區種植抗病品種。\n(四)夏季若遇乾旱應進行滴灌，發病之茶園在冬季茶樹休眠期，應再進行一次剪除病枝之工作。\n(五)防治藥劑可參考植物保護手冊。\n"}, "1680084271.6645453": {"單位": "", "標題": "茶園枝枯的發生原因與識別", "作者": "", "發布日": 0, "摘要": "", "全文": "一、前言\n　　茶園除了常見的病蟲害外，最令農友們著急、心痛的問題，就是茶樹枝條的萎凋與枯死。枝條枯死的情況可能是幾枝而已，也可能是全株死亡（立枯），可能是緩慢的枯萎，也可能是急速的枯死。發生枝枯的原因包括天候異常、人為因素及病蟲害等，無論何種原因造成的枝枯症狀都非常類似，用肉眼很難辨別，必須從多方面觀察、歸納，才能做最正確的判斷。\n二、發生枝枯的原因\n　　茶樹發生枝枯的原因可歸納成三大類：植物病蟲害、天候異常及人為耕作失當等，三者之間又相互影響，因此茶園發生枝枯的原因可能不止一種，如2003年的夏季嚴重缺水，乾旱加上枝枯病二種因子相互作用，使得罹病的茶樹嚴重枯死。\n(一)病蟲害所引起的枝枯\n　　依據危害來源的不同，將引起枝枯症狀的茶樹病蟲害，區分成二大類。\n1.\t病害：枝枯病、潰瘍病、立枯病、膏藥病等枝條病害以及根腐病、褐根病、白紋羽病、紫紋羽病、線蟲等根部病害都會造成茶樹的枯萎，在台灣枝枯病以及部份的根腐病是造成茶園枝枯的主要原因。\n(1)茶樹枝枯病：本病由Macrophoma theicola 所引起，危害茶樹的枝條，造成急速萎凋，有些枝條上會形成潰瘍的病徵；主要發生於夏季，尤其在乾旱的年度更是嚴重，秋天以後病害漸漸緩和，北部在十月以後就較少發病，至次年春天，茶樹長出新梢，氣溫慢慢上升之際，才又漸漸發生，每年的七、八月是本病發生的高峰期。枝枯病菌存在的茶園，年年都會循著此種模式，周而復始的進行著，直至衰弱枯死。\n(2)根部病害：台灣造成茶樹枯死的根部病害種類，在平地茶園可能是根腐病或線蟲，在高山地區除了根腐病外，可能還包括白紋羽病。根部病害造成局部或全部根系的生長不良，影響水份、養份的吸收，致使茶樹生長不良，抗病蟲能力降低，易罹患其它病蟲害。其病徵為全株性的症狀如全株矮化、芽葉變小、黃化、全株性落葉，植株更容易感染枝枯病菌，嚴重者全株立枯死亡。\n \n2.\t蟲害：在台灣會引起枝枯現象的蟲害種類有蛀心蟲、紅蜘蛛及地下害蟲等。蛀心蟲的危害狀與茶枝枯病在田間的病徵完全相同，罹病（蟲）枝條急速枯死，枯葉仍留在枝條上。紅蜘蛛中的錫蘭偽葉蹣蟲體喜聚集在成葉、老葉或葉柄的部份，造成茶樹嚴重的落葉。茶園施用不當的覆蓋材料或腐熟不完全的堆肥，帶來許多地下害蟲，常見者有蠐螬，蠐螬是金龜子之幼蟲，危害茶樹的根及地基部，先是取食地際部之皮層，繼而危害木質部及根部，若被環食一圈，有若環狀剝皮一般，茶樹的水份輸送受阻，全株將萎凋枯死。\n(二)天候因素引起的枝枯\n　　植物的生長易受氣象的影響，溫度與水份是其中重要的因子，茶樹全年需水量應為1,100~1,300公釐，氣溫在30℃~35℃時光合作用速率達最高，42℃則停止；土壤最適含水量為70-90％。雖說茶樹對環境的忍耐力很強，但若乾旱、酷寒、雷電、強風、暴雨等天然災害過烈，茶樹仍無法承受。台灣常見的天然災害有颱風、乾旱、澇害或焚風等，夏季常發生颱風，帶來強風、暴雨使茶樹枝葉折斷、土壤浸水、土石流失、甚至連根拔起；萌芽期的茶園，僅颱風的風力就足以造成芽葉受損，產量下降，有時需要一季的時間才能恢復。焚風的高溫低濕造成茶樹的乾熱傷害，症狀為嫩芽焦枯、葉緣有褐色斑塊、嫩枝條會枯萎。澇害是植株根部長期浸水，如長期下雨、地下水位上升、排水不良等，造成根部附近的土壤長期處於缺氧的狀態，其症狀為嫩芽褐化、落花、落果、葉色失去光澤，後期有落葉的情形。台灣夏季若降雨不調順，作物有發生旱害的危險，茶樹旱害的症狀是嫩葉枯萎、焦枯、落花、落果、葉色失去光澤，細胞因缺水而失去膨壓，全株葉片癱軟而下垂，根系因缺水而褐化，若缺水狀況達永久萎凋點，植株終將枯死，造成茶園嚴重缺株。\n(三)人為耕作不當引起的枝枯\n　　進行茶園耕作包括施肥、噴藥、修剪、採茶、耕犁等農事時，機械保養或使用不當，常傷到茶樹，造成機械性的枝枯。施用肥料、農藥或殺草劑時，濃度太高、 施藥過量、施藥時機不當或使用腐熟不完全的堆肥，都可能造成茶樹發生藥害（肥害），嚴重者有全株枯萎的情形發生。\n三、枝枯症狀的比較及原因的判斷\n　　各種枝枯原因，除了枝枯的症狀外，就茶樹其它部位所呈現出的症狀、病程進展快慢、田間發生狀況或發生時期，整理後列於表1，茶園如發生枝枯問題，可參照本表再綜合當時的天候及環境，即可做出最正確的判斷。舉以下三例說明。\n(一)蛀心蟲與茶枝枯病之區分\n　　蛀心蟲引起的症狀與茶枝枯病，幾乎完全一樣，差異之處為在莖的一側可見到小洞，洞旁遺留細碎木屑（蟲便），輕敲枝條有中空的感覺，蟲蛀枝條輕、脆、易斷，折斷後的枝條中空，有時可見小蟲鑽行其中。而枝枯病危害的枝條，失水下垂，罹病枝上有紡錘型的潰瘍病斑，病斑上有黑色細小的柄子器，病程進展緩慢，多發生於炎熱乾旱的夏季。\n(二)乾旱與茶枝枯病之區分\n　　旱害與茶枝枯病都會發生枝枯的現象，其差別為旱害造成的枝枯是全株性的，枯枝發生的情形是由外往內，由上往下發展；而被M. theicola感染的枝枯病茶樹，枝枯僅發生在罹病的枝條上，並可在病枝上分離出病原菌。\n(三)病蟲害與天然災害枝枯的區別\n　　旱害、熱傷害、澇害等天然災害引起全株性的症狀，芽葉變小、落葉、生長停滯或立枯等，田間發生的情形是區域性的全面發生，不具傳染性。病蟲害引起的枝枯（根部病蟲害除外）是局部性的，田間是點狀發生，具傳染性，病害進展緩慢。\n四、結論\n　　茶樹發生枝枯原因非常複雜，可能是因病而弱，也可能因弱而病，找出正確的致病因子，才能做適當的處理，60％以上的枝枯症狀，都不是由病蟲所引起，一味的噴藥，不僅全無效果，而且容易發生農藥殘留的問題，不可不慎；茶園發生問題時，不應急著噴藥，而是先找出問題真正的原因。\n　　枝枯原因複雜，是多種因子相互影響的結果，防治的方法應多管齊下，包括適當的栽培方式、適地性天然災害防治策略的研議以及正確病蟲害防治觀念的建立等。\n"}, "1680084305.0999362": {"單位": "", "標題": "茶枝枯病有無防治策略？", "作者": "", "發布日": 0, "摘要": "", "全文": "從枝枯病在田間發生之生態，本病防治方式有下列三種策略：\n\n1.預防枝枯病的侵入\n\n　（1）帶病菌之茶苗是本病可能的傳播方式之一，因此對新植或補植的茶苗，其扦插枝條應採自無枝枯病發生的茶園。\n\n　（2）未發生本病的茶園應做好茶園肥培管理工作，包括合理化化學肥料施用（過與不及的施肥量，均不利茶樹的生育）及適當的耕作方式。管理良好的茶\n　　　  園，茶樹樹勢強壯、發育良好，對枝枯病具有相當的抵抗性。\n\n　（3）夏季若遇乾旱，應實施人工灌水。\n\n　（4）避免種植感病品種。\n\n2.已發病的茶園應做好清除病枝條的工作\n\n　剪除病枝是防治茶枝枯病最有效的方法，依據枝枯病在茶樹上發生部位，可將病害嚴重的程度區分為輕度、中度及重度三個等級：\n\n　（1）一級（輕度）：感染點在一年生的枝條，對整叢茶樹影響不大。\n\n　（2）二級（中度）：枝枯病發生於二年生以上較粗的枝條，若發病時，罹病枝上的枝條都會枯死，枯死面積可達整叢的五分之一以上。\n\n　（3）三級（重度）：枝枯病發病部位在茶叢主幹、地際部或深入主根，發病時枯 死面積可達全叢枝葉的三分之一以上，甚至全株死亡。\n\n依據以上三級嚴重程度，可採取不同的防治措施，敘述如下：\n\n　（1）輕度及中度危害時，隨時剪除病枝。\n\n　（2）重度危害時，實施台刈及清除罹病處後再噴藥。\n\n　（3）剪除或挖除之病枝條必須集中燒燬，不可散置於茶園中，以免病菌之傳播。\n\n3.病園在冬季應進行至少一次的剪枝、清園及噴藥工作。經常發病的青心烏龍茶園，在冬季時應進行一次以上的剪枝、清園及噴藥的工作，以清除病原菌。冬\n　季氣溫低，茶樹進入休眠期，病原菌也停止活動，是進行清園的最佳時期。冬季時枝枯病枯死的枝條仍然會留在茶園中，很容易辨認，將此等殘留且帶病原\n　的枝條依本文所敘述的方法剪除燒燬，並馬上噴藥。次年，枝枯病將可受到良好控制。"}, "1680084335.0495937": {"單位": "", "標題": "茶枝枯病如何鑑定？", "作者": "", "發布日": 0, "摘要": "", "全文": "茶枝枯病的病徵有二種：\n枝枯型（die- back）－感染點以上的枝條枯死，葉片留在枝條上（因茶樹是急速萎凋狀）。\n潰瘍型（canker）－受感染的枝條上形成癒傷組織，同一枝條可能有一個或數個，癒傷組織可以很大也可以很小。\n\n簡易鑑定方法如下：\n枯死的枝條或枝條潰瘍的皮層較健康枝條為粗糙、鬆軟，剝去皮層可見到許多細小、黑色的胞腔，濕度高時可泌出白色的胞子團（或線狀），遇水則散開來，內含成千上萬的分生胞子，否則乾燥後則成淡黃色小點。這些都可由肉眼觀察到。\n利用小刀輕刮皮層健康枝條為綠色，罹病枝為褐色。"}, "1680161930.88986": {"單位": "", "標題": "稻熱病", "作者": "", "發布日": 0, "摘要": "", "全文": "一、前言 \n稻米為我國的主要糧食作物，但在水稻栽培過程中，常遭稻熱病危害。在第一期作葉稻熱病發生面積佔稻總栽培面積的十分之一以上。第二期作葉稻熱病雖較少發生，但在水稻生育後期仍常發生穗稻熱病。中國大陸稱稻熱病為稻瘟，早在1637年於「天工開物卷」上即有記載；日本在1704 年已有報告；此後，在義大利、美國、印度等相繼報告出現。目前稻熱病幾乎分布所有稻米產區。\n二、病徵\n稻熱病會感染水稻的各個生育期，侵害各個部位。秧苗期稻熱病主要發生於葉片及葉鞘，此時稻組織較嫩易感病。稻熱病菌感染後，初期呈墨綠色或灰綠色，隨後轉為急速型之白色病斑，病斑迅速擴展，引起葉片甚至全株秧苗枯死。\n本田期水稻之稻熱病主要包括：葉稻熱病、葉舌稻熱病、節稻熱病及穗稻熱病。葉稻熱病之病斑順著葉脈擴展，圓形至紡錘形、兩端較尖，初期墨綠色或灰綠色，急速型病斑為白色，病斑上有大量病原菌孢子，後期病斑邊緣呈褐色或深褐色，中間灰白，病斑邊緣黃暈不明顯。稻熱病較少危害本田期水稻葉鞘，但會感染葉舌及葉節稱之為葉舌稻熱病。稻熱病菌感染葉舌後再擴展至葉節引起臨近葉片及葉鞘組織褐變乾枯萎凋死亡。節稻熱病發生於抽穗後之水稻，莖節褐變或黑變嚴重時稻莖枯死易折斷。葉鞘外側無明顯病徵，葉鞘內側表面則常有褐變現象，莖節上有大量病菌孢子。穗稻熱病包括穗頸、枝梗及穀粒稻熱病，穗頸及枝梗被害時，初呈灰綠色水浸狀病斑，病斑邊緣轉為深褐色，被害部位以上的枝梗及穀粒枯死。穀粒被害，呈暗褐色圓形或橢圓形病斑。三、病原菌概述\n（一）分類地位\nAscomycetes 子囊菌亞綱\n近似 Phyllachorales黑痣菌目\nMagnaporthaceae\nMagnaporthe\n（二）分布\n稻熱病分布於所有稻米產區，含括中國大陸、臺灣、日本、菲律賓、印度、義大利、美國、巴西等國。\n（三）寄主\n水稻、大麥、稗草、小穎羊芋、甘蔗、李氏禾、蘆竹、玉米、馬唐草、狗尾草、牛筋草、象草、巴拉草、拉拉草、葡黍草及茭白筍等。\n(四)型態\n分生孢子之形狀及大小因各學者之報告而有差異，同時亦因寄主植物或培養基不同而不同。一般而言，分生孢子有二個隔膜，梨形，基部圓形，頂端狹小，無色或淡褐色，大小為 20~22 × l0~12µm或19~23×7-9µm。\n(五)診斷技術\n1.苗稻熱病：發生在苗期，在幼苗的葉片上初呈灰綠色的小斑點，嚴重時葉片變成黃褐色而枯死。\n2.葉稻熱病：在葉片上初呈暗綠色小斑點，斑點擴大後成圓形或紡錘形，有時兩個以上的病斑互相融合，而形成不規則形之大病斑，後期葉片呈枯死狀。\n3.節稻熱病：被害節初呈暗褐色，後變為黑色，且乾縮凹陷。被害節易折斷。\n4.葉舌稻熱病：位於葉與葉鞘鄰接的位置，呈褐色。\n5.穗稻熱病：在穗頸、枝梗、穀粒及護穎等部位危害，被害部位呈褐色、暗褐色或暗黑色。\n（六）生活史\n稻熱病之初次感染源自前期作田間之罹病稻 ，病原菌在罹病之稻叢上越冬，當第一期稻生長環境適宜病原菌生長時，即產生分生孢子，靠風傳播到葉片上，經發芽、侵入潛伏，而後出現病斑，由病斑產生大量的分生孢子，再重複感染水稻，如此短期間內多次的重複侵入感染，完成多次的病害環，最後造成流行病。\n四、發生生態\n稻熱病菌分生孢子發芽時，需要水膜及幾近飽和的相對濕度。溫度20~32℃及高\n濕度環境下，分生孢子掉落在稻體後3小\n時，孢子發芽率高達80％以上。分生孢子\n發芽產生發芽管，發芽管先端形成附著器\n（appressorium），形成附著器之溫度範圍為\n12~36℃之間，而以16~24℃最適合。附著\n器會緊密附著於表皮，再產生侵入釘穿入\n組織中， 溫度20~28℃範圍內，最適宜稻熱\n病菌的侵入，部分孢子從掉落稻體到完成\n侵入只需6小時。\n稻熱病菌侵入組織後，以菌絲體在稻組織中生長蔓延，菌絲吸取稻組織的養分繁殖。經2~3日的時間，菌絲體開始形成分生孢子梗，並由稻表皮組織伸出，分生孢子梗生長4小時後，開始產生分生孢子，孢子經50~90分鐘成熟，成熟孢子脫離孢子梗為田間第二次感染源。利用人工接種，發現稻熱病菌孢子從感染稻組織到再形成分生孢子，所需時間約4~5日。稻熱病菌感染水稻的週期短，病斑上的孢子多，病菌的散佈很快，所以容易成為流行病。利用孢子採集器在田間收集孢子時，顯示在水稻生育期間所採集的孢子數，以發病較嚴重的地點較多。分生孢子在東部地區從四月至十一月，北部地區從四月至十月，南部地區從三月至十月均可採集到，但以三月至六月所採集到的較多。在一天當中，分生孢子採集數在夜間到清晨數目最多，白天數目較少，但是若逢連續陰雨，日照不足時，在白天所收集到的分生孢子則會比夜晚多。通常小雨過後空中的孢子多，大雨後空中的孢子反而很少。在稻熱病發生期間，降雨日數越多，發病越嚴重。\n將病斑上所釋放的孢子做成懸浮液，無論置於載玻片或3∼4週稻齡之葉片上，溫度12~36℃範圍內均可發芽，尤其在切葉上發芽率最好，在溫度16~32℃之環境下保持6小時，發芽率可達90％以上。附著器之形成在溫度16~24℃最適合，28℃次之，而36℃只有極少數的孢子可以形成附著器。測試溫度對病原菌侵入葉片之影響，發現在溫度20~28℃下接種6小時，本菌即可侵入寄主；32℃則8小時才能侵入；16℃需10小時；12℃需24小時始能侵入。而在相對濕度93~100％持續6~8小時，可促進孢子之產生與釋放。在露水方面，於24℃條件下，下午7時開始結露，而孢子若在下午7時開始著落於葉面，則第2天上午露水消失時，孢子在露水中的時間有 12 小時，其侵入率約為 50％；若露水延後至上午10時才消失，則孢子在露水中達15小時，則侵入率增加到80％，而孢子若在清晨1時著落於葉面，則到7時露水消失時，孢子接觸露水時間只有6小時，其侵入率只有1％左右，露水延長3小時，則侵入率可達約15％。清晨常為孢子釋放高峰之前期，而高峰時或高峰後期所釋放之孢子，就可能因為結露時間不足，而不能有效侵入稻體，以致喪失活力。在山谷地區之稻田，位於東邊者，因上午受陽光照射時間較遲，下午陽光消失亦較慢，則發病中等；位於西邊者，早上暴露在陽光下較早，下午陽光也較早消失，發病較輕微。而位於谷中之稻田，上午暴露在陽光下較遲，下午也提早失去陽光，露水存在的時間較長，所以山谷發病常較為嚴重。\n五、防治方法\n（一）目前在臺灣已經利用疫情偵測監側方式來進行稻熱病的防治管理，可預告是否需要施藥、施藥次數及施藥時期。而實施藥劑防治，請參閱植物保護手冊選擇藥劑施用。\n（二）增加行株距，稻株比較健壯比較抗病，縱然發病也能比較耐病；插秧行向採用與季節風同向，田間通風良好，可降低稻熱病的蔓延速率。合理施肥，多施鉀肥少氮肥，並可用含矽肥料當土壤改良劑作基肥施用；保持田間灌溉水流通，增強稻株對病害的抵抗力。稻熱病的初次感染源主要來自病稻穀及病稻草。稻種消毒可阻斷稻種傳播稻熱病，病稻草則要注意田間衛生，不能留置病稻草在田間。\n（三）利用螢光菌（Pseudomonas fluorescens）防治。\n（四）近年來新育成的水稻新品種對於稻熱病的抗性已有顯著的進步。對於稻熱\n病之危害，穩定稻米生產頗有貢獻，但 稻之抗性仍不及秈稻，而目前秈稻之栽培面積只佔水稻總面積之10％左右，使秈稻之優良抗性無法充分發揮，頗為可惜。因為加強 稻抗稻熱病之選育工作實為當務之急。"}, "1680163004.4843082": {"單位": "", "標題": "稻熱病", "作者": "", "發布日": 0, "摘要": "", "全文": "學名：Pyricularia grisea(Cooke) Sacc.\n英名：Rice blast\n病徵：\n葉稻熱病：發病初期先於葉面上形成褐色或暗綠色小斑點，如環境適合，擴大成紡錘形。此時病斑周圍呈黃色，中間赤褐色，內部灰白色。嚴重時葉片枯萎甚至全株枯死。\n穗稻熱病：發生於穗頸、枝梗及穀粒上之稻熱病統稱為穗稻熱病。一般穗頸及枝梗上病斑呈淡褐色或暗褐色，穀粒之病斑則為暗灰色或白色。發病後穀粒不充實或為不稔粒。\n節稻熱病：稻莖節呈暗褐色，容易折斷，且上部逐漸枯死，通常在水稻抽穗後較易發現。\n葉舌稻熱病：發生在葉鞘與葉鄰接位置呈褐色。\n發生誘因：\n溫度：溫度高低不定之環境下，會減低稻的抵抗力，容易引起稻熱病的發生。\n濕度：病原菌產生孢子與孢子發芽，以及發芽之後侵入稻體組織，需要高的濕度（RH90％以上），所以雨、露水與發病有密切的關係。\n肥料：多施氮肥會減低稻的抵抗力，發生時不可施用氮肥，以免加劇及蔓延。維持三要素之適當比率，可減輕發生。\n傳播途徑：病原於被害稻藳或穀粒越冬，翌年病斑上之孢子隨氣流或風力傳播為第一次傳染源。\n防治方法：\n1.栽植抗病品種\n品 種   抗病程度 葉稻熱病 穗稻熱病   適 應 地 區 備 註 \n臺 南 5 號 感 感 全 省 抗病程度分為六級\n臺 南 9 號 中抗－中感 極感 全 省\n臺南秈15號 抗 中抗 嘉 南 地 區\n高 雄141號 中抗 中抗 嘉南、高屏地區\n高 雄142號 抗 中抗\n高雄秈 7號 抗 高 屏 地 區\n臺 農 67號 感 中感 全 省\n臺 農 68號 中抗 中抗 全 省\n臺 農 70號 極感 極感 全 省\n臺 農 72號 感 感 中 南 部\n臺農秈12號 中抗 中抗 臺北、臺南地區\n臺農秈14號 抗 中抗 嘉 南 地 區\n臺農秈18號 抗 中抗 全 省\n臺農秈19號 抗 抗 全 省\n臺農秈糯2號 抗 中抗 中 南 部\n臺中 189號\n臺中秈 3號 中抗 中抗 中 南 部\n臺中秈10號 中抗 中抗 桃園以南至中南部地區\n臺中秈17號 中抗 中抗 中 南 部\n臺中糯70號 感 感 全 省\n臺中秈糯1號 抗 抗 中 南 部\n臺 東29號 抗 臺東、花蓮地區\n新 竹64號 感 感 新 竹 地 區\n豐 錦 感 極感 中 北 部 地 區\n臺農秈20號 抗 抗 中 南 部\n臺 中190號 中抗 中抗 臺 中 地 區 \n\n2.育苗箱秧苗處理:4%加普胺粒劑(Carpropamid)30公克 插秧前1天均勻撒佈，並以掃把輕掃秧苗，使藥劑掉落，再以澆水器澆水，每箱500公撮。限育苗箱使用。40%亞賜圃 可濕性粉劑(Isoprothiolane)20公克 25 秧苗綠化初期稀釋水量500 公撮，以澆水器均勻灑在育苗箱內。75%三賽唑 可濕性粉劑(Tricyclazole)2公克 插秧前1天實施，稀釋水量為200~500公撮，以澆水器均勻灑在育苗箱內。8%三賽唑粒劑(Tricyclazole)40公克 插秧前1天均勻撒佈，以掃把輕掃秧苗，使藥劑掉落，再以澆水器灑水，每箱約150公撮。4%撲殺熱粒劑(Probenazole)40公克 插秧前1天實施，以手均勻撒佈，並以掃把輕掃秧苗，使藥劑掉落，再以澆水器澆水，每箱約20公撮。\n3.水田秧苗處理（葉稻熱病）:3%三賽唑粒劑(Tricyclazole)50公克 插秧前1天，無露水時均勻撒佈，並以竹竿輕掃秧苗，使藥粒掉落土面。施藥前秧田應保持濕潤。\n4.超低容量地面撒佈:3%嘉賜黴素 超低容量劑(Kasugamycin)1 公升 1.使用迴轉數以每分鐘5,000轉以上(噴風量每分鐘7~12立方公尺)之動力微粒噴霧機，於 噴 嘴 上 加 裝 孔 徑0.7公厘之流量控制器，以調節流量。如欲改進噴霧之均勻度，可更換噴霧機之藥箱為「加壓藥箱」。2.噴藥前事先調節動力微粒噴霧機開關，以最大噴速，試將0.1公升原液全部均勻噴完0.1公頃稻株，再行大面積噴藥。1.採收前14天停止施藥。2.噴藥時避免強烈陽光、上昇氣流及有風時間。3.噴藥時，必須順風噴射\n人行方向與風向成直角，噴槍保持水平，勿使藥液直接噴到作物上。其有效射程約為7~8公尺，噴射行走速度，每分鐘約40~70公尺。50%護粒松 超低容量劑\n(Edifenphos)1 公升 採收前21天停止施藥。\n5.空中施藥防治稻熱病穗稻熱病：\n一、3%嘉賜黴素 超低容量劑(Kasugamycin)1 公升 1.於抽穗前7天施藥一次，齊穗期再施藥一次。2.８平方公分內，應有直徑1,000μ以下之落藥點36點以上。採收前14天停止施。\n二、75%三賽唑 可濕性粉劑(Tricyciazole)0.4公斤加水15公升。 1.孕穗期前2天施藥一次。2.８平方公分內，應有直徑1000μ以下之落藥點112點以上。採收前25天停止施藥。\n三、80%鋅錳乃浦 可濕性粉劑(Mancozeb)2 公斤加水至20公升 1.抽穗前7天施藥一次，齊穗期再施藥一次2.８平方公分內，應有直徑1000μ以下之落藥點114點以上。1.本藥劑試驗時加展著劑「出來通CS－7」2,000倍液(即每公頃10公撮)。2.藥劑先以半量水稀釋，再行加入該展著劑，以避免混合不均。\n四、35%護粒丹 可濕性粉劑(Edifenphos +Phthalide)1.5 公斤加水至15 公升 1.抽穗前7天施藥一次，齊穗期再施藥一次。2.８平方公分內，應有直徑1000μ以下之落藥點144點以上。採收前28天停止施藥。\n五、20%熱必斯 水懸劑(Phthalide)1.5 公升加水至20公升 1.抽穗前7天施藥一次，齊穗期再施藥一次。2.８平方公分內，應有直徑1000μ以下之落藥點144點以上。採收前28天停止施藥。\n六、20%熱必斯 水懸劑(Phthalide)4 公升加水至15公升 1.抽穗前7天施藥一次。2.８平方公分內，應有直徑1000μ以下之落藥點144點以上。採收前30天停止施藥。\n7.種子處理（葉稻熱病）：200g/L亞汰尼，種子處理用水懸劑(Isotianil)，每公斤稻種10毫升稻種預先浸水催芽，至萌芽時，藥劑加5毫升水混拌均勻。具呼吸中等毒性、皮膚過敏性。"}, "1680163052.8716238": {"單位": "", "標題": "「水稻葉稻熱病發生警報」-氣候條件適合水稻葉稻熱病發生與蔓延，籲請農民及時防治", "作者": "", "發布日": 0, "摘要": "", "全文": "中華民國107年4月2日\n彰化、南投及臺中等縣市早植水稻已陸續進入分蘗終止期，經調查發現特定通風較差的田區水稻葉片出現葉稻熱病病斑，復以近來夜間溫度維持20℃以上，且晨間露水殘留時間延長，極適合葉稻熱病的發生與蔓延。行政院農業委員會臺中區農業改良場呼籲農民注意葉稻熱病的防治工作，以避免對水稻生產造成為害。\n\n臺中區農業改良場表示，預防重於治療是防治水稻葉稻熱病的不二法門。中部地區葉稻熱病通常在3月下旬至4月間發生，當水稻葉片或秧砧稻苗葉片出現初期感染型病斑，農民應即刻進行預防性施藥，可有效避免葉稻熱病對水稻的危害。\n\n該場副研究員廖君達表示，葉稻熱病發病初期先於葉面上形成褐色或暗綠色小斑點，如環境適合則擴大成紡錘形。農民可選用下列藥劑進行防治，包括6%撲殺熱粒劑、75%三賽唑可濕性粉劑3,000倍、40%亞賜圃乳劑1,000倍、20%嘉賜三賽唑可濕性粉劑 1,500倍、15%加普胺水懸劑2,000倍、50%護粒松乳劑1,000倍或20%芬諾尼水懸劑1,500倍等。"}, "1680163810.2102597": {"單位": "", "標題": "茶網餅病", "作者": "", "發布日": 0, "摘要": "", "全文": "病原菌學名：有性世代Exobasidium reticulatum Ito & Sawada\n英名： Japanese blister blight 丶Net bilster blight\n一丶前言\n茶樹網餅病最早由Sawada (1912) 發現。發生嚴重時下一期產量將減產30 - 50%\n之鉅，管理不週的茶園全年皆發生。\n二丶病徵\n茶網餅病在葉片上初期病斑為黃綠色小點，約0.2 - 0.3 公分，對光看為透明小點，可見不明顯淺綠色網紋，此時尚未形成白色子實層，慢慢擴大，淺綠色網紋漸漸擴大，上有稀疏的白色粉狀物，子實層越長越密，肉眼可見一層白色網狀物，因沿葉脈生長故成網紋狀，病斑進展很慢 。病害後期，氣溫漸漸變上升，罹病葉片枯黃，最後焦黑的掛在樹枝上，罹病枝條不萌芽或萌芽率降底，致使春茶產量下降。\n三丶病原菌概述\n（一）分類地位\nUstilaginomycetes (黑粉菌綱)\nExobasidales (壞損外擔菌目）\nExobasidiaceae (壞損外擔菌屬）\nExobasidium reticulatum\n（二）分布日本、中國及臺灣。\n（三）寄主茶樹。\n（四）形態:擔孢子橢圓形至卵圓形，無色，單孢大小為9 - 12 X 3 - 3.5μm ; 自然形成的擔孢子則為圓筒狀至棍棒狀，大小為100 - 130 X 3 -4μm 。\n（五）診斷技術:葉片上初期病斑為黃綠色小點，可見不明顯淺綠色網紋，淺綠色網紋漸漸擴大，上有稀疏的白色粉狀物，子實層越長越密，肉眼可見一層白色網狀物，因沿葉脈生長故成網紋狀，病斑進展很慢。\n（六）生活史\n茶網餅病菌之生活史與茶餅病菌類似。\n四、發生生態\n在臺灣主要發生於1-5 月，魚池地區發生盛期為8 - 11 月，鹿谷地區生盛期為7 -10月。影響茶餅病與茶網餅病發生的氣候因素相似，因此臺灣發生網餅病的茶園，大都能發現茶餅病，但因茶網餅病斑生長緩慢，雖然在老葉發現網餅病，實際上在其幼葉期即已受侵染，其潛伏期約為30 天，且經60 - 70天後才出現網狀病斑；臺灣田間以青心烏龍品種最感病。在日本茶網餅病發生於各主要茶區，除冬季12 - 3 月無發生外，其他各月份皆發生嚴重；日本的主要栽培品種Yab血ta及Benihomare 均非常感病。擔孢子發芽最適溫度為22 °C, 溼度100% , pH5.5 ; 形成最適溫度為1 9 - 25°C , 溼度為100 % , 暴露於乾燥環境或太陽下，短時間內將失去發芽能力。\n五丶防治方法\n目前臺灣尚無防治藥劑推薦，在發病嚴重地區，請勿種植感病品種青心烏龍。"}, "1680163951.375376": {"單位": "", "標題": "茶餅病", "作者": "", "發布日": 0, "摘要": "", "全文": "茶餅病和網餅病發生的情形，常在高濕度的季節和區域發生。 以季節而言，如梅雨期或連續的春雨，在此氣候條件下，平地或山區都容易發病，而位於高海拔山區的茶園，另外在秋末冬初時期，山區雲霧迷漫，濕度過大，仍為一個易發病的時期。 此類病害的防治，必須維持茶園良好的通風性，以及在發病初期即時噴施藥劑防治，才能有效控制疫情。"}, "1680164207.4661925": {"單位": "", "標題": "茶餅病", "作者": "", "發布日": 0, "摘要": "", "全文": "學名：Exobasidium vexans Mass.\n英名：Blister blight\n病徵：\n茶餅病主要危害嫩葉或嫩芽，有時也感染嫩枝條。葉部初期病徵為淡綠、淡黃或淡紅色透明小點，逐漸擴大為圓形。病斑表面為肉色、紅色或紅褐色；背面細胞快速增生，最外層著生白色子實層。因此茶餅病的病斑形態為向內凹陷的肉質性圓形病斑，一片葉子可形成一至十幾個的病斑。嫩枝條的徵狀與葉部病徵相同。\n傳播途徑：本病的傳染源為擔孢子，擔孢子易附著在採茶器械或採茶者之衣物、手指等處。\n防治方法：\n1.病區採茶之人員或剪枝器械，嚴禁再去採、剪健區茶園之茶樹。\n2.避免發病盛期剪枝。\n3.藥劑防治：任選下表一種藥劑防治\n11.8%護汰芬水懸劑(Flutriafol)0.5公升 2,000 發病初期施藥，每隔7-10天施藥一次，連續二次。1.採收前21天停止施藥。2.具口服中至輕毒性、呼吸中等毒性及嚴重眼刺激性。\n25%三泰芬可濕性粉劑(Triadimefon)0.5公斤 2,000 發病初期，每隔10天施藥一次，連續二次。1.採收前15天停止施藥。2.具呼吸中等毒。\n23.6%百克敏乳劑(Pyraclostrobin)0.33公升 3,000 萌芽初期病害發生時施藥，每隔10天施藥一次，連續二次。1.採收前21天停止施藥。2.具中等口服、呼吸急毒性，中度眼刺激性、皮膚刺激性。3.對水生物具毒性，勿使用於「飲用水水源水質保護區」及「飲用水取水口一定距離內之地區」。\n15%易胺座 可濕性粉劑(Imibenconazole)0.5公斤 2,000 發病初期，每隔7天施藥一次，連續二次。1.採收前9天停止施藥。2.試驗時加展著劑“LATRON CS-7”4000倍。3.具中度眼刺激性；中度皮膚過敏性；對水生物中等毒，勿使用於「飲用水水源水質保護區」及「飲用水取水口一定距離內之地區」。\n4.使用後可能造成異味殘留。30%賽福座 可濕性粉劑(Triflumizole)0.5公斤 2,000 發病初期，每隔10天施藥一次，連續三次。1.試驗時加展著劑「組展」3000倍。2.採收前6天停止施藥。3.對眼具中度刺激性，皮膚敏感性。\n84.2%三得芬乳劑(Tridemorph)0.5公升 2,000 發病初期，每隔10天施藥一次，連續三次。採收前21天停止施藥。"}, "1680164507.8666246": {"單位": "", "標題": "茶樹網餅病", "作者": "", "發布日": 0, "摘要": "", "全文": "(四) 茶網餅病（Japanese blister blight 或 Net blister blight）\n1、病徵及發生生態\n初期病斑為黃綠色小點 2~3 公釐，對光看為透明小點，慢慢擴大，上有稀疏的白色粉狀物，子實層越長越密，肉眼可見到白色網狀物，因沿葉脈生長，故成網紋狀，其生態與茶餅病很類似，有茶餅病發生之茶園大多能發現茶網餅病，但茶網餅病病斑生長緩慢，網餅病雖然在老葉發現，實際上其在幼葉期即以受侵入，潛伏期約為 30 天，且經 60～70 天後才出現網紋狀病斑。\n品種間之抗病性差異很大，青心烏龍是極感病的品種。\n2、病原菌：Exobasidium reticulatum Ito et Sawada\n3、管理策略：\n目前尚無推薦防治藥劑，可參考餅病之管理策略，發病嚴重地\n區，建議種植抗病的品種。"}, "1680165537.3306775": {"單位": "", "標題": "稻熱病發生生態與防治方法", "作者": "", "發布日": 0, "摘要": "", "全文": "前言:\n水稻為我國主要糧食作物，苗栗區水稻一年栽植兩期作，種植面積2 萬餘公頃，稻穀產量10,711公頃，產值20億元。水稻生長期間高溫多濕，適合各種病蟲害滋生蔓延。因病蟲為害，稻穀產量損失，第一期作由1.6%至 40.2％，平均15.4％。第二期作由3.1%至90.2%，平均29.9％。本區農民多為老齡農民、兼業農民，平常較疏於防治。長久以來第一期作稻熱 病發生防治即是棘手問題，亦是被限制稻穀高產的重要因素，本（九十）年第一期稻作於四月下旬，全台稻熱病陸續發生，面積高達9,000餘公頃，本轄區內發 生750公頃，局部嚴重，普遍輕微，勢必造成抽穗開花成熟期不一致，影響米質及產量甚鉅。\n發生生態:\n台灣稻熱病在第一期作發生嚴重，為稻病害中最重要者，於第一期水稻之秧田末期至本田初期（分蘗期），連續陰雨，日照不足，為本病原菌最適繁殖及感染之條件， 而此期水稻因低溫，日照不足，生育不良，抗病力降低，病害即發生嚴重，並迅速蔓延。又如氮肥或綠肥施用過量，追肥期太遲，冷水灌溉或山間水田地溫較低，播 種量過多，插秧過密或過晚，乾旱，暴風以及偏用速效氮肥或砂質土壤等，皆為誘發稻熱病之猖獗因子。\n稻熱病菌感染水稻及產孢需要有水膜及幾近飽和之相對濕度，最適溫度為24～28℃。生長於20℃之稻比生長於24～30℃者感病。水溫較氣溫高時稻株較易感病。分蘗盛期後之稻株對葉稻熱病抗性增加，台灣梅雨期早來易發生葉稻熱病，晚來則較易發生穗稻熱病。\n防治方法:1.種植抗病品種，但台灣之稻熱病原菌有生理小種之存在，故對抗病育種或選取品種時，應考慮病原菌生理小種之問題。抗病品種之交互種植亦需考慮。\n2.注意田間衛生，被害稻稈不可堆積散亂田間，並勿施用過量氮肥。\n3.稻種消毒：選種後用下列之藥劑中任選一種，經數小時浸種，並時予攪動（或搖動）經洗淨再浸種催芽。50％免賴得（benomyl）可溼性粉劑或40％免賴得（benomyl + thiram）可溼性粉劑1,000倍液，浸種4～12小時或以41.8％腐絕（thiabendazole）水懸劑或40％腐絕可溼性粉劑2,000倍液，浸種1～6小時。\n4.藥劑防治：(1)育苗箱秧苗處理（主要防治葉稻熱病）：以8％三賽唑（tricyclazole）粒劑每箱施用藥量40公克或4％撲殺熱（porbenazole）粒劑每箱施用藥量40公克或75％三賽唑可溼性粉劑每箱施用藥量2公克等任選一種施用之。\n(2)水田秧苗處理（主要防治葉稻熱病）：以3％三賽唑粒劑，每平方公尺施藥量50公克均勻撒佈，施藥前秧田應保持濕潤。\n(3) 本田部份：第一期作較易發生，田間如有葉稻熱病初發生時，即施藥一次，七天後再施藥一次，並再於抽穗前7天左右及齊穗期各施藥一次，以預防穗稻熱病發生。 目前推荐效果較優藥劑有：6％撲殺熱粒劑，每公頃每次用量藥30公斤。75％三賽唑可溼性粉劑3,000倍液，20％嘉賜三賽唑可溼性粉劑1,500倍 液，50％護粒三賽唑可溼性粉劑1,500倍液，等任選一種防治。"}, "1680165991.9405708": {"單位": "", "標題": "稻熱病管理", "作者": "", "發布日": 0, "摘要": "", "全文": "台灣一期稻作容易遭受稻熱病危害，尤其是穗及穗頸稻熱病更可造成水稻嚴重減產。在防治管理上除了在適當時機施藥預防之外，合理施肥、減少插秧枝數，以及增加行株距也是重要的管理手段。\n稻熱病危害部位及病徵:稻熱病菌可危害葉片、莖節及葉舌，在抽穗期及結穗期還可造成穗頸及穀粒的稻熱病，防治不慎時常會造成嚴重損害。本病在發病初期於葉面上形成褐色或暗綠色小斑點，若環境適合病勢進展，則擴大呈紡錘型。病斑周圍呈黃色，中間灰褐色，嚴重時葉片枯萎，如感染穗頸或稻穗則造成榖粒不充實。稻熱病孢子會在水稻抽穗前，隨著雨露掉落在劍葉葉舌及葉節上，當稻穗抽出時接觸孢子而被感染。罹病初期，在穗頸與枝梗上的病斑呈淡褐色或暗褐色，嚴重時整穗彎折乾枯，俗稱「吊穗」或「吊狗」。穀粒受感染時，病斑則呈暗灰色或白色，發病嚴重時穀粒無法充實或不稔，俗稱「空包彈」。相對溼度高於90%以上時容易發病，溫度高低變化劇烈，易減低水稻的抵抗力使病害更加嚴重。\n感病時期:水稻插秧後35至45天最容易遭受感染葉稻熱病。高屏地區一般於每年1月下旬～2月上旬之間插秧，2月下旬～3月上旬為水稻分蘗盛期，正值日夜溫差大且濕度高的春天氣候，葉稻熱病常於此時大量發生。4月～5月的孕穗期及抽穗期間又即將進入陰晴不定的多雨時節，其氣候適合穗稻熱病發生，穗頸及稻穗一旦罹病，常造成稻穗白化乾枯而減產。如果管理上施用高量氮肥、密植且通風不良之稻田更容易發生。\n防治方法:\n一、為降低稻熱病發生風險，應從整個栽培\n管理著手:\n(一)選用較具抗稻熱病特性品種：如高雄145號等，將可避免病害嚴重發生。\n(二)插秧時避免密植：每叢約5～7株即可，且種植時應增加行株距，將可使田間通風性佳，降低稻熱病及其它病蟲害發生風險。\n(三)控制氮肥用量：氮肥施用過量，會使水稻組織柔嫩，而有利於稻熱病菌的感染且容易倒伏，因此，為預防稻熱病也要控制氮肥的施用。一般而言，建議總氮量約為每分地12公斤，但不同品種有所差異，例如台南11號合適的氮肥用量為每分地16公斤。\n二、藥劑防治:葉稻熱病的預防，應於分蘗盛期時施藥(高屏地區約為2月下旬～3月上旬)。而穗稻熱病的預防則可於施用穗肥時一併施用6%撲殺熱粒劑(約為出穗前20天)，或於抽穗前3～5天及齊穗期施用稻熱病防治用藥，可有效減少病害發生與蔓延。此外，稻熱病在高濕條件下容易發生，稻田栽植過密，或種植在通風不良的地區，特別需要注意防範。預防稻熱病或稻熱病發病初期可選用15%加普胺水懸劑、20%嘉賜三賽唑可濕性粉劑或50%富米熱斯可濕性粉劑，或選用植保手冊登記藥劑進行防治。"}, "1680166476.7960997": {"單位": "", "標題": "台灣水稻疫情整合資訊網-稻熱病簡介", "作者": "", "發布日": 0, "摘要": "", "全文": "稻熱病簡介:稻熱病是水稻受到稻熱病菌(一種真菌，學名：Pyricularia oryzae)感染而造成的病害。水稻從苗期、本田期至收穫為止，地上部的各部位都有可能受到稻熱病菌的感染。 由於現行水稻以單一品種密植的模式、加上稻熱病菌快速的傳播繁殖能力，以及近年氣候變動較大，使得稻熱病的大流行總是來得措手不及。 但如同所有植物病害一般，稻熱病的發生必須滿足三個條件，包含具致病力的病原菌、感病的寄主及適宜的環境 ，也就是所謂的病害三角環(Disease triangle)。 因此只要破壞病害三角的任一角，就能夠阻止稻熱病的大流行。接著我們就針對病原、寄主、環境這三個要件一介紹。\n病原:植物病害大多是由微生物造成，也就是在沒有顯微鏡的幫助下，人類的肉眼幾乎無法看見的一群生物。 稻熱病菌也不例外。稻熱病菌的分生孢子(無性繁殖的孢子)長度僅約25 µm，比人類頭髮的直徑(約100 µm)還小了數倍。 這種微小的孢子，可以輕易地乘著風傳播到數公尺遠，降落到其他稻子上。 當孢子附著到稻子表面後，會迅速發芽並產生附著器。附著器是一種特化的深色細胞，除了能夠緊緊抓住葉表外，還會產生高達80 bar的壓力，是一般家用汽車胎壓的32倍(Howard et al., 1991)。 稻熱病菌就是藉由附著器所蓄積的高壓，幫助菌絲穿過植物的角質層屏障，進入植物細胞。 在適宜的條件下(請見「環境」一節)整個侵入的過程，在短短的12小時內就會完成。\n在侵入後，稻熱病菌會迅速在細胞間蔓延，汲取植物組織的養分。 漸漸地，受感染的植物組織開始壞死，產生典型的稻熱病壞疽病徵。 當環境濕度提高時，組織內的菌絲會伸出組織外，產生分生孢子梗。 每個分生孢子梗上最多可以長出20個分生孢子，一塊小小的葉片病斑上，就能夠產生高達6000個分生孢子。 這些孢子將成為二次接種源，再次隨風飄散，感染鄰近的稻子。 稻熱病菌僅需要約4—6天就能完成上述的一個循環。 如此快速的繁殖速度正是稻熱病能夠在田間產生大流行的主因。\n環境:目前普遍認為稻熱病的發生，與環境溫度、濕度(露點)的相關性最大。適合稻熱病的發生溫度範圍較廣， 根據Koshimizu (1988)在日本之研究報告為15–25度；蔡氏(1980)於臺灣的研究則為19–25度。 濕度為另一個關鍵因子，特別是稻叢間的濕度。高濕度會促使葉面水膜的形成，而葉表的水膜為稻熱病入侵時不可或缺的條件。 由於稻田土地為長時間濕潤的環境，因此在稻株密植的情況下，加上稻株本身之蒸散作用， 將使稻株間的溼氣不易散去。 此時若再遇上4月的春雨或5-6月的梅雨季時的連續降雨，就會引發稻熱病的大流行。\n其中一個降低稻株間濕度的方法就是在插秧時加大稻株間的距離 (圖六)。 本研究2021年上半年在花壇的試驗田間實測。 插秧60天後，田埂處每日濕度大於98%之時長平均為3.1小時；在株距30公分之稻叢間為4.7小時； 株距15公分時為4.4小時；株距10公分時為10.4小時；株距7.5公分時為10.1小時。 可見當株距小於10公分時，會導致高濕時間顯著提升，創造適合稻熱病發病的環境。"}}